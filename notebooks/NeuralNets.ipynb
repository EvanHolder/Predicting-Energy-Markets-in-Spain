{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from keras import layers, models, regularizers\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import timeseries_dataset_from_array\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import os\n",
    "import winsound\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import datetime as dt\n",
    "\n",
    "os.chdir('../scripts')\n",
    "from functions import impute_immediate_mean\n",
    "os.chdir('../notebooks')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up alarm for notification of model completion\n",
    "duration = 1000  # milliseconds\n",
    "freq = 440  # Hz\n",
    "winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw =pd.read_csv('../data/df_clean.csv', index_col=0, parse_dates=True)\n",
    "TSO_preds = df_raw.price_forecast_tomorrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "df = pd.read_csv('../data/df_clean.csv', index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(columns='diff', inplace=True)\n",
    "\n",
    "#continuous = df.select_dtypes(exclude='object').drop(columns=['price_tomorrow']).columns\n",
    "continuous = df.select_dtypes(exclude='object').drop(columns=['price_tomorrow', 'price_forecast_tomorrow']).columns\n",
    "\n",
    "# Get rid of negatives\n",
    "time = dt.datetime(2021,3,23,22)\n",
    "df.loc[time, 'dew_point_bilbao'] = impute_immediate_mean(df['dew_point_bilbao'], time)\n",
    "\n",
    "# Rescale data [-1,1]\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "df[continuous] = scaler.fit_transform(df[continuous])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Categorical columns\n",
    "categorical = df.select_dtypes(include='object').columns\n",
    "\n",
    "# Instationate LabelEncoder, fit and transform on wind_direction cols\n",
    "wind_dir_coder = LabelEncoder()\n",
    "wind_dir_coder.fit(df['wind_madrid'])\n",
    "for col in ['wind_madrid', 'wind_seville', 'wind_barcelona', 'wind_bilbao', 'wind_valencia']:\n",
    "    df[col] = wind_dir_coder.transform(df[col])\n",
    "    \n",
    "\n",
    "# Stack condition columns into single col\n",
    "stacked_conditions = df.filter(regex='condition').stack()\n",
    "\n",
    "# Instantiate Label encoder, fit and transform on condition cols\n",
    "condition_coder = LabelEncoder()\n",
    "condition_coder.fit(stacked_conditions)\n",
    "for col in df.filter(regex='condition').columns:\n",
    "    df[col] = condition_coder.transform(df[col])\n",
    "\n",
    "# Rescale data [-1,1]\n",
    "df[categorical] = scaler.fit_transform(df[categorical])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns='price_tomorrow'), df['price_tomorrow'], test_size=.3,\n",
    "                                                    random_state=17)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=.5, random_state=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "def sMAPE(y_true, y_pred):\n",
    "    return 100 * K.mean(abs(y_pred - y_true)/((abs(y_true)+abs(y_pred))/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMAPE(y_true, y_pred):\n",
    "    return 100/(len(y_true)) * (abs(y_pred - y_true)/((abs(y_true)+abs(y_pred))/2)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_sMAPE\n"
     ]
    }
   ],
   "source": [
    "metric = sMAPE\n",
    "metric.name = 'sMAPE'\n",
    "print('val_'+metric.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, val_year):\n",
    "\n",
    "    # Divide dataset into training and validation\n",
    "    X_train = data.loc[:str(val_year-1)].drop(columns='price_tomorrow')\n",
    "    y_train = data.loc[:str(val_year-1), 'price_tomorrow']\n",
    "    X_val = data.loc[str(val_year)].drop(columns='price_tomorrow')\n",
    "    y_val = data.loc[str(val_year), 'price_tomorrow']\n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n",
    "def compile_fit(nn, X_train, y_train, validation,\n",
    "                patience=10,\n",
    "                metric=sMAPE,\n",
    "                #metric = tf.keras.metrics.MeanAbsolutePercentageError(name='MAPE'),\n",
    "                loss = tf.keras.metrics.mean_absolute_error,\n",
    "                batch_size = None):\n",
    "    \n",
    "    # Create early stopping point\n",
    "    metric.name='sMAPE'\n",
    "    callback = keras.callbacks.EarlyStopping(\n",
    "        patience=patience,\n",
    "        monitor='val_'+metric.name,\n",
    "        mode='min',\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    # Compile the model\n",
    "    nn.compile(\n",
    "        loss=loss, \n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        metrics=metric\n",
    "    )\n",
    "    \n",
    "    # Fit the model\n",
    "    history = nn.fit(\n",
    "        x = X_train,\n",
    "        y = y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs = 200,\n",
    "        callbacks=[callback],\n",
    "        validation_data=validation\n",
    "    )\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model and build layers\n",
    "nn = models.Sequential()\n",
    "nn.add(layers.Dense(62, activation='relu', input_shape=(shape,)))\n",
    "nn.add(layers.Dense(239, activation='relu'))\n",
    "nn.add(layers.Dense(162, activation='relu'))\n",
    "nn.add(layers.Dense(1, activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 2.0992 - sMAPE: 4.3128 - val_loss: 1.7284 - val_sMAPE: 5.0428\n",
      "Epoch 2/200\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 1.5216 - sMAPE: 2.9144 - val_loss: 1.9358 - val_sMAPE: 5.4734\n",
      "Epoch 3/200\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 1.4467 - sMAPE: 2.7597 - val_loss: 1.7417 - val_sMAPE: 5.1736\n",
      "Epoch 4/200\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 1.3971 - sMAPE: 2.6582 - val_loss: 1.5125 - val_sMAPE: 4.5392\n",
      "Epoch 5/200\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 1.3742 - sMAPE: 2.6165 - val_loss: 1.7475 - val_sMAPE: 5.2833\n",
      "Epoch 6/200\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 1.3565 - sMAPE: 2.5725 - val_loss: 1.9629 - val_sMAPE: 5.8024\n",
      "Epoch 7/200\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 1.3170 - sMAPE: 2.5025 - val_loss: 1.5946 - val_sMAPE: 4.8130\n",
      "Epoch 8/200\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 1.2907 - sMAPE: 2.4511 - val_loss: 1.9676 - val_sMAPE: 5.8131\n",
      "Epoch 9/200\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 1.2742 - sMAPE: 2.4176 - val_loss: 2.0740 - val_sMAPE: 6.1587\n",
      "Epoch 10/200\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 1.2618 - sMAPE: 2.3966 - val_loss: 1.7865 - val_sMAPE: 5.3048\n",
      "Epoch 11/200\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 1.2519 - sMAPE: 2.3718 - val_loss: 1.9662 - val_sMAPE: 5.8566\n",
      "Epoch 12/200\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 1.2196 - sMAPE: 2.3120 - val_loss: 1.7871 - val_sMAPE: 5.3356\n",
      "Epoch 13/200\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 1.2268 - sMAPE: 2.3281 - val_loss: 2.0182 - val_sMAPE: 5.9629\n",
      "Epoch 14/200\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 1.2156 - sMAPE: 2.2976 - val_loss: 1.3964 - val_sMAPE: 4.0714\n",
      "Epoch 15/200\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 1.2089 - sMAPE: 2.2864 - val_loss: 1.8627 - val_sMAPE: 5.4737\n",
      "Epoch 16/200\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 1.1859 - sMAPE: 2.2370 - val_loss: 1.8102 - val_sMAPE: 5.3347\n",
      "Epoch 17/200\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 1.1925 - sMAPE: 2.2511 - val_loss: 1.6053 - val_sMAPE: 4.7725\n",
      "Epoch 18/200\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 1.1643 - sMAPE: 2.1989 - val_loss: 1.7011 - val_sMAPE: 5.0811\n",
      "Epoch 19/200\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 1.1484 - sMAPE: 2.1653 - val_loss: 1.5488 - val_sMAPE: 4.5099\n",
      "Epoch 20/200\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 1.1445 - sMAPE: 2.1581 - val_loss: 1.6759 - val_sMAPE: 4.9730\n",
      "Epoch 21/200\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 1.1349 - sMAPE: 2.1395 - val_loss: 1.6559 - val_sMAPE: 4.8357\n",
      "Epoch 22/200\n",
      "1370/1370 [==============================] - 2s 2ms/step - loss: 1.1326 - sMAPE: 2.1326 - val_loss: 1.4699 - val_sMAPE: 4.2558\n",
      "Epoch 23/200\n",
      "1370/1370 [==============================] - 2s 2ms/step - loss: 1.1286 - sMAPE: 2.1248 - val_loss: 1.6124 - val_sMAPE: 4.6501\n",
      "Epoch 24/200\n",
      "1370/1370 [==============================] - 2s 1ms/step - loss: 1.1160 - sMAPE: 2.1013 - val_loss: 1.4699 - val_sMAPE: 4.2441\n",
      "r2: 0.9776875436701491\n",
      "mape: 4.185979120507125\n",
      "smape: 4.070921528837432\n",
      "smape: 4.0714497566223145\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val = split_data(df, 2020)\n",
    "\n",
    "bl = compile_fit(nn, X_train, y_train, (X_val, y_val),\n",
    "                patience=10,\n",
    "                loss = tf.keras.metrics.mean_absolute_error)\n",
    "preds = bl.predict(X_val).flatten()\n",
    "r2 = (np.corrcoef(y_val, preds)**2)[0][1]\n",
    "print('r2:', r2)\n",
    "print('mape:', mean_absolute_percentage_error(y_val, preds)*100)\n",
    "print('smape:', SMAPE(y_val, preds))\n",
    "loss, sMAPE_val = bl.evaluate(X_val, y_val, verbose=0)\n",
    "print('smape:', sMAPE_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model and build layers\n",
    "nn_final = models.Sequential()\n",
    "nn_final.add(layers.Dense(62, activation='relu', input_shape=(shape,)))\n",
    "nn_final.add(layers.Dense(239, activation='relu'))\n",
    "nn_final.add(layers.Dense(162, activation='relu'))\n",
    "nn_final.add(layers.Dense(1, activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1644/1644 [==============================] - 3s 1ms/step - loss: 1.9733 - sMAPE: 4.2737 - val_loss: 3.5257 - val_sMAPE: 3.9302\n",
      "Epoch 2/200\n",
      "1644/1644 [==============================] - 2s 1ms/step - loss: 1.5054 - sMAPE: 3.0898 - val_loss: 2.5294 - val_sMAPE: 3.1163\n",
      "Epoch 3/200\n",
      "1644/1644 [==============================] - 2s 1ms/step - loss: 1.4663 - sMAPE: 3.0000 - val_loss: 2.7105 - val_sMAPE: 3.2777\n",
      "Epoch 4/200\n",
      "1644/1644 [==============================] - 3s 2ms/step - loss: 1.4028 - sMAPE: 2.8682 - val_loss: 2.4926 - val_sMAPE: 3.0372\n",
      "Epoch 5/200\n",
      "1644/1644 [==============================] - 3s 2ms/step - loss: 1.3379 - sMAPE: 2.7306 - val_loss: 2.8074 - val_sMAPE: 3.3143\n",
      "Epoch 6/200\n",
      "1644/1644 [==============================] - 2s 1ms/step - loss: 1.3100 - sMAPE: 2.6720 - val_loss: 2.6923 - val_sMAPE: 3.1800\n",
      "Epoch 7/200\n",
      "1644/1644 [==============================] - 2s 1ms/step - loss: 1.2757 - sMAPE: 2.6006 - val_loss: 2.9182 - val_sMAPE: 3.5041\n",
      "Epoch 8/200\n",
      "1644/1644 [==============================] - 2s 1ms/step - loss: 1.2648 - sMAPE: 2.5793 - val_loss: 2.5996 - val_sMAPE: 3.1444\n",
      "Epoch 9/200\n",
      "1644/1644 [==============================] - 2s 1ms/step - loss: 1.2446 - sMAPE: 2.5322 - val_loss: 2.8880 - val_sMAPE: 3.6045\n",
      "Epoch 10/200\n",
      "1644/1644 [==============================] - 2s 1ms/step - loss: 1.2276 - sMAPE: 2.4953 - val_loss: 2.6306 - val_sMAPE: 3.1107\n",
      "Epoch 11/200\n",
      "1644/1644 [==============================] - 3s 2ms/step - loss: 1.2230 - sMAPE: 2.4855 - val_loss: 2.6101 - val_sMAPE: 3.0049\n",
      "Epoch 12/200\n",
      "1644/1644 [==============================] - 2s 1ms/step - loss: 1.2051 - sMAPE: 2.4430 - val_loss: 2.5430 - val_sMAPE: 3.0304\n",
      "Epoch 13/200\n",
      "1644/1644 [==============================] - 2s 2ms/step - loss: 1.1892 - sMAPE: 2.4096 - val_loss: 2.5868 - val_sMAPE: 3.0398\n",
      "Epoch 14/200\n",
      "1644/1644 [==============================] - 3s 2ms/step - loss: 1.1855 - sMAPE: 2.3972 - val_loss: 2.6644 - val_sMAPE: 3.0783\n",
      "Epoch 15/200\n",
      "1644/1644 [==============================] - 2s 1ms/step - loss: 1.1723 - sMAPE: 2.3668 - val_loss: 3.3081 - val_sMAPE: 3.5299\n",
      "Epoch 16/200\n",
      "1644/1644 [==============================] - 2s 1ms/step - loss: 1.1636 - sMAPE: 2.3514 - val_loss: 2.9295 - val_sMAPE: 3.2304\n",
      "Epoch 17/200\n",
      "1644/1644 [==============================] - 2s 1ms/step - loss: 1.1527 - sMAPE: 2.3298 - val_loss: 2.4448 - val_sMAPE: 3.0907\n",
      "Epoch 18/200\n",
      "1644/1644 [==============================] - 2s 1ms/step - loss: 1.1450 - sMAPE: 2.3083 - val_loss: 4.1177 - val_sMAPE: 3.8777\n",
      "Epoch 19/200\n",
      "1644/1644 [==============================] - 2s 1ms/step - loss: 1.1398 - sMAPE: 2.2941 - val_loss: 2.4973 - val_sMAPE: 3.1724\n",
      "Epoch 20/200\n",
      "1644/1644 [==============================] - 2s 2ms/step - loss: 1.1376 - sMAPE: 2.2866 - val_loss: 2.9828 - val_sMAPE: 3.3189\n",
      "Epoch 21/200\n",
      "1644/1644 [==============================] - 2s 1ms/step - loss: 1.1289 - sMAPE: 2.2669 - val_loss: 2.4456 - val_sMAPE: 3.1116\n",
      "r2: 0.9975249037005292\n",
      "mape: 2.9504125262141203\n",
      "smape: 3.004926558162059\n",
      "smape: 3.004925489425659\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val = split_data(df, 2021)\n",
    "\n",
    "bl_final = compile_fit(nn_final, X_train, y_train, (X_val, y_val),\n",
    "                patience=10,\n",
    "                loss = tf.keras.metrics.mean_absolute_error)\n",
    "preds = bl_final.predict(X_val).flatten()\n",
    "r2 = (np.corrcoef(y_val, preds)**2)[0][1]\n",
    "print('r2:', r2)\n",
    "print('mape:', mean_absolute_percentage_error(y_val, preds)*100)\n",
    "print('smape:', SMAPE(y_val, preds))\n",
    "loss, sMAPE_val = bl_final.evaluate(X_val, y_val, verbose=0)\n",
    "print('smape:', sMAPE_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2: 0.9714777867123521\n",
      "mape: 14.959628546355278\n",
      "smape: 16.918003049222687\n"
     ]
    }
   ],
   "source": [
    "print('r2:', (np.corrcoef(y_val,TSO_preds.loc['2020'])**2)[0][1])\n",
    "print('mape:', mean_absolute_percentage_error(y_val,TSO_preds.loc['2020'])*100)\n",
    "print('smape:', SMAPE(y_val,TSO_preds.loc['2020']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2: 0.9974031129868238\n",
      "mape: 3.210796692591586\n",
      "smape: 3.334922035726982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2021-01-01 00:00:00    -0.131090\n",
       "2021-01-01 01:00:00    -2.204759\n",
       "2021-01-01 02:00:00    -1.673647\n",
       "2021-01-01 03:00:00    -1.716557\n",
       "2021-01-01 04:00:00    -2.175416\n",
       "                         ...    \n",
       "2021-12-30 19:00:00    -7.747296\n",
       "2021-12-30 20:00:00    -5.384048\n",
       "2021-12-30 21:00:00    -9.977943\n",
       "2021-12-30 22:00:00   -13.360194\n",
       "2021-12-30 23:00:00   -17.658956\n",
       "Name: price_tomorrow, Length: 8736, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = split_data(df, 2021)\n",
    "preds = bl.predict(X_test).flatten()\n",
    "r2 = (np.corrcoef(y_test, preds)**2)[0][1]\n",
    "print('r2:', r2)\n",
    "print('mape:', mean_absolute_percentage_error(y_test, preds)*100)\n",
    "print('smape:', SMAPE(y_test, preds))\n",
    "resid_forecast = preds - y_test\n",
    "resid_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 42.3649 - MAPE: 83.3904 - val_loss: 24.8675 - val_MAPE: 111.7421\n",
      "Epoch 2/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 24.3124 - MAPE: 68.8397 - val_loss: 23.3587 - val_MAPE: 100.0323\n",
      "Epoch 3/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 23.2809 - MAPE: 62.0716 - val_loss: 22.6162 - val_MAPE: 96.2855\n",
      "Epoch 4/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 22.5349 - MAPE: 60.1233 - val_loss: 21.8751 - val_MAPE: 94.0755\n",
      "Epoch 5/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 21.7326 - MAPE: 58.6938 - val_loss: 21.1528 - val_MAPE: 95.9708\n",
      "Epoch 6/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 20.7999 - MAPE: 56.7986 - val_loss: 20.1292 - val_MAPE: 94.3731\n",
      "Epoch 7/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 19.6020 - MAPE: 55.6993 - val_loss: 18.8427 - val_MAPE: 95.4855\n",
      "Epoch 8/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 18.0284 - MAPE: 55.1644 - val_loss: 17.1238 - val_MAPE: 97.9483\n",
      "Epoch 9/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 15.9196 - MAPE: 54.7906 - val_loss: 14.7550 - val_MAPE: 102.0337\n",
      "Epoch 10/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 13.2180 - MAPE: 51.2085 - val_loss: 12.0199 - val_MAPE: 101.4767\n",
      "Epoch 11/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 10.3763 - MAPE: 49.6144 - val_loss: 9.5851 - val_MAPE: 98.7602\n",
      "Epoch 12/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 8.7122 - MAPE: 46.6954 - val_loss: 8.6697 - val_MAPE: 97.0760\n",
      "Epoch 13/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 8.1930 - MAPE: 43.9931 - val_loss: 8.4811 - val_MAPE: 94.9215\n",
      "Epoch 14/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.9654 - MAPE: 43.5136 - val_loss: 8.1589 - val_MAPE: 90.2864\n",
      "Epoch 15/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.8089 - MAPE: 42.7593 - val_loss: 8.0142 - val_MAPE: 89.7980\n",
      "Epoch 16/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.6934 - MAPE: 41.9618 - val_loss: 7.9013 - val_MAPE: 88.4938\n",
      "Epoch 17/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.5989 - MAPE: 41.5502 - val_loss: 7.8481 - val_MAPE: 87.7954\n",
      "Epoch 18/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.5309 - MAPE: 41.0745 - val_loss: 7.7562 - val_MAPE: 86.6834\n",
      "Epoch 19/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.4656 - MAPE: 40.6785 - val_loss: 7.6819 - val_MAPE: 84.7859\n",
      "Epoch 20/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.4101 - MAPE: 39.7905 - val_loss: 7.6691 - val_MAPE: 81.1435\n",
      "Epoch 21/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.3568 - MAPE: 39.2496 - val_loss: 7.5660 - val_MAPE: 80.5407\n",
      "Epoch 22/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.2990 - MAPE: 38.6698 - val_loss: 7.7036 - val_MAPE: 79.6300\n",
      "Epoch 23/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.2576 - MAPE: 38.8286 - val_loss: 7.4625 - val_MAPE: 80.0509\n",
      "Epoch 24/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 7.2288 - MAPE: 38.1678 - val_loss: 7.4232 - val_MAPE: 78.8882\n",
      "Epoch 25/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.1803 - MAPE: 37.4694 - val_loss: 7.4292 - val_MAPE: 77.5186\n",
      "Epoch 26/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.1486 - MAPE: 37.3799 - val_loss: 7.3322 - val_MAPE: 77.5184\n",
      "Epoch 27/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.1084 - MAPE: 36.7988 - val_loss: 7.2989 - val_MAPE: 76.1484\n",
      "Epoch 28/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.0835 - MAPE: 36.3635 - val_loss: 7.3226 - val_MAPE: 75.1726\n",
      "Epoch 29/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.0651 - MAPE: 36.2957 - val_loss: 7.2739 - val_MAPE: 73.4240\n",
      "Epoch 30/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.0198 - MAPE: 35.7371 - val_loss: 7.2384 - val_MAPE: 75.0487\n",
      "Epoch 31/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 7.0082 - MAPE: 35.1625 - val_loss: 7.1809 - val_MAPE: 72.6405\n",
      "Epoch 32/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.9696 - MAPE: 35.1348 - val_loss: 7.1824 - val_MAPE: 71.2904\n",
      "Epoch 33/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.9537 - MAPE: 34.8566 - val_loss: 7.1167 - val_MAPE: 72.5389\n",
      "Epoch 34/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.9284 - MAPE: 34.6932 - val_loss: 7.1074 - val_MAPE: 71.3433\n",
      "Epoch 35/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.9039 - MAPE: 34.0939 - val_loss: 7.1225 - val_MAPE: 70.4945\n",
      "Epoch 36/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.8834 - MAPE: 33.7701 - val_loss: 7.0510 - val_MAPE: 70.5089\n",
      "Epoch 37/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.8546 - MAPE: 33.9122 - val_loss: 7.0219 - val_MAPE: 69.8152\n",
      "Epoch 38/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.8386 - MAPE: 33.7979 - val_loss: 7.0223 - val_MAPE: 69.0464\n",
      "Epoch 39/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.8219 - MAPE: 33.4144 - val_loss: 7.0060 - val_MAPE: 69.2989\n",
      "Epoch 40/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.7946 - MAPE: 33.2060 - val_loss: 6.9942 - val_MAPE: 69.2769\n",
      "Epoch 41/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.7828 - MAPE: 33.3226 - val_loss: 7.0542 - val_MAPE: 65.7990\n",
      "Epoch 42/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.7783 - MAPE: 32.8779 - val_loss: 7.1822 - val_MAPE: 70.3645\n",
      "Epoch 43/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.7420 - MAPE: 32.6554 - val_loss: 6.9402 - val_MAPE: 65.4686\n",
      "Epoch 44/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.7299 - MAPE: 32.4850 - val_loss: 6.9198 - val_MAPE: 66.3519\n",
      "Epoch 45/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.7226 - MAPE: 32.0699 - val_loss: 6.9207 - val_MAPE: 66.7538\n",
      "Epoch 46/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.7057 - MAPE: 31.9391 - val_loss: 6.8919 - val_MAPE: 65.0622\n",
      "Epoch 47/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.6940 - MAPE: 32.2783 - val_loss: 6.8846 - val_MAPE: 64.9862\n",
      "Epoch 48/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.6783 - MAPE: 31.8771 - val_loss: 6.8648 - val_MAPE: 64.4338\n",
      "Epoch 49/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.6574 - MAPE: 31.8197 - val_loss: 6.8577 - val_MAPE: 64.0338\n",
      "Epoch 50/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.6539 - MAPE: 31.3227 - val_loss: 6.8536 - val_MAPE: 63.9932\n",
      "Epoch 51/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.6412 - MAPE: 31.3444 - val_loss: 6.8501 - val_MAPE: 61.9919\n",
      "Epoch 52/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.6313 - MAPE: 31.3233 - val_loss: 6.8431 - val_MAPE: 62.7841\n",
      "Epoch 53/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.6231 - MAPE: 31.1422 - val_loss: 6.8473 - val_MAPE: 63.4425\n",
      "Epoch 54/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.6058 - MAPE: 30.8358 - val_loss: 6.8286 - val_MAPE: 61.0420\n",
      "Epoch 55/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.5982 - MAPE: 30.8334 - val_loss: 6.8026 - val_MAPE: 61.4593\n",
      "Epoch 56/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.5916 - MAPE: 30.9894 - val_loss: 6.8237 - val_MAPE: 61.3918\n",
      "Epoch 57/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.5716 - MAPE: 30.6630 - val_loss: 6.8124 - val_MAPE: 60.9818\n",
      "Epoch 58/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.5660 - MAPE: 30.4998 - val_loss: 6.9284 - val_MAPE: 61.6341\n",
      "Epoch 59/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.5516 - MAPE: 30.5000 - val_loss: 6.7768 - val_MAPE: 60.4217\n",
      "Epoch 60/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.5560 - MAPE: 30.3107 - val_loss: 6.8020 - val_MAPE: 62.3260\n",
      "Epoch 61/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.5424 - MAPE: 30.3945 - val_loss: 6.7678 - val_MAPE: 62.0723\n",
      "Epoch 62/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.5374 - MAPE: 30.6727 - val_loss: 6.7714 - val_MAPE: 59.7517\n",
      "Epoch 63/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.5297 - MAPE: 30.2308 - val_loss: 6.7659 - val_MAPE: 60.9871\n",
      "Epoch 64/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.5278 - MAPE: 29.9674 - val_loss: 6.7834 - val_MAPE: 60.2495\n",
      "Epoch 65/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.5087 - MAPE: 29.9064 - val_loss: 6.8491 - val_MAPE: 62.4007\n",
      "Epoch 66/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.4993 - MAPE: 30.2195 - val_loss: 6.8062 - val_MAPE: 59.5190\n",
      "Epoch 67/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.5032 - MAPE: 29.7893 - val_loss: 6.7676 - val_MAPE: 59.4298\n",
      "Epoch 68/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.4919 - MAPE: 29.7104 - val_loss: 6.8400 - val_MAPE: 61.5431\n",
      "Epoch 69/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.4850 - MAPE: 29.8398 - val_loss: 6.7751 - val_MAPE: 60.6694\n",
      "Epoch 70/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.4809 - MAPE: 29.8614 - val_loss: 6.7039 - val_MAPE: 59.1688\n",
      "Epoch 71/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.4613 - MAPE: 29.4125 - val_loss: 6.7092 - val_MAPE: 59.6436\n",
      "Epoch 72/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.4535 - MAPE: 29.4374 - val_loss: 6.7075 - val_MAPE: 59.5057\n",
      "Epoch 73/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.4601 - MAPE: 29.4059 - val_loss: 6.7589 - val_MAPE: 59.0167\n",
      "Epoch 74/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.4417 - MAPE: 29.4695 - val_loss: 6.7228 - val_MAPE: 58.3572\n",
      "Epoch 75/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.4350 - MAPE: 29.0912 - val_loss: 6.6886 - val_MAPE: 58.5827\n",
      "Epoch 76/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.4262 - MAPE: 29.6614 - val_loss: 6.7035 - val_MAPE: 59.3901\n",
      "Epoch 77/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.4217 - MAPE: 29.1754 - val_loss: 6.6997 - val_MAPE: 58.0888\n",
      "Epoch 78/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.4166 - MAPE: 29.3208 - val_loss: 6.6984 - val_MAPE: 60.0224\n",
      "Epoch 79/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.4208 - MAPE: 29.3119 - val_loss: 6.8473 - val_MAPE: 61.9790\n",
      "Epoch 80/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.4007 - MAPE: 29.2533 - val_loss: 6.6630 - val_MAPE: 58.9944\n",
      "Epoch 81/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.3976 - MAPE: 28.8626 - val_loss: 6.6561 - val_MAPE: 58.6392\n",
      "Epoch 82/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.3905 - MAPE: 28.9708 - val_loss: 6.6758 - val_MAPE: 59.2342\n",
      "Epoch 83/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.3878 - MAPE: 29.0871 - val_loss: 6.6814 - val_MAPE: 57.8697\n",
      "Epoch 84/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.3821 - MAPE: 28.8556 - val_loss: 6.6534 - val_MAPE: 58.6794\n",
      "Epoch 85/100\n",
      "334/334 [==============================] - 1s 2ms/step - loss: 6.3681 - MAPE: 29.1229 - val_loss: 6.6986 - val_MAPE: 57.9934\n",
      "Epoch 86/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.3773 - MAPE: 28.8967 - val_loss: 6.6810 - val_MAPE: 58.9872\n",
      "Epoch 87/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.3687 - MAPE: 28.7754 - val_loss: 6.6315 - val_MAPE: 58.5093\n",
      "Epoch 88/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.3585 - MAPE: 28.7532 - val_loss: 6.6602 - val_MAPE: 56.8734\n",
      "Epoch 89/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.3566 - MAPE: 28.6196 - val_loss: 6.6946 - val_MAPE: 57.1142\n",
      "Epoch 90/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.3500 - MAPE: 28.9529 - val_loss: 6.7473 - val_MAPE: 60.9010\n",
      "Epoch 91/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.3485 - MAPE: 28.8765 - val_loss: 6.6696 - val_MAPE: 57.3434\n",
      "Epoch 92/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.3348 - MAPE: 28.5160 - val_loss: 6.6542 - val_MAPE: 58.7095\n",
      "Epoch 93/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.3291 - MAPE: 28.7331 - val_loss: 6.6715 - val_MAPE: 59.4932\n",
      "Epoch 94/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.3255 - MAPE: 28.3685 - val_loss: 6.6056 - val_MAPE: 57.7105\n",
      "Epoch 95/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.3149 - MAPE: 28.3867 - val_loss: 6.6400 - val_MAPE: 58.1340\n",
      "Epoch 96/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.3123 - MAPE: 28.3650 - val_loss: 6.5967 - val_MAPE: 57.9205\n",
      "Epoch 97/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.3117 - MAPE: 28.3174 - val_loss: 6.6021 - val_MAPE: 58.0523\n",
      "Epoch 98/100\n",
      "334/334 [==============================] - 1s 3ms/step - loss: 6.3077 - MAPE: 28.6687 - val_loss: 6.6058 - val_MAPE: 58.6624\n",
      "r2: 0.9276014251521141\n",
      "r2: 0.927929047762599\n",
      "val r2: 0.9198971676998733\n",
      "val r2: 0.9202833278256821\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model and build layers\n",
    "nn = models.Sequential()\n",
    "nn.add(layers.Dense(239, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "nn.add(layers.Dense(162, activation='relu'))\n",
    "nn.add(layers.Dense(1, activation='relu'))\n",
    "\n",
    "# Loss Metric to optimize\n",
    "metric = tf.keras.metrics.MeanAbsolutePercentageError(name='MAPE')\n",
    "\n",
    "# Create early stopping point\n",
    "callback = keras.callbacks.EarlyStopping(\n",
    "    patience=10,\n",
    "    monitor='val_'+metric.name,\n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "nn.compile(loss=tf.keras.metrics.mean_absolute_error, \n",
    "           optimizer=keras.optimizers.Adam(learning_rate=.0001),\n",
    "           metrics=metric)\n",
    "\n",
    "# Fit the model\n",
    "history = nn.fit(x= X_train,\n",
    "                 y=y_train,\n",
    "                 batch_size=128,\n",
    "                 epochs = 100,\n",
    "                 callbacks=[callback],\n",
    "                 validation_data=(X_val, y_val),\n",
    ")\n",
    "\n",
    "preds_train = nn.predict(X_train).flatten()\n",
    "preds_val = nn.predict(X_val).flatten()\n",
    "\n",
    "print('r2:',r2_score(y_train, preds_train))\n",
    "print('r2:',(np.corrcoef(y_train, preds_train)**2)[0][1])\n",
    "\n",
    "print('val r2:',r2_score(y_val, preds_val))\n",
    "print('val r2:',(np.corrcoef(y_val, preds_val)**2)[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_, y_train, X_val, y_val = split_data(df, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 40.7536 - MAPE: 82.2737 - val_loss: 29.4587 - val_MAPE: 112.3087\n",
      "Epoch 2/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 27.4505 - MAPE: 78.2185 - val_loss: 25.6727 - val_MAPE: 95.6277\n",
      "Epoch 3/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 24.9472 - MAPE: 65.1849 - val_loss: 23.9091 - val_MAPE: 81.0519\n",
      "Epoch 4/100\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 23.1896 - MAPE: 55.6207 - val_loss: 22.2045 - val_MAPE: 68.1717\n",
      "Epoch 5/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 21.1731 - MAPE: 47.3178 - val_loss: 20.1566 - val_MAPE: 54.0342\n",
      "Epoch 6/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 18.9979 - MAPE: 40.0940 - val_loss: 18.0588 - val_MAPE: 41.6691\n",
      "Epoch 7/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 16.8930 - MAPE: 35.7444 - val_loss: 16.0439 - val_MAPE: 28.6478\n",
      "Epoch 8/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 15.1438 - MAPE: 30.5226 - val_loss: 14.5786 - val_MAPE: 27.8606\n",
      "Epoch 9/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 13.9179 - MAPE: 26.9165 - val_loss: 13.5892 - val_MAPE: 27.8606\n",
      "Epoch 10/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 12.9888 - MAPE: 25.1765 - val_loss: 12.8144 - val_MAPE: 27.8122\n",
      "Epoch 11/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 12.2912 - MAPE: 24.2078 - val_loss: 12.2748 - val_MAPE: 28.4628\n",
      "Epoch 12/100\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 11.7065 - MAPE: 23.6774 - val_loss: 11.6196 - val_MAPE: 27.6600\n",
      "Epoch 13/100\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 11.1763 - MAPE: 23.1183 - val_loss: 11.1782 - val_MAPE: 27.5312\n",
      "Epoch 14/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 10.7344 - MAPE: 22.6043 - val_loss: 10.7316 - val_MAPE: 26.9204\n",
      "Epoch 15/100\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 10.3438 - MAPE: 22.1033 - val_loss: 10.3997 - val_MAPE: 26.3158\n",
      "Epoch 16/100\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 10.0517 - MAPE: 21.6522 - val_loss: 10.1462 - val_MAPE: 25.7484\n",
      "Epoch 17/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 9.8160 - MAPE: 21.3405 - val_loss: 9.9062 - val_MAPE: 25.3580\n",
      "Epoch 18/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 9.6133 - MAPE: 21.0099 - val_loss: 9.7292 - val_MAPE: 24.9279\n",
      "Epoch 19/100\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 9.4583 - MAPE: 20.7242 - val_loss: 9.6942 - val_MAPE: 25.4181\n",
      "Epoch 20/100\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 9.3152 - MAPE: 20.5124 - val_loss: 9.4351 - val_MAPE: 24.4504\n",
      "Epoch 21/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 9.1801 - MAPE: 20.3550 - val_loss: 9.3490 - val_MAPE: 24.3628\n",
      "Epoch 22/100\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 9.0684 - MAPE: 20.1993 - val_loss: 9.2047 - val_MAPE: 23.9875\n",
      "Epoch 23/100\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 8.9724 - MAPE: 20.0312 - val_loss: 9.1108 - val_MAPE: 23.6877\n",
      "Epoch 24/100\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 8.8656 - MAPE: 19.9131 - val_loss: 9.2001 - val_MAPE: 24.3516\n",
      "Epoch 25/100\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 8.7769 - MAPE: 19.7466 - val_loss: 8.9469 - val_MAPE: 23.2960\n",
      "Epoch 26/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 8.7080 - MAPE: 19.7666 - val_loss: 8.8771 - val_MAPE: 22.9268\n",
      "Epoch 27/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 8.6240 - MAPE: 19.6435 - val_loss: 8.8044 - val_MAPE: 22.7795\n",
      "Epoch 28/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 8.5434 - MAPE: 19.5744 - val_loss: 8.7291 - val_MAPE: 22.7590\n",
      "Epoch 29/100\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 8.4950 - MAPE: 19.5380 - val_loss: 8.7017 - val_MAPE: 22.2686\n",
      "Epoch 30/100\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 8.4232 - MAPE: 19.4365 - val_loss: 8.6345 - val_MAPE: 22.6142\n",
      "Epoch 31/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 8.3491 - MAPE: 19.3261 - val_loss: 8.5958 - val_MAPE: 21.9382\n",
      "Epoch 32/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 8.3103 - MAPE: 19.3082 - val_loss: 8.5487 - val_MAPE: 21.9117\n",
      "Epoch 33/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 8.2492 - MAPE: 19.2034 - val_loss: 8.4698 - val_MAPE: 21.7320\n",
      "Epoch 34/100\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 8.1977 - MAPE: 19.1609 - val_loss: 8.4323 - val_MAPE: 21.8003\n",
      "Epoch 35/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 8.1484 - MAPE: 19.1129 - val_loss: 8.3870 - val_MAPE: 21.4005\n",
      "Epoch 36/100\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 8.0963 - MAPE: 19.0505 - val_loss: 8.3454 - val_MAPE: 21.3163\n",
      "Epoch 37/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 8.0437 - MAPE: 19.0040 - val_loss: 8.3047 - val_MAPE: 21.6043\n",
      "Epoch 38/100\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 7.9958 - MAPE: 18.9216 - val_loss: 8.3014 - val_MAPE: 21.5781\n",
      "Epoch 39/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 7.9561 - MAPE: 18.8510 - val_loss: 8.2580 - val_MAPE: 21.4213\n",
      "Epoch 40/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 7.9145 - MAPE: 18.8321 - val_loss: 8.1935 - val_MAPE: 21.0726\n",
      "Epoch 41/100\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 7.8928 - MAPE: 18.7315 - val_loss: 8.1438 - val_MAPE: 21.0992\n",
      "Epoch 42/100\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 7.8325 - MAPE: 18.7069 - val_loss: 8.1229 - val_MAPE: 20.7696\n",
      "Epoch 43/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 7.7965 - MAPE: 18.6477 - val_loss: 8.0787 - val_MAPE: 20.7263\n",
      "Epoch 44/100\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 7.7698 - MAPE: 18.5658 - val_loss: 8.0547 - val_MAPE: 20.5772\n",
      "Epoch 45/100\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 7.7230 - MAPE: 18.5042 - val_loss: 8.0491 - val_MAPE: 21.0018\n",
      "Epoch 46/100\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 7.6850 - MAPE: 18.4188 - val_loss: 8.0274 - val_MAPE: 20.9373\n",
      "Epoch 47/100\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 7.6603 - MAPE: 18.4194 - val_loss: 7.9705 - val_MAPE: 20.6897\n",
      "Epoch 48/100\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 7.6240 - MAPE: 18.3446 - val_loss: 7.9530 - val_MAPE: 20.4681\n",
      "Epoch 49/100\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 7.6067 - MAPE: 18.3013 - val_loss: 7.9335 - val_MAPE: 20.3875\n",
      "Epoch 50/100\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 7.5485 - MAPE: 18.1828 - val_loss: 7.9223 - val_MAPE: 20.6084\n",
      "Epoch 51/100\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 7.5266 - MAPE: 18.1456 - val_loss: 7.8869 - val_MAPE: 20.2596\n",
      "Epoch 52/100\n",
      "167/167 [==============================] - 0s 3ms/step - loss: 7.4931 - MAPE: 18.0600 - val_loss: 7.8346 - val_MAPE: 20.2826\n",
      "Epoch 53/100\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 7.4582 - MAPE: 18.0342 - val_loss: 7.9018 - val_MAPE: 20.7868\n",
      "Epoch 54/100\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 7.4358 - MAPE: 18.0795 - val_loss: 7.8161 - val_MAPE: 20.3873\n",
      "Epoch 55/100\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 7.4071 - MAPE: 18.0717 - val_loss: 7.7940 - val_MAPE: 19.8725\n",
      "Epoch 56/100\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 7.3895 - MAPE: 18.0416 - val_loss: 7.8774 - val_MAPE: 20.6360\n",
      "Epoch 57/100\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 7.3646 - MAPE: 18.0279 - val_loss: 7.7230 - val_MAPE: 20.0570\n",
      "Epoch 58/100\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 7.3152 - MAPE: 18.2198 - val_loss: 7.7175 - val_MAPE: 19.9138\n",
      "Epoch 59/100\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 7.2891 - MAPE: 18.1002 - val_loss: 7.6955 - val_MAPE: 20.1433\n",
      "Epoch 60/100\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 7.2682 - MAPE: 18.5793 - val_loss: 7.6573 - val_MAPE: 19.8791\n",
      "Epoch 61/100\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 7.2467 - MAPE: 18.6973 - val_loss: 7.6629 - val_MAPE: 20.2029\n",
      "Epoch 62/100\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 7.2197 - MAPE: 18.8502 - val_loss: 7.6726 - val_MAPE: 20.4380\n",
      "Epoch 63/100\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 7.2109 - MAPE: 18.7489 - val_loss: 7.5994 - val_MAPE: 19.9233\n",
      "Epoch 64/100\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 7.1774 - MAPE: 19.1197 - val_loss: 7.5866 - val_MAPE: 19.6452\n",
      "Epoch 65/100\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 7.1480 - MAPE: 19.1100 - val_loss: 7.5547 - val_MAPE: 20.4095\n",
      "Epoch 66/100\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 7.1294 - MAPE: 19.3869 - val_loss: 7.5422 - val_MAPE: 21.3500\n",
      "Epoch 67/100\n",
      "167/167 [==============================] - 1s 5ms/step - loss: 7.0959 - MAPE: 19.4419 - val_loss: 7.5143 - val_MAPE: 22.1001\n",
      "Epoch 68/100\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 7.0748 - MAPE: 19.7706 - val_loss: 7.5100 - val_MAPE: 22.6776\n",
      "Epoch 69/100\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 7.0520 - MAPE: 19.8156 - val_loss: 7.5079 - val_MAPE: 23.9820\n",
      "Epoch 70/100\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 7.0295 - MAPE: 20.0480 - val_loss: 7.5602 - val_MAPE: 25.2349\n",
      "Epoch 71/100\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 7.0250 - MAPE: 20.0263 - val_loss: 7.4748 - val_MAPE: 26.1673\n",
      "Epoch 72/100\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 7.0008 - MAPE: 20.3853 - val_loss: 7.4440 - val_MAPE: 26.4878\n",
      "Epoch 73/100\n",
      "167/167 [==============================] - 1s 3ms/step - loss: 6.9779 - MAPE: 20.4908 - val_loss: 7.4201 - val_MAPE: 27.1134\n",
      "Epoch 74/100\n",
      "167/167 [==============================] - 1s 4ms/step - loss: 6.9821 - MAPE: 20.6863 - val_loss: 7.4667 - val_MAPE: 27.2669\n",
      "r2: 0.9269175386415136\n",
      "r2: 0.9271853803859837\n",
      "val r2: 0.9165620880865135\n",
      "val r2: 0.916804032657446\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model and build layers\n",
    "nn = models.Sequential()\n",
    "nn.add(layers.Dense(239, activation='relu', input_shape=(X_train.shape[1],),\n",
    "                    kernel_regularizer=regularizers.L1(.0001)))\n",
    "nn.add(layers.Dense(162, activation='relu', kernel_regularizer=regularizers.L1(.0001)))\n",
    "nn.add(layers.Dense(1, activation='relu'))\n",
    "\n",
    "# Loss Metric to optimize\n",
    "metric = tf.keras.metrics.MeanAbsolutePercentageError(name='MAPE')\n",
    "\n",
    "# Create early stopping point\n",
    "callback = keras.callbacks.EarlyStopping(\n",
    "    patience=10,\n",
    "    monitor='val_'+metric.name,\n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "nn.compile(loss=tf.keras.metrics.mean_absolute_error, \n",
    "           optimizer=keras.optimizers.Adam(learning_rate=.0001),\n",
    "           metrics=metric)\n",
    "\n",
    "# Fit the model\n",
    "history = nn.fit(x= X_train,\n",
    "                 y=y_train,\n",
    "                 batch_size=256,\n",
    "                 epochs = 100,\n",
    "                 callbacks=[callback],\n",
    "                 validation_data=(X_val, y_val),\n",
    ")\n",
    "\n",
    "preds_train = nn.predict(X_train).flatten()\n",
    "preds_val = nn.predict(X_val).flatten()\n",
    "\n",
    "print('r2:',r2_score(y_train, preds_train))\n",
    "print('r2:',(np.corrcoef(y_train, preds_train)**2)[0][1])\n",
    "\n",
    "print('val r2:',r2_score(y_val, preds_val))\n",
    "print('val r2:',(np.corrcoef(y_val, preds_val)**2)[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network - 24 Hour Prediction \n",
    "Two hidden layers\n",
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_supervised(train, n_input, n_out=7, stride=1):\n",
    "    # flatten data\n",
    "    data = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n",
    "    X, y = list(), list()\n",
    "    in_start = 0\n",
    "    # step over the entire history one time step at a time\n",
    "    for _ in range(len(data)):\n",
    "        # define the end of the input sequence\n",
    "        in_end = in_start + n_input\n",
    "        out_end = in_end + n_out\n",
    "        # ensure we have enough data for this instance\n",
    "        if out_end <= len(data):\n",
    "            X.append(data[in_start:in_end, :-1])\n",
    "            y.append(data[in_end:out_end, -1])\n",
    "        # move along one time step\n",
    "        in_start += stride\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1826, 24, 62)\n",
      "(366, 24, 62)\n"
     ]
    }
   ],
   "source": [
    "train = df.loc[:'2019'].drop(columns='price_tomorrow')\n",
    "val = df.loc['2020'].drop(columns='price_tomorrow')\n",
    "\n",
    "train['price_tomorrow'] = df.loc[:'2019', 'price_tomorrow']\n",
    "val['price_tomorrow'] = df.loc['2020', 'price_tomorrow']\n",
    "\n",
    "train = np.array(np.split(train, len(train)/24))\n",
    "val = np.array(np.split(val, len(val)/24))\n",
    "print(train.shape)\n",
    "print(val.shape)\n",
    "\n",
    "\n",
    "X_train, y_train = to_supervised(train, n_input=24, n_out=24, stride=24)\n",
    "X_val, y_val = to_supervised(val, n_input=24, n_out=24, stride=24)\n",
    "input_shape=(X_train.shape[1], X_train.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model and build layers\n",
    "bm = models.Sequential()\n",
    "bm.add(layers.Dense(62, activation='relu', input_shape=input_shape))\n",
    "bm.add(layers.Dense(239, activation='relu'))\n",
    "bm.add(layers.Dense(162, activation='relu'))\n",
    "bm.add(TimeDistributed(layers.Dense(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "* <u>monitor_metric & metric (MAPE)</u>:  chosen because sMAPE not available. Chance to hard code sMAPE and implement?\n",
    "* <u>patience (10)</u>: chosen to prevent reaching local minimum\n",
    "* <u>loss function (mean_absolute_error)</u>: chosen because as the electricity prices have large spikes, the Euclidean norm would put too much importance on the spiky prices\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "58/58 [==============================] - 1s 6ms/step - loss: 12.8354 - MAPE: 23.8156 - val_loss: 6.6339 - val_MAPE: 20.9957\n",
      "Epoch 2/100\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 6.2299 - MAPE: 12.9851 - val_loss: 6.3519 - val_MAPE: 20.7919\n",
      "Epoch 3/100\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 5.9734 - MAPE: 12.6865 - val_loss: 7.3727 - val_MAPE: 24.7458\n",
      "Epoch 4/100\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 5.9424 - MAPE: 12.5946 - val_loss: 8.1275 - val_MAPE: 27.1244\n",
      "Epoch 5/100\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 5.9886 - MAPE: 12.7219 - val_loss: 7.2862 - val_MAPE: 24.4366\n",
      "Epoch 6/100\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 5.7854 - MAPE: 12.3688 - val_loss: 5.4870 - val_MAPE: 18.0086\n",
      "Epoch 7/100\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 5.7725 - MAPE: 12.2448 - val_loss: 6.0984 - val_MAPE: 20.8754\n",
      "Epoch 8/100\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 5.7683 - MAPE: 12.3319 - val_loss: 7.2579 - val_MAPE: 24.3321\n",
      "Epoch 9/100\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 5.7905 - MAPE: 12.2621 - val_loss: 6.1431 - val_MAPE: 21.0078\n",
      "Epoch 10/100\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 5.6658 - MAPE: 12.0444 - val_loss: 8.5846 - val_MAPE: 29.3594\n",
      "Epoch 11/100\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 5.7717 - MAPE: 12.2813 - val_loss: 6.1409 - val_MAPE: 21.3960\n",
      "Epoch 12/100\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 5.7693 - MAPE: 12.3194 - val_loss: 6.4291 - val_MAPE: 22.0588\n",
      "Epoch 13/100\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 5.6331 - MAPE: 11.9967 - val_loss: 5.7046 - val_MAPE: 19.3274\n",
      "Epoch 14/100\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 5.6766 - MAPE: 12.0926 - val_loss: 6.1183 - val_MAPE: 21.0723\n",
      "Epoch 15/100\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 5.5682 - MAPE: 11.8354 - val_loss: 6.9164 - val_MAPE: 24.0128\n",
      "Epoch 16/100\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 5.6465 - MAPE: 11.9898 - val_loss: 5.8647 - val_MAPE: 20.0411\n",
      "train r2: 0.652412158831897\n",
      "train r2: 0.672250990806971\n",
      "val r2: 0.5840653925835957\n",
      "val r2: 0.6189845842045377\n"
     ]
    }
   ],
   "source": [
    "# Loss Metric to optimize\n",
    "metric = tf.keras.metrics.MeanAbsolutePercentageError(name='MAPE')\n",
    "\n",
    "# Create early stopping point\n",
    "callback = keras.callbacks.EarlyStopping(\n",
    "    patience=10,\n",
    "    monitor='val_'+metric.name,\n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "bm.compile(loss=tf.keras.metrics.mean_absolute_error, \n",
    "           optimizer=keras.optimizers.Adam(),\n",
    "           metrics=metric)\n",
    "\n",
    "# Fit the model\n",
    "history = bm.fit(x= X_train,\n",
    "                 y=y_train,\n",
    "                 epochs = 100,\n",
    "                 callbacks=[callback],\n",
    "                 batch_size=32,\n",
    "                 validation_data=(X_val, y_val),\n",
    ")\n",
    "\n",
    "preds_train = bm.predict(X_train).flatten()\n",
    "preds_val = bm.predict(X_val).flatten()\n",
    "\n",
    "\n",
    "print('train r2:',r2_score(y_train.flatten(), preds_train))\n",
    "print('train r2:',(np.corrcoef(y_train.flatten(), preds_train)**2)[0][1])\n",
    "\n",
    "print('val r2:',r2_score(y_val.flatten(), preds_val))\n",
    "print('val r2:',(np.corrcoef(y_val.flatten(), preds_val)**2)[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model and build layers\n",
    "bm = models.Sequential()\n",
    "bm.add(layers.Dense(239, activation='relu', input_shape=input_shape, kernel_regularizer=regularizers.l1(0.9)))\n",
    "bm.add(layers.Dropout(.9))\n",
    "bm.add(layers.Dense(162, activation='relu', kernel_regularizer=regularizers.l1(0.9)))\n",
    "bm.add(layers.Dropout(.9))\n",
    "bm.add(TimeDistributed(layers.Dense(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "4/4 [==============================] - 1s 123ms/step - loss: 3070.5112 - MAPE: 101.8340 - val_loss: 2922.1626 - val_MAPE: 101.8104\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 2883.5691 - MAPE: 101.3586 - val_loss: 2739.7991 - val_MAPE: 101.1662\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 2703.2878 - MAPE: 100.7100 - val_loss: 2563.8469 - val_MAPE: 100.5940\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 2529.2197 - MAPE: 100.2305 - val_loss: 2394.1724 - val_MAPE: 100.0971\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 2361.3186 - MAPE: 99.6174 - val_loss: 2230.2959 - val_MAPE: 99.6700\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 99ms/step - loss: 2199.3940 - MAPE: 99.2076 - val_loss: 2072.3784 - val_MAPE: 99.3002\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 2043.2935 - MAPE: 98.9438 - val_loss: 1920.2661 - val_MAPE: 98.9757\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 1893.2133 - MAPE: 98.7547 - val_loss: 1774.1318 - val_MAPE: 98.6878\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 1748.9343 - MAPE: 98.3810 - val_loss: 1633.9053 - val_MAPE: 98.4256\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 1610.6371 - MAPE: 98.4842 - val_loss: 1499.4052 - val_MAPE: 98.1748\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 1478.0415 - MAPE: 98.2872 - val_loss: 1370.6615 - val_MAPE: 97.9251\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 1351.2557 - MAPE: 98.1702 - val_loss: 1247.8281 - val_MAPE: 97.6728\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 1230.6328 - MAPE: 98.1689 - val_loss: 1131.7712 - val_MAPE: 97.3980\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 1116.6366 - MAPE: 98.3509 - val_loss: 1021.4200 - val_MAPE: 97.1105\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 1008.1313 - MAPE: 98.1647 - val_loss: 916.8488 - val_MAPE: 96.8032\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 108ms/step - loss: 905.6412 - MAPE: 97.9495 - val_loss: 818.3315 - val_MAPE: 96.4854\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 809.2230 - MAPE: 97.9108 - val_loss: 726.0428 - val_MAPE: 96.1590\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 718.9461 - MAPE: 97.7211 - val_loss: 639.6510 - val_MAPE: 95.8245\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 102ms/step - loss: 634.5608 - MAPE: 97.7203 - val_loss: 559.3539 - val_MAPE: 95.4793\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 556.3351 - MAPE: 97.6449 - val_loss: 485.1843 - val_MAPE: 95.1362\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 484.1218 - MAPE: 97.4643 - val_loss: 417.0025 - val_MAPE: 94.7975\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 417.9449 - MAPE: 97.3441 - val_loss: 354.6152 - val_MAPE: 94.4575\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 357.5350 - MAPE: 97.1297 - val_loss: 298.4630 - val_MAPE: 94.1157\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 303.4090 - MAPE: 96.9418 - val_loss: 248.3436 - val_MAPE: 93.7662\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 255.1970 - MAPE: 96.8274 - val_loss: 204.0850 - val_MAPE: 93.4024\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 212.9058 - MAPE: 96.5873 - val_loss: 165.9777 - val_MAPE: 93.0263\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 176.9557 - MAPE: 96.4500 - val_loss: 134.2539 - val_MAPE: 92.6519\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 147.2464 - MAPE: 96.1606 - val_loss: 108.5689 - val_MAPE: 92.2712\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 123.3676 - MAPE: 96.1113 - val_loss: 88.4558 - val_MAPE: 91.8709\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 105.2078 - MAPE: 95.7352 - val_loss: 74.3406 - val_MAPE: 91.4313\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 93.2576 - MAPE: 95.6107 - val_loss: 66.2203 - val_MAPE: 90.9620\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 85.4565 - MAPE: 95.3221 - val_loss: 58.0610 - val_MAPE: 90.4629\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 77.2989 - MAPE: 95.0797 - val_loss: 50.5414 - val_MAPE: 89.9553\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 70.5703 - MAPE: 94.8668 - val_loss: 45.8749 - val_MAPE: 89.4376\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 67.0440 - MAPE: 94.6063 - val_loss: 44.0402 - val_MAPE: 88.9118\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 65.3835 - MAPE: 94.3281 - val_loss: 42.3485 - val_MAPE: 88.3640\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 63.5915 - MAPE: 94.0118 - val_loss: 40.6740 - val_MAPE: 87.7953\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 62.0418 - MAPE: 93.6722 - val_loss: 39.1720 - val_MAPE: 87.2053\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 60.6109 - MAPE: 93.3461 - val_loss: 38.2111 - val_MAPE: 86.5951\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 59.8516 - MAPE: 93.2418 - val_loss: 37.5240 - val_MAPE: 85.9676\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 59.1376 - MAPE: 92.6926 - val_loss: 36.8305 - val_MAPE: 85.3210\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 58.5182 - MAPE: 92.3554 - val_loss: 36.3935 - val_MAPE: 84.6574\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 58.0795 - MAPE: 91.9815 - val_loss: 35.9096 - val_MAPE: 83.9672\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 57.6413 - MAPE: 91.5778 - val_loss: 35.5592 - val_MAPE: 83.2627\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 57.2624 - MAPE: 91.4097 - val_loss: 35.2185 - val_MAPE: 82.5348\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 56.9508 - MAPE: 90.6920 - val_loss: 34.8961 - val_MAPE: 81.7915\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 56.6276 - MAPE: 90.2962 - val_loss: 34.6231 - val_MAPE: 81.0348\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 56.3596 - MAPE: 90.0040 - val_loss: 34.3343 - val_MAPE: 80.2678\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 56.0657 - MAPE: 89.5408 - val_loss: 34.0391 - val_MAPE: 79.4894\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 55.7842 - MAPE: 89.1671 - val_loss: 33.7588 - val_MAPE: 78.6932\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 55.4660 - MAPE: 88.6304 - val_loss: 33.4589 - val_MAPE: 77.8754\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 55.1833 - MAPE: 88.1970 - val_loss: 33.1964 - val_MAPE: 77.0372\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 54.9318 - MAPE: 87.7673 - val_loss: 32.9369 - val_MAPE: 76.1730\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 54.6246 - MAPE: 87.0243 - val_loss: 32.6261 - val_MAPE: 75.2930\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 54.2980 - MAPE: 86.4256 - val_loss: 32.3087 - val_MAPE: 74.3915\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 53.9765 - MAPE: 86.1213 - val_loss: 32.0312 - val_MAPE: 73.4817\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 53.6644 - MAPE: 85.5315 - val_loss: 31.6758 - val_MAPE: 72.5666\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 53.3329 - MAPE: 84.8407 - val_loss: 31.3528 - val_MAPE: 71.6389\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 52.9928 - MAPE: 84.5516 - val_loss: 31.0637 - val_MAPE: 70.6916\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 52.7073 - MAPE: 84.0037 - val_loss: 30.7029 - val_MAPE: 69.7326\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 52.3521 - MAPE: 83.3592 - val_loss: 30.3735 - val_MAPE: 68.7571\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 52.0184 - MAPE: 82.4622 - val_loss: 30.0646 - val_MAPE: 67.7744\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 51.6151 - MAPE: 82.2272 - val_loss: 29.6854 - val_MAPE: 66.7883\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 51.2844 - MAPE: 81.8191 - val_loss: 29.3288 - val_MAPE: 65.7996\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 96ms/step - loss: 50.8381 - MAPE: 81.3949 - val_loss: 28.9842 - val_MAPE: 64.8038\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 50.4919 - MAPE: 80.5984 - val_loss: 28.5981 - val_MAPE: 63.8076\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 50.1133 - MAPE: 80.1506 - val_loss: 28.2086 - val_MAPE: 62.8011\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 49.6828 - MAPE: 79.0360 - val_loss: 27.8396 - val_MAPE: 61.8073\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 49.2524 - MAPE: 78.2626 - val_loss: 27.4651 - val_MAPE: 60.8033\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 48.8870 - MAPE: 77.8844 - val_loss: 27.0765 - val_MAPE: 59.7998\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 48.4693 - MAPE: 77.1284 - val_loss: 26.6980 - val_MAPE: 58.7920\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 48.0389 - MAPE: 76.2972 - val_loss: 26.2912 - val_MAPE: 57.7905\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 47.5532 - MAPE: 76.1460 - val_loss: 25.8877 - val_MAPE: 56.8103\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 47.1546 - MAPE: 74.3006 - val_loss: 25.4753 - val_MAPE: 55.8415\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 101ms/step - loss: 46.6481 - MAPE: 73.9055 - val_loss: 25.0691 - val_MAPE: 54.8920\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 46.1783 - MAPE: 73.3536 - val_loss: 24.6545 - val_MAPE: 53.9529\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 103ms/step - loss: 45.7243 - MAPE: 71.8932 - val_loss: 24.2511 - val_MAPE: 53.0348\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 45.2647 - MAPE: 71.9921 - val_loss: 23.8389 - val_MAPE: 52.1266\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 44.7612 - MAPE: 71.6764 - val_loss: 23.4418 - val_MAPE: 51.2343\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 102ms/step - loss: 44.3328 - MAPE: 70.8911 - val_loss: 23.0515 - val_MAPE: 50.3533\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 43.8195 - MAPE: 69.2191 - val_loss: 22.6027 - val_MAPE: 49.5063\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 110ms/step - loss: 43.3195 - MAPE: 68.5830 - val_loss: 22.1779 - val_MAPE: 48.6810\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 42.8454 - MAPE: 67.3169 - val_loss: 21.7952 - val_MAPE: 47.8751\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 0s 109ms/step - loss: 42.3722 - MAPE: 66.7351 - val_loss: 21.4054 - val_MAPE: 47.1062\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 41.8458 - MAPE: 66.1223 - val_loss: 20.9735 - val_MAPE: 46.3861\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 99ms/step - loss: 41.2872 - MAPE: 67.2034 - val_loss: 20.5829 - val_MAPE: 45.7022\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 100ms/step - loss: 40.7530 - MAPE: 64.0700 - val_loss: 20.1794 - val_MAPE: 45.0491\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 40.2697 - MAPE: 63.6177 - val_loss: 19.8060 - val_MAPE: 44.4307\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 99ms/step - loss: 39.7965 - MAPE: 62.7548 - val_loss: 19.4524 - val_MAPE: 43.8499\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 98ms/step - loss: 39.2625 - MAPE: 61.8676 - val_loss: 19.0681 - val_MAPE: 43.3128\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 111ms/step - loss: 38.7156 - MAPE: 61.2312 - val_loss: 18.6883 - val_MAPE: 42.8096\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 107ms/step - loss: 38.1349 - MAPE: 60.6650 - val_loss: 18.3723 - val_MAPE: 42.3706\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 112ms/step - loss: 37.6446 - MAPE: 60.6070 - val_loss: 18.0148 - val_MAPE: 41.9905\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 110ms/step - loss: 37.1455 - MAPE: 59.7977 - val_loss: 17.6306 - val_MAPE: 41.6775\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 104ms/step - loss: 36.5901 - MAPE: 57.3449 - val_loss: 17.3491 - val_MAPE: 41.4389\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 101ms/step - loss: 36.0132 - MAPE: 57.4680 - val_loss: 17.0463 - val_MAPE: 41.2731\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 109ms/step - loss: 35.4711 - MAPE: 56.8420 - val_loss: 16.7897 - val_MAPE: 41.1870\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 101ms/step - loss: 35.0287 - MAPE: 56.7273 - val_loss: 16.5770 - val_MAPE: 41.1788\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 34.4528 - MAPE: 56.7084 - val_loss: 16.3296 - val_MAPE: 41.2555\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s 99ms/step - loss: 34.0179 - MAPE: 55.0572 - val_loss: 16.1079 - val_MAPE: 41.4030\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 98ms/step - loss: 33.4417 - MAPE: 54.5309 - val_loss: 15.9427 - val_MAPE: 41.6154\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 99ms/step - loss: 33.0139 - MAPE: 53.7295 - val_loss: 15.7722 - val_MAPE: 41.9236\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 32.4909 - MAPE: 53.1394 - val_loss: 15.5873 - val_MAPE: 42.3062\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 31.8857 - MAPE: 52.4532 - val_loss: 15.5152 - val_MAPE: 42.7513\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 31.5689 - MAPE: 50.7270 - val_loss: 15.4028 - val_MAPE: 43.2538\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s 93ms/step - loss: 31.0200 - MAPE: 52.1089 - val_loss: 15.3370 - val_MAPE: 43.8172\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 0s 94ms/step - loss: 30.6218 - MAPE: 50.6093 - val_loss: 15.2963 - val_MAPE: 44.4408\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s 97ms/step - loss: 30.1660 - MAPE: 48.5617 - val_loss: 15.2438 - val_MAPE: 45.1244\n",
      "train r2: -3.798560230924428\n",
      "train r2: 0.0023237040319962713\n",
      "val r2: -0.26172456004227174\n",
      "val r2: 0.001139147004360362\n"
     ]
    }
   ],
   "source": [
    "# Loss Metric to optimize\n",
    "metric = tf.keras.metrics.MeanAbsolutePercentageError(name='MAPE')\n",
    "\n",
    "# Create early stopping point\n",
    "callback = keras.callbacks.EarlyStopping(\n",
    "    patience=10,\n",
    "    monitor='val_'+metric.name,\n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "bm.compile(loss=tf.keras.metrics.mean_absolute_error, \n",
    "           optimizer=keras.optimizers.Adam(),\n",
    "           metrics=metric)\n",
    "\n",
    "# Fit the model\n",
    "history = bm.fit(x= X_train,\n",
    "                 y=y_train,\n",
    "                 epochs = 200,\n",
    "                 callbacks=[callback],\n",
    "                 batch_size=512,\n",
    "                 validation_data=(X_val, y_val),\n",
    ")\n",
    "\n",
    "preds_train = bm.predict(X_train).flatten()\n",
    "preds_val = bm.predict(X_val).flatten()\n",
    "\n",
    "print('train r2:',r2_score(y_train.flatten(), preds_train))\n",
    "print('train r2:',(np.corrcoef(y_train.flatten(), preds_train)**2)[0][1])\n",
    "\n",
    "print('val r2:',r2_score(y_val.flatten(), preds_val))\n",
    "print('val r2:',(np.corrcoef(y_val.flatten(), preds_val)**2)[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 45.4839 - MAPE: 91.9167 - val_loss: 14.1024 - val_MAPE: 66.8014\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 33.7040 - MAPE: 79.5775 - val_loss: 11.1353 - val_MAPE: 52.1070\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 29.3823 - MAPE: 66.4293 - val_loss: 10.0158 - val_MAPE: 47.2930\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 27.3341 - MAPE: 62.4996 - val_loss: 9.8122 - val_MAPE: 45.6371\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 25.9432 - MAPE: 55.5520 - val_loss: 9.7036 - val_MAPE: 45.2370\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 25.4551 - MAPE: 56.4819 - val_loss: 9.4428 - val_MAPE: 42.3645\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 24.9479 - MAPE: 53.2063 - val_loss: 9.4181 - val_MAPE: 42.3927\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 24.3422 - MAPE: 52.0987 - val_loss: 9.3754 - val_MAPE: 42.5363\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 24.0473 - MAPE: 51.0788 - val_loss: 9.2533 - val_MAPE: 40.9980\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 23.6397 - MAPE: 50.6882 - val_loss: 9.2193 - val_MAPE: 40.3316\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 23.2921 - MAPE: 49.9936 - val_loss: 9.2629 - val_MAPE: 41.8958\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 23.0707 - MAPE: 46.5365 - val_loss: 9.1623 - val_MAPE: 40.4954\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 22.8354 - MAPE: 46.6125 - val_loss: 9.1190 - val_MAPE: 39.7095\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 22.3515 - MAPE: 45.7213 - val_loss: 9.0785 - val_MAPE: 39.2843\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 22.3956 - MAPE: 48.1304 - val_loss: 9.0428 - val_MAPE: 39.1185\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 22.1809 - MAPE: 46.0905 - val_loss: 9.0216 - val_MAPE: 38.5208\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 21.9118 - MAPE: 44.6431 - val_loss: 9.0170 - val_MAPE: 40.2121\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 21.7377 - MAPE: 46.2671 - val_loss: 9.0063 - val_MAPE: 39.5202\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 21.7625 - MAPE: 43.9639 - val_loss: 8.9208 - val_MAPE: 38.6830\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 21.5076 - MAPE: 42.9237 - val_loss: 8.8986 - val_MAPE: 38.6378\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 21.3242 - MAPE: 44.0305 - val_loss: 8.8690 - val_MAPE: 38.7422\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 21.3454 - MAPE: 42.4029 - val_loss: 8.8659 - val_MAPE: 38.0820\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 20.9969 - MAPE: 42.1361 - val_loss: 8.9083 - val_MAPE: 37.5172\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 21.0572 - MAPE: 43.6731 - val_loss: 8.8250 - val_MAPE: 37.8923\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 20.8666 - MAPE: 41.5298 - val_loss: 8.8288 - val_MAPE: 38.5777\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 20.7811 - MAPE: 42.1265 - val_loss: 8.7830 - val_MAPE: 38.1982\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 20.6739 - MAPE: 41.4457 - val_loss: 8.7718 - val_MAPE: 36.8796\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 20.6952 - MAPE: 42.0688 - val_loss: 8.7443 - val_MAPE: 36.9349\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 20.3558 - MAPE: 40.6507 - val_loss: 8.8324 - val_MAPE: 36.2733\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 20.3514 - MAPE: 40.5410 - val_loss: 8.7840 - val_MAPE: 35.9863\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 20.2374 - MAPE: 40.1925 - val_loss: 8.6909 - val_MAPE: 36.3489\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 20.2333 - MAPE: 39.8813 - val_loss: 8.6420 - val_MAPE: 36.6056\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 20.1378 - MAPE: 39.6157 - val_loss: 8.5957 - val_MAPE: 36.6552\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 20.1125 - MAPE: 39.8018 - val_loss: 8.5850 - val_MAPE: 36.9059\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 19.9909 - MAPE: 39.3319 - val_loss: 8.5770 - val_MAPE: 35.9629\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 20.0022 - MAPE: 39.7829 - val_loss: 8.6040 - val_MAPE: 35.2682\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 19.8526 - MAPE: 38.9964 - val_loss: 8.5531 - val_MAPE: 35.3803\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 19.8400 - MAPE: 39.3522 - val_loss: 8.6589 - val_MAPE: 34.7255\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 19.7754 - MAPE: 38.7735 - val_loss: 8.6974 - val_MAPE: 34.7072\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 19.6844 - MAPE: 38.4480 - val_loss: 8.5807 - val_MAPE: 34.8082\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 19.6017 - MAPE: 39.4322 - val_loss: 8.5335 - val_MAPE: 35.0207\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 19.4891 - MAPE: 38.2527 - val_loss: 8.4842 - val_MAPE: 34.6113\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 19.4479 - MAPE: 38.7884 - val_loss: 8.4638 - val_MAPE: 35.0119\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 19.4746 - MAPE: 38.3143 - val_loss: 8.4718 - val_MAPE: 34.8330\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 19.2792 - MAPE: 38.3545 - val_loss: 8.5121 - val_MAPE: 34.3161\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 19.2484 - MAPE: 38.0443 - val_loss: 8.5863 - val_MAPE: 33.9277\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 19.1521 - MAPE: 37.4525 - val_loss: 8.4140 - val_MAPE: 34.2565\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 19.1177 - MAPE: 37.4676 - val_loss: 8.4995 - val_MAPE: 33.7899\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 19.1438 - MAPE: 37.7525 - val_loss: 8.3766 - val_MAPE: 33.8194\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 18.9886 - MAPE: 37.4557 - val_loss: 8.2952 - val_MAPE: 33.9716\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 19.0681 - MAPE: 37.7154 - val_loss: 8.4804 - val_MAPE: 33.5882\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 18.9513 - MAPE: 37.5494 - val_loss: 8.4582 - val_MAPE: 33.5547\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 18.8805 - MAPE: 37.4023 - val_loss: 8.3575 - val_MAPE: 33.4285\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 18.9249 - MAPE: 37.2534 - val_loss: 8.2476 - val_MAPE: 33.6547\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 18.9120 - MAPE: 37.8716 - val_loss: 8.2982 - val_MAPE: 33.5370\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 18.8576 - MAPE: 37.2636 - val_loss: 8.3283 - val_MAPE: 33.0091\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 18.7524 - MAPE: 36.8340 - val_loss: 8.3108 - val_MAPE: 33.3630\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 18.7709 - MAPE: 37.5859 - val_loss: 8.2463 - val_MAPE: 33.3528\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 18.7797 - MAPE: 37.2460 - val_loss: 8.6045 - val_MAPE: 33.0218\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 18.5755 - MAPE: 36.9172 - val_loss: 8.5266 - val_MAPE: 32.8886\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 18.6008 - MAPE: 36.5179 - val_loss: 8.1034 - val_MAPE: 33.0864\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 18.6852 - MAPE: 37.0578 - val_loss: 8.3589 - val_MAPE: 32.6310\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 18.5311 - MAPE: 36.3787 - val_loss: 8.5077 - val_MAPE: 32.6189\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 18.5476 - MAPE: 36.5327 - val_loss: 8.3984 - val_MAPE: 32.9950\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 18.5580 - MAPE: 36.6507 - val_loss: 7.9578 - val_MAPE: 33.0020\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 18.4697 - MAPE: 36.5952 - val_loss: 8.1333 - val_MAPE: 32.7666\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 18.4045 - MAPE: 36.4965 - val_loss: 7.9441 - val_MAPE: 32.7988\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 18.3543 - MAPE: 36.5069 - val_loss: 8.0991 - val_MAPE: 32.7114\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 18.3464 - MAPE: 36.4945 - val_loss: 7.8694 - val_MAPE: 32.7246\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 18.2138 - MAPE: 36.0222 - val_loss: 8.0624 - val_MAPE: 32.3888\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 18.2502 - MAPE: 36.6249 - val_loss: 7.8695 - val_MAPE: 32.8269\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 18.1688 - MAPE: 36.2928 - val_loss: 7.7560 - val_MAPE: 32.8123\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 18.2410 - MAPE: 36.4444 - val_loss: 8.2014 - val_MAPE: 32.3137\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 18.2033 - MAPE: 36.3074 - val_loss: 8.2645 - val_MAPE: 32.2400\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 18.1750 - MAPE: 36.5138 - val_loss: 8.2422 - val_MAPE: 32.2745\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 18.1855 - MAPE: 35.6706 - val_loss: 8.2020 - val_MAPE: 32.1751\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 18.2600 - MAPE: 36.3906 - val_loss: 7.9891 - val_MAPE: 32.3484\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 18.0267 - MAPE: 35.8398 - val_loss: 8.1301 - val_MAPE: 32.1363\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 17.9469 - MAPE: 35.5857 - val_loss: 8.3243 - val_MAPE: 31.8383\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 18.0443 - MAPE: 35.8290 - val_loss: 8.0765 - val_MAPE: 31.6829\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 17.8908 - MAPE: 35.6668 - val_loss: 7.7388 - val_MAPE: 32.1153\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 17.9460 - MAPE: 35.9380 - val_loss: 7.6684 - val_MAPE: 31.9590\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 17.8359 - MAPE: 35.9512 - val_loss: 7.7792 - val_MAPE: 31.9658\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 17.9721 - MAPE: 35.6439 - val_loss: 7.6486 - val_MAPE: 31.7528\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 17.7749 - MAPE: 35.6758 - val_loss: 7.7249 - val_MAPE: 31.9330\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 17.7206 - MAPE: 35.6135 - val_loss: 7.6885 - val_MAPE: 31.8242\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 17.7115 - MAPE: 35.7434 - val_loss: 7.5279 - val_MAPE: 31.8900\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 17.6427 - MAPE: 35.6455 - val_loss: 7.7854 - val_MAPE: 31.7369\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 17.5177 - MAPE: 35.2903 - val_loss: 7.8251 - val_MAPE: 31.8169\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 17.5483 - MAPE: 35.4319 - val_loss: 7.4370 - val_MAPE: 31.6514\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 17.5670 - MAPE: 35.7224 - val_loss: 7.4067 - val_MAPE: 31.7734\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 17.5235 - MAPE: 35.6095 - val_loss: 7.2520 - val_MAPE: 31.8806\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 17.5627 - MAPE: 35.4442 - val_loss: 7.3330 - val_MAPE: 31.6100\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 17.5064 - MAPE: 35.5763 - val_loss: 7.6556 - val_MAPE: 31.3353\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 17.4801 - MAPE: 35.4719 - val_loss: 7.3190 - val_MAPE: 32.2328\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 17.4845 - MAPE: 35.3909 - val_loss: 7.4410 - val_MAPE: 31.2997\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 17.4585 - MAPE: 35.9041 - val_loss: 7.2267 - val_MAPE: 31.6369\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 17.5199 - MAPE: 35.5587 - val_loss: 7.0610 - val_MAPE: 32.7466\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 17.2687 - MAPE: 35.7612 - val_loss: 7.1998 - val_MAPE: 31.7047\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 17.4063 - MAPE: 35.2550 - val_loss: 7.1500 - val_MAPE: 31.8188\n",
      "train r2: 0.4610921866254599\n",
      "train r2: 0.5979128031454339\n",
      "val r2: 0.353535359011678\n",
      "val r2: 0.3696322500886179\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model and build layers\n",
    "bm = models.Sequential()\n",
    "bm.add(layers.Dense(239, activation='relu', input_shape=input_shape, kernel_regularizer=regularizers.l1(0)))\n",
    "bm.add(layers.Dropout(.9))\n",
    "bm.add(layers.Dense(162, activation='relu', kernel_regularizer=regularizers.l1(0)))\n",
    "bm.add(layers.Dropout(.9))\n",
    "bm.add(TimeDistributed(layers.Dense(1)))\n",
    "\n",
    "# Loss Metric to optimize\n",
    "metric = tf.keras.metrics.MeanAbsolutePercentageError(name='MAPE')\n",
    "\n",
    "# Create early stopping point\n",
    "callback = keras.callbacks.EarlyStopping(\n",
    "    patience=10,\n",
    "    monitor='val_'+metric.name,\n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "bm.compile(loss=tf.keras.metrics.mean_absolute_error, \n",
    "           optimizer=keras.optimizers.Adam(),\n",
    "           metrics=metric)\n",
    "\n",
    "# Fit the model\n",
    "history = bm.fit(x= X_train,\n",
    "                 y=y_train,\n",
    "                 epochs = 100,\n",
    "                 callbacks=[callback],\n",
    "                 batch_size=128,\n",
    "                 validation_data=(X_val, y_val),\n",
    ")\n",
    "\n",
    "preds_train = bm.predict(X_train).flatten()\n",
    "preds_val = bm.predict(X_val).flatten()\n",
    "\n",
    "print('train r2:',r2_score(y_train.flatten(), preds_train))\n",
    "print('train r2:',(np.corrcoef(y_train.flatten(), preds_train)**2)[0][1])\n",
    "\n",
    "print('val r2:',r2_score(y_val.flatten(), preds_val))\n",
    "print('val r2:',(np.corrcoef(y_val.flatten(), preds_val)**2)[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 46.8585 - MAPE: 90.4892 - val_loss: 17.5185 - val_MAPE: 67.1698\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 36.7941 - MAPE: 79.6642 - val_loss: 13.9950 - val_MAPE: 47.4856\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 32.5062 - MAPE: 66.7438 - val_loss: 13.3872 - val_MAPE: 48.3413\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 30.4398 - MAPE: 60.3333 - val_loss: 12.8435 - val_MAPE: 44.3023\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 28.9885 - MAPE: 53.8950 - val_loss: 12.7383 - val_MAPE: 45.2990\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 28.0770 - MAPE: 54.0073 - val_loss: 12.3631 - val_MAPE: 42.5779\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 27.3943 - MAPE: 52.5591 - val_loss: 12.2777 - val_MAPE: 43.1760\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 1s 37ms/step - loss: 26.8713 - MAPE: 49.6120 - val_loss: 12.1268 - val_MAPE: 42.0520\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 26.4406 - MAPE: 50.0308 - val_loss: 12.0917 - val_MAPE: 42.5025\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 25.8199 - MAPE: 51.5100 - val_loss: 12.0949 - val_MAPE: 43.1972\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 25.4520 - MAPE: 50.1542 - val_loss: 11.8539 - val_MAPE: 41.2658\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 25.2384 - MAPE: 47.5307 - val_loss: 11.8252 - val_MAPE: 41.5656\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 24.6753 - MAPE: 45.7127 - val_loss: 11.8169 - val_MAPE: 41.9496\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 24.5108 - MAPE: 46.0155 - val_loss: 11.8391 - val_MAPE: 42.5885\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 24.3157 - MAPE: 46.8670 - val_loss: 11.7782 - val_MAPE: 42.4243\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 23.9825 - MAPE: 44.6938 - val_loss: 11.6753 - val_MAPE: 41.6844\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 23.6821 - MAPE: 44.1249 - val_loss: 11.5649 - val_MAPE: 40.5917\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 23.4603 - MAPE: 43.3977 - val_loss: 11.4548 - val_MAPE: 40.0415\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 23.2167 - MAPE: 44.3024 - val_loss: 11.4355 - val_MAPE: 40.6646\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 1s 32ms/step - loss: 23.0283 - MAPE: 42.2585 - val_loss: 11.3685 - val_MAPE: 40.5959\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 22.9126 - MAPE: 41.8642 - val_loss: 11.3311 - val_MAPE: 40.6177\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 22.6122 - MAPE: 41.0221 - val_loss: 11.2637 - val_MAPE: 39.8533\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 22.4158 - MAPE: 42.7012 - val_loss: 11.1475 - val_MAPE: 39.2528\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 22.2767 - MAPE: 41.8864 - val_loss: 11.0885 - val_MAPE: 38.0643\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 22.0394 - MAPE: 40.4060 - val_loss: 11.1012 - val_MAPE: 40.0724\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 21.9976 - MAPE: 40.0452 - val_loss: 10.9727 - val_MAPE: 39.5755\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 21.7782 - MAPE: 39.7691 - val_loss: 10.8323 - val_MAPE: 38.1905\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 21.6059 - MAPE: 39.1647 - val_loss: 10.7318 - val_MAPE: 37.7934\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 21.6026 - MAPE: 39.2336 - val_loss: 10.6472 - val_MAPE: 37.4700\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 21.5648 - MAPE: 40.3317 - val_loss: 10.6320 - val_MAPE: 38.3403\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 21.4654 - MAPE: 40.5226 - val_loss: 10.5256 - val_MAPE: 37.2975\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 1s 33ms/step - loss: 21.2257 - MAPE: 38.3845 - val_loss: 10.4716 - val_MAPE: 36.6790\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 21.2068 - MAPE: 38.7801 - val_loss: 10.4532 - val_MAPE: 35.9604\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 20.8609 - MAPE: 38.3634 - val_loss: 10.3342 - val_MAPE: 35.9680\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 20.9420 - MAPE: 38.6888 - val_loss: 10.2864 - val_MAPE: 36.3373\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 20.7632 - MAPE: 38.2931 - val_loss: 10.1736 - val_MAPE: 35.5457\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 20.6980 - MAPE: 37.8806 - val_loss: 10.1388 - val_MAPE: 36.5768\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 20.3912 - MAPE: 37.7008 - val_loss: 10.0505 - val_MAPE: 35.3015\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 20.4018 - MAPE: 37.5925 - val_loss: 10.0090 - val_MAPE: 34.9178\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 20.3237 - MAPE: 37.6566 - val_loss: 9.8850 - val_MAPE: 35.3036\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 20.1901 - MAPE: 37.4577 - val_loss: 9.8413 - val_MAPE: 35.9091\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 20.0246 - MAPE: 37.7131 - val_loss: 9.8514 - val_MAPE: 34.7337\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 19.9137 - MAPE: 36.7482 - val_loss: 9.8767 - val_MAPE: 34.1464\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 19.8612 - MAPE: 36.8493 - val_loss: 9.8456 - val_MAPE: 33.9662\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 19.8848 - MAPE: 37.1028 - val_loss: 9.6822 - val_MAPE: 34.0572\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 19.6033 - MAPE: 36.6189 - val_loss: 9.6171 - val_MAPE: 34.4817\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 19.5054 - MAPE: 36.4242 - val_loss: 9.4383 - val_MAPE: 34.2507\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 19.3983 - MAPE: 36.0171 - val_loss: 9.3938 - val_MAPE: 34.4396\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 19.3778 - MAPE: 36.7130 - val_loss: 9.3176 - val_MAPE: 34.2469\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 19.2108 - MAPE: 36.0077 - val_loss: 9.4776 - val_MAPE: 33.2315\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 19.2557 - MAPE: 36.2149 - val_loss: 9.2172 - val_MAPE: 34.0222\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 19.0724 - MAPE: 37.6366 - val_loss: 9.1762 - val_MAPE: 35.0906\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 18.9517 - MAPE: 35.5982 - val_loss: 9.2054 - val_MAPE: 33.4425\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 18.9457 - MAPE: 36.2887 - val_loss: 9.2993 - val_MAPE: 32.8170\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 18.8230 - MAPE: 36.1336 - val_loss: 9.0407 - val_MAPE: 33.1689\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 18.6749 - MAPE: 35.8504 - val_loss: 9.1151 - val_MAPE: 32.9470\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 18.7349 - MAPE: 36.5722 - val_loss: 8.8462 - val_MAPE: 33.5661\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 18.4936 - MAPE: 35.2042 - val_loss: 8.8058 - val_MAPE: 34.0467\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 18.4369 - MAPE: 36.0447 - val_loss: 8.8421 - val_MAPE: 32.8735\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 18.3069 - MAPE: 35.3579 - val_loss: 8.7690 - val_MAPE: 32.8914\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 18.3334 - MAPE: 35.4016 - val_loss: 8.8897 - val_MAPE: 32.7688\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 18.3135 - MAPE: 35.1414 - val_loss: 8.5723 - val_MAPE: 32.9527\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 18.1084 - MAPE: 35.8728 - val_loss: 8.4773 - val_MAPE: 32.9152\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 34ms/step - loss: 18.0752 - MAPE: 35.8489 - val_loss: 8.4673 - val_MAPE: 33.3615\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 18.0607 - MAPE: 35.2130 - val_loss: 8.3936 - val_MAPE: 33.0119\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 17.9383 - MAPE: 35.7968 - val_loss: 8.3814 - val_MAPE: 32.5619\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 17.8687 - MAPE: 35.1157 - val_loss: 8.2518 - val_MAPE: 33.1781\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 17.7131 - MAPE: 35.4420 - val_loss: 8.4944 - val_MAPE: 32.3860\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 17.6829 - MAPE: 35.7597 - val_loss: 8.2107 - val_MAPE: 34.5354\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 1s 33ms/step - loss: 17.5788 - MAPE: 35.2279 - val_loss: 8.3350 - val_MAPE: 32.1661\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 17.6899 - MAPE: 35.6847 - val_loss: 8.1076 - val_MAPE: 32.9836\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 17.4741 - MAPE: 35.4262 - val_loss: 8.0580 - val_MAPE: 33.0912\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 17.4704 - MAPE: 35.0676 - val_loss: 8.0116 - val_MAPE: 33.6608\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 17.3831 - MAPE: 35.6198 - val_loss: 7.9612 - val_MAPE: 34.0324\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 17.2468 - MAPE: 34.8990 - val_loss: 7.9839 - val_MAPE: 32.9814\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 17.1634 - MAPE: 34.6106 - val_loss: 7.9744 - val_MAPE: 33.1294\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 17.0217 - MAPE: 34.6463 - val_loss: 7.9142 - val_MAPE: 33.2601\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 17.0436 - MAPE: 34.8329 - val_loss: 7.9117 - val_MAPE: 33.1419\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 16.9383 - MAPE: 34.8096 - val_loss: 7.8790 - val_MAPE: 34.5030\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 16.8202 - MAPE: 34.9099 - val_loss: 7.8428 - val_MAPE: 33.8084\n",
      "train r2: 0.3598204798881486\n",
      "train r2: 0.5818973967622155\n",
      "val r2: 0.33874439352623664\n",
      "val r2: 0.36775351892582664\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model and build layers\n",
    "bm = models.Sequential()\n",
    "bm.add(layers.Dense(239, activation='relu', input_shape=input_shape, kernel_regularizer=regularizers.l1(0.001)))\n",
    "bm.add(layers.Dropout(.9))\n",
    "bm.add(layers.Dense(162, activation='relu', kernel_regularizer=regularizers.l1(0.001)))\n",
    "bm.add(layers.Dropout(.9))\n",
    "bm.add(TimeDistributed(layers.Dense(1)))\n",
    "\n",
    "# Loss Metric to optimize\n",
    "metric = tf.keras.metrics.MeanAbsolutePercentageError(name='MAPE')\n",
    "\n",
    "# Create early stopping point\n",
    "callback = keras.callbacks.EarlyStopping(\n",
    "    patience=10,\n",
    "    monitor='val_'+metric.name,\n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "bm.compile(loss=tf.keras.metrics.mean_absolute_error, \n",
    "           optimizer=keras.optimizers.Adam(),\n",
    "           metrics=metric)\n",
    "\n",
    "# Fit the model\n",
    "history = bm.fit(x= X_train,\n",
    "                 y=y_train,\n",
    "                 epochs = 100,\n",
    "                 callbacks=[callback],\n",
    "                 batch_size=128,\n",
    "                 validation_data=(X_val, y_val),\n",
    ")\n",
    "\n",
    "preds_train = bm.predict(X_train).flatten()\n",
    "preds_val = bm.predict(X_val).flatten()\n",
    "\n",
    "print('train r2:',r2_score(y_train.flatten(), preds_train))\n",
    "print('train r2:',(np.corrcoef(y_train.flatten(), preds_train)**2)[0][1])\n",
    "\n",
    "print('val r2:',r2_score(y_val.flatten(), preds_val))\n",
    "print('val r2:',(np.corrcoef(y_val.flatten(), preds_val)**2)[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limit Price Spikes\n",
    "Limit price spikes to +- 3*STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAWwElEQVR4nO3df5BdZX3H8fenwaaRlV+COzGJ3TgTaEmisdmhtFZ6t2CJyBjs1DYZlKTQrjI4YpuZkogz0jqZYarRapHYSChQaFYGRFIgaqTuYGeIuLEpmwCRhUTcJE1UMLDIRDd++8c9C5fl7t3dc+/u/fF8XjN39pznnOec5zt79nzv85wfq4jAzMzS8xv1boCZmdWHE4CZWaKcAMzMEuUEYGaWKCcAM7NEnVDvBozn9NNPj46Ojlx1X3zxRU488cTaNqiOHE9jczyNrdXigcox7dy586cRcUal+g2fADo6Oujr68tVt7e3l0KhUNsG1ZHjaWyOp7G1WjxQOSZJPxqvvoeAzMwS5QRgZpYoJwAzs0Q5AZiZJcoJwMwsUU4AZmaJcgIwM0uUE4CZWaKcAMzMEtXwTwKb1UPH2vtfnt5//Xvr2BKzqTNuD0DSzZKOSNpdUvZVSbuyz35Ju7LyDkkvlSz7ckmdpZL6JQ1I+qIkTUlEZmY2IRPpAdwC3ADcNlIQEX85Mi1pA3C0ZP2nImJJme1sBLqBHcADwDJg26RbbGZmNTFuDyAiHgKeLbcs+xb/F8CWStuQNBs4KSIejuI/Ib4NuGTSrTUzs5rRRP4pvKQO4L6IWDSq/DzgcxHRWbLeHuCHwPPAJyPiu5I6gesj4oJsvXcB10TExWPsr5tib4H29valPT09uYIbGhqira0tV91G5HimT/+BVzq1i+ecPKE6jRxPHo6n8VWKqaura+fIuXks1V4EXsmrv/0fAt4SET+TtBT4uqSFQLnx/jEzT0RsAjYBdHZ2Rt5XuLba618dz/RZXXoR+NLChOo0cjx5OJ7GV21MuROApBOAPwOWjpRFxDHgWDa9U9JTwJnAIDC3pPpc4GDefZuZWfWqeQ7gAuCJiBgcKZB0hqQZ2fRbgQXA0xFxCHhB0rnZdYPLgHur2LeZmVVpIreBbgEeBs6SNCjpimzRCl578fc84FFJ/wvcBXwkIkYuIF8J3AQMAE/hO4DMzOpq3CGgiFg5RvnqMmV3A3ePsX4fsKjcMjMzm35+FYSZWaL8Kgizcfi1ENaq3AMwM0uUE4CZWaKcAMzMEuUEYGaWKCcAM7NEOQGYmSXKCcDMLFFOAGZmiXICMDNLlJ8ENsuUPvFrlgL3AMzMEuUEYGaWKCcAM7NEOQGYmSXKCcDMLFFOAGZmifJtoJa0yd766X8OY63EPQAzs0SN2wOQdDNwMXAkIhZlZdcBfwP8JFvtExHxQLZsHXAFcBz4WER8MytfCtwCzAIeAK6OiKhlMGYT4Qe+zIom0gO4BVhWpvzzEbEk+4yc/M8GVgALszo3SpqRrb8R6AYWZJ9y2zQzs2kybgKIiIeAZye4veVAT0Qci4h9wABwjqTZwEkR8XD2rf824JKcbTYzsxqo5iLwRyVdBvQBayLiOWAOsKNkncGs7FfZ9OjysiR1U+wt0N7eTm9vb64GDg0N5a7biBxPbaxZPFyT7Yxuu38/ja3V4oHqY8qbADYCnwYi+7kBuBxQmXWjQnlZEbEJ2ATQ2dkZhUIhVyN7e3vJW7cROZ7aWF2jawD7Ly28at6/n8bWavFA9THlSgARcXhkWtJXgPuy2UFgXsmqc4GDWfncMuVmU8a3bJpVlus20GxMf8T7gd3Z9FZghaSZkuZTvNj7SEQcAl6QdK4kAZcB91bRbjMzq9JEbgPdAhSA0yUNAp8CCpKWUBzG2Q98GCAi9ki6E3gMGAauiojj2aau5JXbQLdlHzMzq5NxE0BErCxTvLnC+uuB9WXK+4BFk2qdWY1Mxb3/HmKyZucngc3MEuUEYGaWKCcAM7NEOQGYmSXKCcDMLFFOAGZmiXICMDNLlBOAmVmi/C8hraX4n72YTZx7AGZmiXICMDNLlBOAmVminADMzBLlBGBmlignADOzRDkBmJklygnAzCxRTgBmZolyAjAzS5QTgJlZosZNAJJulnRE0u6Sss9IekLSo5LukXRKVt4h6SVJu7LPl0vqLJXUL2lA0hclaUoiMquDjrX303/gqN9FZE1lIj2AW4Blo8q2A4si4m3AD4F1Jcueiogl2ecjJeUbgW5gQfYZvU0zM5tG4yaAiHgIeHZU2bciYjib3QHMrbQNSbOBkyLi4YgI4DbgklwtNjOzmlDxfDzOSlIHcF9ELCqz7D+Br0bE7dl6eyj2Cp4HPhkR35XUCVwfERdkdd4FXBMRF4+xv26KvQXa29uX9vT05ImNoaEh2tractVtRI5nfP0HjtZ0e5PRPgsOvwSL55xctzbUko+3xlcppq6urp0R0VmpflX/D0DStcAwcEdWdAh4S0T8TNJS4OuSFgLlxvvHzDwRsQnYBNDZ2RmFQiFX+3p7e8lbtxE5nvGtruMY/JrFw2zoP4H9lxbq1oZa8vHW+KqNKXcCkLQKuBg4PxvWISKOAcey6Z2SngLOBAZ59TDRXOBg3n2bmVn1ciUAScuAa4A/johflJSfATwbEcclvZXixd6nI+JZSS9IOhf4HnAZ8C/VN9/M/wXMLK9xE4CkLUABOF3SIPApinf9zAS2Z3dz7sju+DkP+EdJw8Bx4CMRMXIB+UqKdxTNArZlHzMzq5NxE0BErCxTvHmMde8G7h5jWR/wmovIZmZWH34S2MwsUU4AZmaJcgIwM0uUE4CZWaKcAMzMElXVk8Bm9eJ7/82q5x6AmVminADMzBLlBGBmlignADOzRDkBmJklygnAzCxRvg3UrMZKb1Hdf/17674ds7E4AVjT8L3/ZrXlISAzs0S5B2A2TTykY43GPQAzs0Q5AZiZJcoJwMwsUb4GYNZAxrrTaXS5ryFYLYzbA5B0s6QjknaXlJ0mabukJ7Ofp5YsWydpQNJeSReWlC+V1J8t+6Ik1T4cMzObqIkMAd0CLBtVthZ4MCIWAA9m80g6G1gBLMzq3ChpRlZnI9ANLMg+o7dpZmbTaNwhoIh4SFLHqOLlQCGbvhXoBa7Jynsi4hiwT9IAcI6k/cBJEfEwgKTbgEuAbVVHYNbk/ICb1YsiYvyVigngvohYlM3/PCJOKVn+XEScKukGYEdE3J6Vb6Z4kt8PXB8RF2Tl7wKuiYiLx9hfN8XeAu3t7Ut7enpyBTc0NERbW1uuuo0o9Xj6DxydwtZUr30WHH7p1WWL55z88nRp+8cqn6jS+lMl9eOtGVSKqaura2dEdFaqX+uLwOXG9aNCeVkRsQnYBNDZ2RmFQiFXY3p7e8lbtxGlHs/qBv+mvGbxMBv6R/1J9b9YMvPKsv2XFl6ezhNXaf2pkvrx1gyqjSlvAjgsaXZEHJI0GziSlQ8C80rWmwsczMrnlik3S5KHfawR5H0OYCuwKpteBdxbUr5C0kxJ8yle7H0kIg4BL0g6N7v757KSOmZmVgfj9gAkbaF4wfd0SYPAp4DrgTslXQE8A3wAICL2SLoTeAwYBq6KiOPZpq6keEfRLIrXBXwB2MysjiZyF9DKMRadP8b664H1Zcr7gEWTap2ZmU0ZPwls1oT8ZlGrBb8LyMwsUU4AZmaJ8hCQNTTfLjk+DwdZXu4BmJklygnAzCxRTgBmZonyNQBrKB7zN5s+7gGYmSXKCcDMLFFOAGZmiXICMDNLlBOAmVminADMzBLlBGBmlig/B2B153v/a8fvBbLJcA/AzCxRTgBmZolyAjAzS5QTgJlZonInAElnSdpV8nle0sclXSfpQEn5RSV11kkakLRX0oW1CcHMzPLIfRdQROwFlgBImgEcAO4B/gr4fER8tnR9SWcDK4CFwJuBb0s6MyKO522DmZnlV6shoPOBpyLiRxXWWQ70RMSxiNgHDADn1Gj/ZmY2SYqI6jci3Qz8ICJukHQdsBp4HugD1kTEc5JuAHZExO1Znc3Atoi4q8z2uoFugPb29qU9PT252jU0NERbW1uuuo2oVePpP3C03k2pifZZcPilerfiFYvnnFxV/VY93lpJpZi6urp2RkRnpfpVJwBJvwkcBBZGxGFJ7cBPgQA+DcyOiMslfQl4eFQCeCAi7q60/c7Ozujr68vVtt7eXgqFQq66jahV42mVB8HWLB5mQ3/jPFtZ7YNgrXq8tZJKMUkaNwHUYgjoPRS//R8GiIjDEXE8In4NfIVXhnkGgXkl9eZSTBxmZlYHtUgAK4EtIzOSZpcsez+wO5veCqyQNFPSfGAB8EgN9m9mZjlU1V+V9Hrg3cCHS4r/SdISikNA+0eWRcQeSXcCjwHDwFW+A8jMrH6qSgAR8QvgjaPKPlRh/fXA+mr2aWYT4xfD2Xj8JLDVRcfa++k/cLRlLgCbNSMnADOzRDkBmJklygnAzCxRTgBmZolyAjAzS5QTgJlZopwAzMwS5QRgZpaoxnl1oZlNGT8VbOW4B2BmlignADOzRDkBmJklygnAzCxRTgBmZonyXUA2bfzqZ7PG4h6AmVminADMzBLlISCzxPihMBvhHoCZWaKqSgCS9kvql7RLUl9Wdpqk7ZKezH6eWrL+OkkDkvZKurDaxpuZWX616AF0RcSSiOjM5tcCD0bEAuDBbB5JZwMrgIXAMuBGSTNqsH8zM8thKoaAlgO3ZtO3ApeUlPdExLGI2AcMAOdMwf7NzGwCFBH5K0v7gOeAAP41IjZJ+nlEnFKyznMRcaqkG4AdEXF7Vr4Z2BYRd5XZbjfQDdDe3r60p6cnV/uGhoZoa2vLVbcRNXs8/QeOvmq+fRYcfqlOjZkCzRjP4jknj7ms2Y+30VotHqgcU1dX186SkZmyqr0L6J0RcVDSm4Dtkp6osK7KlJXNPhGxCdgE0NnZGYVCIVfjent7yVu3ETV7PKtHPQi2ZvEwG/pb50a0Zoxn/6WFMZc1+/E2WqvFA9XHVNXRGhEHs59HJN1DcUjnsKTZEXFI0mzgSLb6IDCvpPpc4GA1+7fG56d/zRpX7msAkk6U9IaRaeBPgd3AVmBVttoq4N5seiuwQtJMSfOBBcAjefdvZmbVqaYH0A7cI2lkO/8REd+Q9H3gTklXAM8AHwCIiD2S7gQeA4aBqyLieFWtN7Oq+KGwtOVOABHxNPD2MuU/A84fo856YH3efZqZWe34SWAzs0Q5AZiZJcoJwMwsUU4AZmaJcgIwM0uUE4CZWaKa67l1M5syfiYgPU4AVnN+/YNZc/AQkJlZotwDsJrwt36z5uMegJlZotwDsNz8rd+subkHYGaWKCcAM7NEOQGYmSXKCcDMLFFOAGZmiXICMDNLlBOAmVmi/ByAmVXkl8S1rtw9AEnzJH1H0uOS9ki6Oiu/TtIBSbuyz0UlddZJGpC0V9KFtQjAaqdj7f0vfyxtHWvvp//AUR8LLa6aHsAwsCYifiDpDcBOSduzZZ+PiM+WrizpbGAFsBB4M/BtSWdGxPEq2mDTwN8AzVpT7gQQEYeAQ9n0C5IeB+ZUqLIc6ImIY8A+SQPAOcDDedtg08/fCM1ahyKi+o1IHcBDwCLg74DVwPNAH8VewnOSbgB2RMTtWZ3NwLaIuKvM9rqBboD29valPT09udo1NDREW1tbrrqNaKrj6T9w9OXpxXNOLlteS+2z4PBLU7LpukghntLjotm02vkAKsfU1dW1MyI6K9Wv+iKwpDbgbuDjEfG8pI3Ap4HIfm4ALgdUpnrZ7BMRm4BNAJ2dnVEoFHK1rbe3l7x1G9FUx7O69Nt9/4slS6bmXoE1i4fZ0N869yGkEM/+Swv1aUwNtNr5AKqPqaqjVdLrKJ7874iIrwFExOGS5V8B7stmB4F5JdXnAger2b+ZTS9fD2ot1dwFJGAz8HhEfK6kfHbJau8HdmfTW4EVkmZKmg8sAB7Ju38zM6tONT2AdwIfAvol7crKPgGslLSE4vDOfuDDABGxR9KdwGMU7yC6yncAmZnVTzV3Af035cf1H6hQZz2wPu8+zcysdlrnipXl4ts6zdLlBJAgn/TNDPwyODOzZLkHYGa5+JbQ5ucEYGZVczJoTh4CMjNLlBOAmVminADMzBLlawAtzLd7Wj34ekDzcA/AzCxRTgBmZonyEFCDK+1Or1k8/PI7+921NrNqOQE0oImM3Xt835qBrwc0NieABuETuplNN18DMDNLlHsAdeJv/JYaDwc1HieAKeYTvZk1Kg8BmZklyj2AKeBv/WaVeTioMSSTAHzAmTU+/51Or2lPAJKWAV8AZgA3RcT1090GM2sck33uxYmhdqY1AUiaAXwJeDcwCHxf0taIeGwq9td/4OjLT85OxFgHYukBN9aB6GEfs9oa62+q0t9apb/J0ifpx6ubiunuAZwDDETE0wCSeoDlwJQkgLFM9mSd50A0s+lXzd9kNXUn8iWxESkipm9n0p8DyyLir7P5DwG/HxEfHbVeN9CdzZ4F7M25y9OBn+as24gcT2NzPI2t1eKByjH9dkScUanydPcAVKbsNRkoIjYBm6remdQXEZ3VbqdROJ7G5ngaW6vFA9XHNN3PAQwC80rm5wIHp7kNZmbG9CeA7wMLJM2X9JvACmDrNLfBzMyY5iGgiBiW9FHgmxRvA705IvZM4S6rHkZqMI6nsTmextZq8UCVMU3rRWAzM2scfheQmVminADMzBLVkglA0jJJeyUNSFpb7/ZMlqR5kr4j6XFJeyRdnZWfJmm7pCezn6fWu62TIWmGpP+RdF823+zxnCLpLklPZL+rP2jmmCT9bXa87Za0RdJvNVM8km6WdETS7pKyMdsvaV12jtgr6cL6tHpsY8Tzmex4e1TSPZJOKVk26XhaLgGUvG7iPcDZwEpJZ9e3VZM2DKyJiN8FzgWuymJYCzwYEQuAB7P5ZnI18HjJfLPH8wXgGxHxO8DbKcbWlDFJmgN8DOiMiEUUb9JYQXPFcwuwbFRZ2fZnf08rgIVZnRuzc0cjuYXXxrMdWBQRbwN+CKyD/PG0XAKg5HUTEfFLYOR1E00jIg5FxA+y6RconljmUIzj1my1W4FL6tLAHCTNBd4L3FRS3MzxnAScB2wGiIhfRsTPaeKYKN4VOEvSCcDrKT6j0zTxRMRDwLOjisdq/3KgJyKORcQ+YIDiuaNhlIsnIr4VEcPZ7A6Kz1JBznhaMQHMAX5cMj+YlTUlSR3AO4DvAe0RcQiKSQJ4Ux2bNln/DPw98OuSsmaO563AT4B/y4a1bpJ0Ik0aU0QcAD4LPAMcAo5GxLdo0nhKjNX+VjhPXA5sy6ZzxdOKCWBCr5toBpLagLuBj0fE8/VuT16SLgaORMTOerelhk4Afg/YGBHvAF6ksYdHKsrGxpcD84E3AydK+mB9WzWlmvo8IelaikPFd4wUlVlt3HhaMQG0xOsmJL2O4sn/joj4WlZ8WNLsbPls4Ei92jdJ7wTeJ2k/xSG5P5F0O80bDxSPs8GI+F42fxfFhNCsMV0A7IuIn0TEr4CvAX9I88YzYqz2N+15QtIq4GLg0njlQa5c8bRiAmj6101IEsWx5ccj4nMli7YCq7LpVcC90922PCJiXUTMjYgOir+P/4qID9Kk8QBExP8BP5Z0VlZ0PsXXmjdrTM8A50p6fXb8nU/x2lOzxjNirPZvBVZImilpPrAAeKQO7ZsUFf+h1jXA+yLiFyWL8sUTES33AS6ieIX8KeDaercnR/v/iGL37VFgV/a5CHgjxTsZnsx+nlbvtuaIrQDcl003dTzAEqAv+z19HTi1mWMC/gF4AtgN/Dsws5niAbZQvH7xK4rfiK+o1H7g2uwcsRd4T73bP8F4BiiO9Y+cF75cTTx+FYSZWaJacQjIzMwmwAnAzCxRTgBmZolyAjAzS5QTgJlZopwAzMwS5QRgZpao/weCp+ZcuRBQ4QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.loc[:'2019', 'price_tomorrow'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train data, move price column to the end of set\n",
    "train = df.loc[:'2019'].drop(columns='price_tomorrow')\n",
    "train['price_tomorrow'] = df.loc[:'2019', 'price_tomorrow']\n",
    "\n",
    "# Get price_tomorrow std, mean\n",
    "price_std = df.loc[:'2019', 'price_tomorrow'].std()\n",
    "price_mean = df.loc[:'2019', 'price_tomorrow'].mean()\n",
    "\n",
    "# Copy price data and trim\n",
    "train_trimmed = train.copy()\n",
    "train_trimmed.loc[train_trimmed.price_tomorrow>(price_mean + price_std*3), 'price_tomorrow'] = price_mean + price_std*3\n",
    "\n",
    "# Prep trimmed set for modeling\n",
    "train_trimmed = np.array(np.split(train_trimmed, len(train_trimmed)/24))\n",
    "X_train_trimmed, y_train_trimmed = to_supervised(train_trimmed, n_input=24, n_out=24, stride=24)\n",
    "input_shape=(X_train_trimmed.shape[1], X_train_trimmed.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - 1s 19ms/step - loss: 27.5423 - MAPE: 48.7608 - val_loss: 11.3260 - val_MAPE: 32.1205\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 9.4534 - MAPE: 18.0859 - val_loss: 5.8631 - val_MAPE: 17.3613\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 6.9641 - MAPE: 13.8306 - val_loss: 5.6631 - val_MAPE: 16.9238\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 6.3103 - MAPE: 12.8144 - val_loss: 6.1048 - val_MAPE: 19.4528\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 6.0803 - MAPE: 12.8012 - val_loss: 6.6318 - val_MAPE: 22.0523\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 5.9934 - MAPE: 12.6876 - val_loss: 6.1971 - val_MAPE: 20.4445\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 5.9179 - MAPE: 12.5849 - val_loss: 6.8428 - val_MAPE: 22.7620\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 5.9300 - MAPE: 12.5031 - val_loss: 6.0804 - val_MAPE: 20.0912\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 5.8487 - MAPE: 12.4032 - val_loss: 6.7355 - val_MAPE: 22.5357\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 5.8436 - MAPE: 12.4487 - val_loss: 6.1224 - val_MAPE: 20.5202\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 5.7836 - MAPE: 12.3336 - val_loss: 6.3260 - val_MAPE: 21.3017\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 5.7525 - MAPE: 12.3092 - val_loss: 6.4322 - val_MAPE: 21.7429\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 5.7353 - MAPE: 12.2160 - val_loss: 6.4720 - val_MAPE: 21.8296\n",
      "train r2: 0.575173580473701\n",
      "train r2: 0.6355498754335003\n",
      "val r2: 0.5383384396682895\n",
      "val r2: 0.5968869626809818\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model and build layers\n",
    "bm_1 = models.Sequential()\n",
    "bm_1.add(layers.Dense(62, activation='relu', input_shape=input_shape))\n",
    "bm_1.add(layers.Dense(239, activation='relu'))\n",
    "bm_1.add(layers.Dense(162, activation='relu'))\n",
    "bm_1.add(TimeDistributed(layers.Dense(1)))\n",
    "\n",
    "# Loss Metric to optimize\n",
    "metric = tf.keras.metrics.MeanAbsolutePercentageError(name='MAPE')\n",
    "\n",
    "# Create early stopping point\n",
    "callback = keras.callbacks.EarlyStopping(\n",
    "    patience=10,\n",
    "    monitor='val_'+metric.name,\n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "bm_1.compile(loss=tf.keras.metrics.mean_absolute_error, \n",
    "           optimizer=keras.optimizers.Adam(),\n",
    "           metrics=metric)\n",
    "\n",
    "# Fit the model\n",
    "history = bm_1.fit(x= X_train_trimmed,\n",
    "                 y=y_train_trimmed,\n",
    "                 epochs = 100,\n",
    "                 callbacks=[callback],\n",
    "                 batch_size=128,\n",
    "                 validation_data=(X_val, y_val),\n",
    ")\n",
    "\n",
    "preds_train = bm_1.predict(X_train_trimmed).flatten()\n",
    "preds_val = bm_1.predict(X_val).flatten()\n",
    "\n",
    "print('train r2:',r2_score(y_train_trimmed.flatten(), preds_train))\n",
    "print('train r2:',(np.corrcoef(y_train.flatten(), preds_train)**2)[0][1])\n",
    "\n",
    "print('val r2:',r2_score(y_val.flatten(), preds_val))\n",
    "print('val r2:',(np.corrcoef(y_val.flatten(), preds_val)**2)[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trimming the training response variable did not improve model performance much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM - DNN\n",
    "### DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1826, 24, 7)\n",
      "(366, 24, 7)\n",
      "(1825, 24, 6) (1825, 24)\n",
      "(365, 24, 6) (365, 24)\n"
     ]
    }
   ],
   "source": [
    "# Get columns representing future information \n",
    "DNN_cols = df.filter(regex='forecast').columns\n",
    "\n",
    "train = df.loc[:'2019', DNN_cols].copy()\n",
    "val = df.loc['2020', DNN_cols].copy()\n",
    "\n",
    "train['price_tomorrow'] = df.loc[:'2019', 'price_tomorrow']\n",
    "val['price_tomorrow'] = df.loc['2020', 'price_tomorrow']\n",
    "\n",
    "train = np.array(np.split(train, len(train)/24))\n",
    "val = np.array(np.split(val, len(val)/24))\n",
    "print(train.shape)\n",
    "print(val.shape)\n",
    "\n",
    "\n",
    "X_train, y_train = to_supervised(train, n_input=24, n_out=24, stride=24)\n",
    "X_val, y_val = to_supervised(val, n_input=24, n_out=24, stride=24)\n",
    "input_shape=(X_train.shape[1], X_train.shape[2])\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model and build layers\n",
    "bm_1 = models.Sequential()\n",
    "bm_1.add(layers.Dense(62, activation='relu', input_shape=input_shape))\n",
    "bm_1.add(layers.Dense(239, activation='relu'))\n",
    "bm_1.add(layers.Dense(162, activation='relu'))\n",
    "bm_1.add(TimeDistributed(layers.Dense(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - 1s 22ms/step - loss: 31.1012 - MAPE: 54.8837 - val_loss: 7.6221 - val_MAPE: 22.0542\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 9.5633 - MAPE: 18.6024 - val_loss: 6.4179 - val_MAPE: 18.1986\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 6.9690 - MAPE: 13.9584 - val_loss: 6.0370 - val_MAPE: 17.4881\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 6.7030 - MAPE: 13.4970 - val_loss: 5.9364 - val_MAPE: 17.4142\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 6.6260 - MAPE: 13.3519 - val_loss: 5.8679 - val_MAPE: 17.1270\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 6.5688 - MAPE: 13.1972 - val_loss: 5.7908 - val_MAPE: 16.9660\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 6.4767 - MAPE: 13.0076 - val_loss: 5.6648 - val_MAPE: 16.5560\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 6.3765 - MAPE: 12.8074 - val_loss: 5.6211 - val_MAPE: 16.8038\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 6.2441 - MAPE: 12.6377 - val_loss: 5.6271 - val_MAPE: 17.0610\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 6.1414 - MAPE: 12.5432 - val_loss: 5.7092 - val_MAPE: 17.6546\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 6.1120 - MAPE: 12.6177 - val_loss: 5.5993 - val_MAPE: 17.4925\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 6.0496 - MAPE: 12.6041 - val_loss: 5.6319 - val_MAPE: 17.7280\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 6.0232 - MAPE: 12.6004 - val_loss: 6.2680 - val_MAPE: 19.9830\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 6.0250 - MAPE: 12.6530 - val_loss: 6.7330 - val_MAPE: 21.3585\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 6.2306 - MAPE: 12.9499 - val_loss: 5.7442 - val_MAPE: 18.3345\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 6.0014 - MAPE: 12.6014 - val_loss: 5.8728 - val_MAPE: 18.8382\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 5.9794 - MAPE: 12.5993 - val_loss: 5.9262 - val_MAPE: 19.0980\n",
      "train r2: 0.5552289382714086\n",
      "train r2: 0.6389792939446287\n",
      "val r2: 0.5290725929659816\n",
      "val r2: 0.5979660285450905\n"
     ]
    }
   ],
   "source": [
    "dnn = models.Sequential()\n",
    "dnn.add(layers.Dense(62, activation='relu', input_shape=input_shape))\n",
    "dnn.add(layers.Dense(239, activation='relu'))\n",
    "dnn.add(layers.Dense(162, activation='relu'))\n",
    "dnn.add(TimeDistributed(layers.Dense(1)))\n",
    "\n",
    "# Loss Metric to optimize\n",
    "metric = tf.keras.metrics.MeanAbsolutePercentageError(name='MAPE')\n",
    "\n",
    "# Create early stopping point\n",
    "callback = keras.callbacks.EarlyStopping(\n",
    "    patience=10,\n",
    "    monitor='val_'+metric.name,\n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "dnn.compile(loss=tf.keras.metrics.mean_absolute_error, \n",
    "            optimizer=keras.optimizers.Adam(),\n",
    "            metrics=metric)\n",
    "\n",
    "# Fit the model\n",
    "history = dnn.fit(x= X_train,\n",
    "                  y=y_train,\n",
    "                  epochs = 100,\n",
    "                  callbacks=[callback],\n",
    "                  batch_size=128,\n",
    "                  validation_data=(X_val, y_val),\n",
    ")\n",
    "\n",
    "preds_train = dnn.predict(X_train).flatten()\n",
    "preds_val = dnn.predict(X_val).flatten()\n",
    "\n",
    "print('train r2:',r2_score(y_train.flatten(), preds_train))\n",
    "print('train r2:',(np.corrcoef(y_train.flatten(), preds_train)**2)[0][1])\n",
    "\n",
    "print('val r2:',r2_score(y_val.flatten(), preds_val))\n",
    "print('val r2:',(np.corrcoef(y_val.flatten(), preds_val)**2)[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1825, 24, 57)\n",
      "(366, 24, 57)\n",
      "(1824, 24, 6) (1824, 24)\n",
      "(365, 24, 6) (365, 24)\n"
     ]
    }
   ],
   "source": [
    "# Get columns representing past information \n",
    "LSTM_cols = list(set(df.columns) - set(DNN_cols))\n",
    "\n",
    "train_LSTM = df.loc[:'2019', LSTM_cols].copy()\n",
    "val_LSTM = df.loc['2020', LSTM_cols].copy()\n",
    "\n",
    "train_LSTM['price_tomorrow'] = df.loc[:'2019', 'price_tomorrow']\n",
    "val_LSTM['price_tomorrow'] = df.loc['2020', 'price_tomorrow']\n",
    "\n",
    "train_LSTM = np.array(np.split(train_LSTM, len(train_LSTM)/24))\n",
    "val_LSTM = np.array(np.split(val_LSTM, len(val_LSTM)/24))\n",
    "print(train_LSTM.shape)\n",
    "print(val_LSTM.shape)\n",
    "\n",
    "\n",
    "X_train_LSTM, y_train_LSTM = to_supervised(train, n_input=24, n_out=24, stride=24)\n",
    "X_val_LSTM, y_val_LSTM = to_supervised(val, n_input=24, n_out=24, stride=24)\n",
    "input_shape=(X_train_LSTM.shape[1], X_train_LSTM.shape[2])\n",
    "print(X_train_LSTM.shape, y_train_LSTM.shape)\n",
    "print(X_val_LSTM.shape, y_val_LSTM.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_LSTM.shape[1]*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import RepeatVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 26.6459 - MAPE: 48.2963 - val_loss: 14.2966 - val_MAPE: 51.7783\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 25.3086 - MAPE: 45.2933 - val_loss: 13.4928 - val_MAPE: 53.2092\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 24.1907 - MAPE: 46.2159 - val_loss: 13.4061 - val_MAPE: 55.4275\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 23.3549 - MAPE: 46.3062 - val_loss: 13.2973 - val_MAPE: 57.4276\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 22.4916 - MAPE: 46.2195 - val_loss: 13.4286 - val_MAPE: 59.3083\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 21.9316 - MAPE: 45.3119 - val_loss: 13.7680 - val_MAPE: 61.9331\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 21.4020 - MAPE: 44.5079 - val_loss: 13.7720 - val_MAPE: 63.9574\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 20.9852 - MAPE: 46.8672 - val_loss: 13.8392 - val_MAPE: 66.1354\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 20.3976 - MAPE: 46.2649 - val_loss: 13.9022 - val_MAPE: 68.1763\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 19.9114 - MAPE: 45.0588 - val_loss: 14.1110 - val_MAPE: 69.8624\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 19.5399 - MAPE: 44.7417 - val_loss: 14.5458 - val_MAPE: 71.8341\n",
      "train r2: -1.2335523211196078\n",
      "train r2: 0.20860366672203412\n",
      "val r2: -0.12525477272566876\n",
      "val r2: 0.26045952495646585\n"
     ]
    }
   ],
   "source": [
    "lstm = keras.Sequential()\n",
    "lstm.add(layers.LSTM(83, activation='tanh', input_shape=input_shape))\n",
    "lstm.add(RepeatVector(y_train_LSTM.shape[1]))\n",
    "lstm.add(layers.Dense(184, activation='relu', kernel_regularizer=regularizers.l1(0.1)))\n",
    "lstm.add(TimeDistributed(layers.Dense(1)))\n",
    "\n",
    "# Loss Metric to optimize\n",
    "metric = tf.keras.metrics.MeanAbsolutePercentageError(name='MAPE')\n",
    "\n",
    "# Create early stopping point\n",
    "callback = keras.callbacks.EarlyStopping(\n",
    "    patience=10,\n",
    "    monitor='val_'+metric.name,\n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "dnn.compile(loss=tf.keras.metrics.mean_absolute_error, \n",
    "            optimizer=keras.optimizers.Adam(),\n",
    "            metrics=metric)\n",
    "\n",
    "# Fit the model\n",
    "history = dnn.fit(x= X_train_LSTM,\n",
    "                  y=y_train_LSTM,\n",
    "                  epochs = 100,\n",
    "                  callbacks=[callback],\n",
    "                  batch_size=128,\n",
    "                  validation_data=(X_val_LSTM, y_val_LSTM),\n",
    ")\n",
    "\n",
    "preds_train = dnn.predict(X_train_LSTM).flatten()\n",
    "preds_val = dnn.predict(X_val_LSTM).flatten()\n",
    "\n",
    "print('train r2:',r2_score(y_train_LSTM.flatten(), preds_train))\n",
    "print('train r2:',(np.corrcoef(y_train_LSTM.flatten(), preds_train)**2)[0][1])\n",
    "\n",
    "print('val r2:',r2_score(y_val_LSTM.flatten(), preds_val))\n",
    "print('val r2:',(np.corrcoef(y_val_LSTM.flatten(), preds_val)**2)[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.48064142],\n",
       "       [0.48064142, 1.        ]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(df['price_forecast_tomorrow'].values, df.price_tomorrow)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble LSTM-DNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU - DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
