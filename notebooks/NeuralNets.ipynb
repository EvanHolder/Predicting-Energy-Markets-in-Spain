{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Models\n",
    "____\n",
    "GOALS:\n",
    "* Model `price_actual` using a univariate XGBRegressor <br>\n",
    "* Model all price components EXCEPT `price_day_ahead` with a multivariate XGBRegressor\n",
    "___\n",
    "OUTLINE:<br>\n",
    "1. Import Libraries\n",
    "2. Read in Data\n",
    "3. Modeling `price_actual`<br>\n",
    "    3.1 Prepare Data (Categoricals)<br>\n",
    "    3.2 Split Data<br>\n",
    "    3.3 Model one-to-one<br>\n",
    "    3.4 Model 24-to-24<br>\n",
    "    3.5 LSTM <br>\n",
    "    3.6 LSTM-DNN <br>\n",
    "4. Modeling Price Components (excluding `price_day_ahead`)<br>\n",
    "    4.1 Model one-to-one<br>\n",
    "    4.2 Model 24-to-24<br>\n",
    "    4.3 LSTM <br>\n",
    "    4.4 LSTM-DNN <br>\n",
    "    \n",
    "5. Final Model <br>\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_gen(data, input_window, output_window, stride):\n",
    "    '''\n",
    "    Yields train and test samples of the given provided datasets, at specified input and out lengths, and specified strides\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    train: tuple,\n",
    "        Tuple of length 2, which provides the training features and training targets respectively\n",
    "    test: tuple,\n",
    "        Tuple of length 2, which provides the testing features and testing targets respectively\n",
    "    input_window: int,\n",
    "        Length of the sequence of input data\n",
    "    output_window: int,\n",
    "        Length of the sequence of output data\n",
    "    stride, int\n",
    "        Number of steps to move between first sample and second sample\n",
    "    '''\n",
    "    # Define X_train, y_train, X_test, y_test\n",
    "    X, y = data[0], data[1]\n",
    "    \n",
    "    # Compute number of samples \n",
    "    n = len(X)/stride\n",
    "    \n",
    "    # If the input_window is greater than a day, X_train\n",
    "    if input_window > 24:\n",
    "        n_add = input_window - 24\n",
    "        X = X.iloc[:n_add].append(X)\n",
    "    else:\n",
    "        n_add = 0\n",
    "    for i in range(0, len(X)-n_add, stride):\n",
    "        yield X.iloc[i:i+input_window].to_numpy(), y.iloc[i:i+output_window].to_numpy()\n",
    "        \n",
    "def resample(data, input_window, output_window, stride):\n",
    "    win = window_gen((data[0], data[1]), input_window=input_window, output_window=output_window, stride=stride)\n",
    "    \n",
    "    n = int(len(data[0])/stride)\n",
    "    X_data = np.array([])\n",
    "    y_data = np.array([])\n",
    "    \n",
    "    for i in range(n):\n",
    "        X_sample, y_sample = next(win)\n",
    "        X_data = np.append(X_data, X_sample)\n",
    "        y_data = np.append(y_data, y_sample)\n",
    "        \n",
    "    # Reshape\n",
    "    X_data = X_data.reshape(n,input_window,len(data[0].columns))\n",
    "    y_data = y_data.reshape(n, output_window)\n",
    "    \n",
    "    return X_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_nn(models):\n",
    "    '''\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    models: list,\n",
    "        List containing trained models to use in ensemble\n",
    "    RETURNS\n",
    "    ----------\n",
    "    ensemble: keras model,\n",
    "        Trained model combining all input models into a single output model.\n",
    "    '''\n",
    "    # Get models in list\n",
    "    models = [dnn, lstm]\n",
    "\n",
    "    # Rename layers \n",
    "    for i, model in enumerate(models):\n",
    "        for i2, layer in enumerate(model.layers):\n",
    "            layer.trainable = False\n",
    "            layer._name = f'ensemble_{i}_{i2}_{layer.name}'\n",
    "    \n",
    "    # Define multi-headed input\n",
    "    ensemble_visible = [model.input for model in models]\n",
    "    \n",
    "    # Concatenate merge output from each model\n",
    "    ensemble_outputs = [model.output for model in models]\n",
    "    merge = layers.merge.concatenate(ensemble_outputs)\n",
    "    hidden = layers.Dense(24, activation='relu')(merge)\n",
    "    output = TimeDistributed(layers.Dense(1))(hidden)\n",
    "    ensemble = keras.Model(inputs=ensemble_visible, outputs=output)   \n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(model, train, test):\n",
    "    \n",
    "    if type(train[0]) is not list:\n",
    "        X_train = [train[0]]\n",
    "        X_test = [test[0]]\n",
    "    else:\n",
    "        X_train = train[0]\n",
    "        X_test = test[0]\n",
    "    \n",
    "    # Convert data into arrays if not already\n",
    "    X_train = [np.array(x_data) for x_data in X_train]\n",
    "    X_test = [np.array(x_data) for x_data in X_test]\n",
    "    y_train, y_test = np.array(train[1]), np.array(test[1])\n",
    "        \n",
    "    # Convert data into arrays if not already\n",
    "    #X_train, y_train = np.array(train[0]), np.array(train[1])\n",
    "    #X_test, y_test = np.array(test[0]), np.array(test[1])\n",
    "    \n",
    "    # Predict \n",
    "    preds_train = model.predict(X_train)\n",
    "    preds_test = model.predict(X_test)\n",
    "    \n",
    "    # Compute sMAPE\n",
    "    sMAPE_train = sMAPE(y_train.flatten(), preds_train.flatten())\n",
    "    sMAPE_val = sMAPE(y_test.flatten(), preds_test.flatten())\n",
    "\n",
    "    # Compute r2\n",
    "    r2_train = r2(y_train.flatten(), preds_train.flatten())\n",
    "    r2_val = r2(y_test.flatten(), preds_test.flatten())\n",
    "    \n",
    "    return [sMAPE_train, sMAPE_val, r2_train, r2_val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from keras import layers, models, regularizers\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import timeseries_dataset_from_array\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import os\n",
    "import winsound\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import datetime as dt\n",
    "\n",
    "os.chdir('../scripts')\n",
    "from functions import impute_immediate_mean, split_data, SMAPE,sMAPE, r2, compute_metrics, to_supervised\n",
    "os.chdir('../notebooks')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up alarm for notification of model completion\n",
    "duration = 1000  # milliseconds\n",
    "freq = 440  # Hz\n",
    "winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lag =pd.read_csv('../data/clean/df_clean_lag.csv', index_col=0, parse_dates=True)\n",
    "TSO_preds = df_lag.price_day_ahead.copy()\n",
    "y_true_train = df_lag.loc[:'2019', 'price_actual'].copy()\n",
    "y_true_val = df_lag.loc['2020', 'price_actual'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Modeling\n",
    "### 3.1 Prepare Data\n",
    "Scale Continuous Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous = df_lag.select_dtypes(exclude='object').drop(columns=['price_actual', 'price_day_ahead']).columns\n",
    "\n",
    "# Get rid of negatives\n",
    "time = dt.datetime(2021,3,24,22)\n",
    "df_lag.loc[time, 'dew_point_bilbao_lag'] = impute_immediate_mean(df_lag['dew_point_bilbao_lag'], time)\n",
    "\n",
    "# Rescale data [-1,1]\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "df_lag[continuous] = scaler.fit_transform(df_lag[continuous])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode and scale categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get catergorical \n",
    "categorical = df_lag.select_dtypes(include='object').columns\n",
    "\n",
    "# Get wind direction cols\n",
    "wind_dirs = df_lag.filter(regex='wind(?!_speeds|_forecast)').columns\n",
    "\n",
    "# Instantiate encoder and transfrom wind_dir cols\n",
    "wind_dir_coder = LabelEncoder()\n",
    "wind_dir_coder.fit(df_lag['wind_madrid_lag'])\n",
    "for col in wind_dirs:\n",
    "    df_lag[col] = wind_dir_coder.transform(df_lag[col])\n",
    "    \n",
    "# Stack condition columns into single col\n",
    "stacked_conditions = df_lag.filter(regex='condition').stack()\n",
    "\n",
    "# Instantiate Label encoder, fit and transform on condition cols\n",
    "condition_coder = LabelEncoder()\n",
    "condition_coder.fit(stacked_conditions)\n",
    "for col in df_lag.filter(regex='condition').columns:\n",
    "    df_lag[col] = condition_coder.transform(df_lag[col])\n",
    "\n",
    "# Rescale data [-1,1]\n",
    "df_lag[categorical] = scaler.fit_transform(df_lag[categorical])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Data into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get price components to drop\n",
    "price_drop = df_lag.filter(regex='price_(?!actual|day)').columns\n",
    "\n",
    "# Split data\n",
    "X_train, y_train, X_val, y_val = split_data(df_lag.drop(columns=price_drop), 2020, 'price_actual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create results_actual dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSO_metrics = [round(sMAPE(y_true_train, TSO_preds.loc[:'2019']),3),\n",
    "               round(sMAPE(y_true_val, TSO_preds.loc['2020']),3), \n",
    "               round(r2(y_true_train, TSO_preds.loc[:'2019']),3),\n",
    "               round(r2(y_true_val, TSO_preds.loc['2020']),3)]\n",
    "results_actual = pd.DataFrame({'TSO':TSO_metrics}, \n",
    "                              index=['sMAPE_train', 'sMAPE_val', 'r2_train', 'r2_val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Modeling (one-to-one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input_shape\n",
    "input_shape = (X_train.shape[1],)\n",
    "\n",
    "# Instantiate model and build layers\n",
    "nn = models.Sequential()\n",
    "nn.add(layers.Dense(59, activation='relu', input_shape=input_shape))\n",
    "nn.add(layers.Dense(239, activation='relu'))\n",
    "nn.add(layers.Dense(162, activation='relu'))\n",
    "nn.add(layers.Dense(1, activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1369/1369 [==============================] - 3s 2ms/step - loss: 2.0712 - SMAPE: 4.3372 - val_loss: 1.4228 - val_SMAPE: 4.1740\n",
      "Epoch 2/200\n",
      "1369/1369 [==============================] - 2s 1ms/step - loss: 1.4814 - SMAPE: 2.8341 - val_loss: 1.5818 - val_SMAPE: 4.6781\n",
      "Epoch 3/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 1.4051 - SMAPE: 2.6793 - val_loss: 1.5677 - val_SMAPE: 4.7071\n",
      "Epoch 4/200\n",
      "1369/1369 [==============================] - 3s 2ms/step - loss: 1.3545 - SMAPE: 2.5828 - val_loss: 1.5839 - val_SMAPE: 4.8793\n",
      "Epoch 5/200\n",
      "1369/1369 [==============================] - 2s 1ms/step - loss: 1.3174 - SMAPE: 2.5079 - val_loss: 1.5754 - val_SMAPE: 4.8076\n",
      "Epoch 6/200\n",
      "1369/1369 [==============================] - 2s 1ms/step - loss: 1.2824 - SMAPE: 2.4439 - val_loss: 1.5899 - val_SMAPE: 4.8689\n",
      "Epoch 7/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 1.2429 - SMAPE: 2.3634 - val_loss: 1.4458 - val_SMAPE: 4.4351\n",
      "Epoch 8/200\n",
      "1369/1369 [==============================] - 2s 1ms/step - loss: 1.2447 - SMAPE: 2.3650 - val_loss: 1.5837 - val_SMAPE: 4.8025\n",
      "Epoch 9/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 1.2320 - SMAPE: 2.3390 - val_loss: 1.7984 - val_SMAPE: 5.4190\n",
      "Epoch 10/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 1.1932 - SMAPE: 2.2699 - val_loss: 2.2038 - val_SMAPE: 6.4301\n",
      "Epoch 11/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 1.1674 - SMAPE: 2.2187 - val_loss: 1.8448 - val_SMAPE: 5.4149\n"
     ]
    }
   ],
   "source": [
    "nn1 = compile_fit(nn, (X_train,y_train), (X_val, y_val), patience=10,\n",
    "                  loss = tf.keras.metrics.mean_absolute_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSO</th>\n",
       "      <th>nn1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sMAPE_train</th>\n",
       "      <td>16.030</td>\n",
       "      <td>2.910315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sMAPE_val</th>\n",
       "      <td>16.922</td>\n",
       "      <td>4.179681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_train</th>\n",
       "      <td>0.954</td>\n",
       "      <td>0.980623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_val</th>\n",
       "      <td>0.971</td>\n",
       "      <td>0.977432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                TSO       nn1\n",
       "sMAPE_train  16.030  2.910315\n",
       "sMAPE_val    16.922  4.179681\n",
       "r2_train      0.954  0.980623\n",
       "r2_val        0.971  0.977432"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_actual['nn1'] = compute_metrics(nn1, (X_train,y_train), (X_val, y_val))\n",
    "results_actual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Modeling (24-to-24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restructure data for 24 hour input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and validation\n",
    "X_train, y_train, X_val, y_val = split_data(df_lag.drop(columns=price_drop), 2020, 'price_actual')\n",
    "\n",
    "# Reorganize the training and testing data into batches\n",
    "X_train, y_train = resample((X_train, y_train), 24, 24, 24)\n",
    "X_val, y_val = resample((X_val,y_val), 24, 24, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input_shape\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "# Instantiate model and build layers\n",
    "nn = models.Sequential()\n",
    "nn.add(layers.Dense(59, activation='relu', input_shape=input_shape))\n",
    "nn.add(layers.Dense(239, activation='relu'))\n",
    "nn.add(layers.Dense(162, activation='relu'))\n",
    "nn.add(TimeDistributed(layers.Dense(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "58/58 [==============================] - 1s 8ms/step - loss: 12.2007 - SMAPE: 31.7609 - val_loss: 4.0983 - val_SMAPE: 10.5374\n",
      "Epoch 2/200\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 2.1361 - SMAPE: 4.1268 - val_loss: 2.3717 - val_SMAPE: 6.8199\n",
      "Epoch 3/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.7626 - SMAPE: 3.4348 - val_loss: 1.8982 - val_SMAPE: 5.7040\n",
      "Epoch 4/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.7156 - SMAPE: 3.3673 - val_loss: 2.1122 - val_SMAPE: 6.4022\n",
      "Epoch 5/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.6477 - SMAPE: 3.1796 - val_loss: 3.3190 - val_SMAPE: 9.3461\n",
      "Epoch 6/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.6403 - SMAPE: 3.2754 - val_loss: 1.6228 - val_SMAPE: 4.8660\n",
      "Epoch 7/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.7401 - SMAPE: 3.3245 - val_loss: 1.4932 - val_SMAPE: 4.3720\n",
      "Epoch 8/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.5563 - SMAPE: 2.9986 - val_loss: 2.0069 - val_SMAPE: 6.0486\n",
      "Epoch 9/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.5782 - SMAPE: 3.0232 - val_loss: 2.0115 - val_SMAPE: 5.9895\n",
      "Epoch 10/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.5029 - SMAPE: 2.9020 - val_loss: 2.9858 - val_SMAPE: 8.4217\n",
      "Epoch 11/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.5804 - SMAPE: 3.0434 - val_loss: 2.3022 - val_SMAPE: 6.7125\n",
      "Epoch 12/200\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5093 - SMAPE: 2.9339 - val_loss: 3.8763 - val_SMAPE: 10.3502\n",
      "Epoch 13/200\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 1.6539 - SMAPE: 3.1213 - val_loss: 1.3859 - val_SMAPE: 3.8766\n",
      "Epoch 14/200\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 1.5226 - SMAPE: 2.9377 - val_loss: 2.3063 - val_SMAPE: 6.8241\n",
      "Epoch 15/200\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 1.5470 - SMAPE: 2.9591 - val_loss: 2.9395 - val_SMAPE: 8.1803\n",
      "Epoch 16/200\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5406 - SMAPE: 2.9535 - val_loss: 1.6238 - val_SMAPE: 4.9520\n",
      "Epoch 17/200\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4393 - SMAPE: 2.7366 - val_loss: 1.6997 - val_SMAPE: 5.1969\n",
      "Epoch 18/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.5011 - SMAPE: 2.8386 - val_loss: 1.4419 - val_SMAPE: 4.3824\n",
      "Epoch 19/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.4594 - SMAPE: 2.7842 - val_loss: 1.4124 - val_SMAPE: 4.1089\n",
      "Epoch 20/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.5069 - SMAPE: 2.8385 - val_loss: 1.3952 - val_SMAPE: 3.8717\n",
      "Epoch 21/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.4527 - SMAPE: 2.7466 - val_loss: 2.2012 - val_SMAPE: 6.6167\n",
      "Epoch 22/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.4005 - SMAPE: 2.6803 - val_loss: 2.3308 - val_SMAPE: 6.9773\n",
      "Epoch 23/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.5989 - SMAPE: 2.9908 - val_loss: 1.7203 - val_SMAPE: 5.2590\n",
      "Epoch 24/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.4612 - SMAPE: 2.8790 - val_loss: 1.8008 - val_SMAPE: 5.5649\n",
      "Epoch 25/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.3969 - SMAPE: 2.6573 - val_loss: 1.9806 - val_SMAPE: 6.1036\n",
      "Epoch 26/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.3715 - SMAPE: 2.5931 - val_loss: 1.3815 - val_SMAPE: 4.2258\n",
      "Epoch 27/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.3986 - SMAPE: 2.6213 - val_loss: 1.2850 - val_SMAPE: 3.7069\n",
      "Epoch 28/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.3921 - SMAPE: 2.6138 - val_loss: 1.9119 - val_SMAPE: 5.9210\n",
      "Epoch 29/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.3727 - SMAPE: 2.5792 - val_loss: 1.7596 - val_SMAPE: 5.4418\n",
      "Epoch 30/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.3547 - SMAPE: 2.6843 - val_loss: 1.8335 - val_SMAPE: 5.7495\n",
      "Epoch 31/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.3947 - SMAPE: 2.7008 - val_loss: 1.4112 - val_SMAPE: 4.3594\n",
      "Epoch 32/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.3448 - SMAPE: 2.5729 - val_loss: 1.3162 - val_SMAPE: 3.9865\n",
      "Epoch 33/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.3301 - SMAPE: 2.5209 - val_loss: 1.5086 - val_SMAPE: 4.7488\n",
      "Epoch 34/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.3307 - SMAPE: 2.5083 - val_loss: 1.4826 - val_SMAPE: 4.6487\n",
      "Epoch 35/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.3124 - SMAPE: 2.4952 - val_loss: 1.2919 - val_SMAPE: 3.6388\n",
      "Epoch 36/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.3343 - SMAPE: 2.5133 - val_loss: 1.5637 - val_SMAPE: 4.8812\n",
      "Epoch 37/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.3551 - SMAPE: 2.5326 - val_loss: 1.3447 - val_SMAPE: 4.1547\n",
      "Epoch 38/200\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3988 - SMAPE: 2.6056 - val_loss: 3.2046 - val_SMAPE: 9.1102\n",
      "Epoch 39/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.5881 - SMAPE: 2.9617 - val_loss: 1.7744 - val_SMAPE: 5.4726\n",
      "Epoch 40/200\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.2936 - SMAPE: 2.4296 - val_loss: 1.3502 - val_SMAPE: 3.6058\n",
      "Epoch 41/200\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.3836 - SMAPE: 2.6290 - val_loss: 1.3515 - val_SMAPE: 4.0918\n",
      "Epoch 42/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.3161 - SMAPE: 2.4903 - val_loss: 1.4059 - val_SMAPE: 4.3987\n",
      "Epoch 43/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.2371 - SMAPE: 2.3341 - val_loss: 1.5093 - val_SMAPE: 4.7675\n",
      "Epoch 44/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.2773 - SMAPE: 2.3984 - val_loss: 1.2425 - val_SMAPE: 3.7036\n",
      "Epoch 45/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.3033 - SMAPE: 2.4459 - val_loss: 1.2525 - val_SMAPE: 3.6829\n",
      "Epoch 46/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.2606 - SMAPE: 2.3651 - val_loss: 1.3001 - val_SMAPE: 3.8441\n",
      "Epoch 47/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.3386 - SMAPE: 2.5046 - val_loss: 1.3728 - val_SMAPE: 4.2919\n",
      "Epoch 48/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.2366 - SMAPE: 2.3473 - val_loss: 2.4604 - val_SMAPE: 7.1525\n",
      "Epoch 49/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.3822 - SMAPE: 2.5906 - val_loss: 2.5998 - val_SMAPE: 7.6498\n",
      "Epoch 50/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.3574 - SMAPE: 2.5872 - val_loss: 2.0990 - val_SMAPE: 6.5144\n"
     ]
    }
   ],
   "source": [
    "nn2 = compile_fit(nn, (X_train, y_train), (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSO</th>\n",
       "      <th>nn1</th>\n",
       "      <th>nn2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sMAPE_train</th>\n",
       "      <td>16.030</td>\n",
       "      <td>2.910315</td>\n",
       "      <td>3.962906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sMAPE_val</th>\n",
       "      <td>16.922</td>\n",
       "      <td>4.179681</td>\n",
       "      <td>3.454599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_train</th>\n",
       "      <td>0.954</td>\n",
       "      <td>0.980623</td>\n",
       "      <td>0.983838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_val</th>\n",
       "      <td>0.971</td>\n",
       "      <td>0.977432</td>\n",
       "      <td>0.980697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                TSO       nn1       nn2\n",
       "sMAPE_train  16.030  2.910315  3.962906\n",
       "sMAPE_val    16.922  4.179681  3.454599\n",
       "r2_train      0.954  0.980623  0.983838\n",
       "r2_val        0.971  0.977432  0.980697"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_actual['nn2'] = compute_metrics(nn2, (X_train, y_train), (X_val, y_val))\n",
    "results_actual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and validation\n",
    "X_train, y_train, X_val, y_val = split_data(df_lag.drop(columns=price_drop), 2020, 'price_actual')\n",
    "\n",
    "# Reorganize the training and testing data into batches\n",
    "X_train, y_train = resample((X_train, y_train), 24*7, 24, 24)\n",
    "X_val, y_val = resample((X_val,y_val), 24*7, 24, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "# Instantiate model and build layers\n",
    "nn = models.Sequential()\n",
    "nn.add(layers.LSTM(60, activation='tanh', input_shape=input_shape))\n",
    "nn.add(layers.RepeatVector(y_train.shape[1]))\n",
    "nn.add(layers.LSTM(24, activation='tanh', return_sequences=True))\n",
    "nn.add(TimeDistributed(layers.Dense(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "58/58 [==============================] - 7s 80ms/step - loss: 53.9754 - SMAPE: 179.1431 - val_loss: 35.6774 - val_SMAPE: 148.6349\n",
      "Epoch 2/200\n",
      "58/58 [==============================] - 4s 69ms/step - loss: 50.0152 - SMAPE: 154.3059 - val_loss: 33.4253 - val_SMAPE: 131.5672\n",
      "Epoch 3/200\n",
      "58/58 [==============================] - 4s 68ms/step - loss: 48.1394 - SMAPE: 143.7396 - val_loss: 31.7212 - val_SMAPE: 119.7844\n",
      "Epoch 4/200\n",
      "58/58 [==============================] - 4s 68ms/step - loss: 46.5005 - SMAPE: 135.2807 - val_loss: 30.1331 - val_SMAPE: 109.5757\n",
      "Epoch 5/200\n",
      "58/58 [==============================] - 4s 69ms/step - loss: 44.9406 - SMAPE: 127.1814 - val_loss: 28.5983 - val_SMAPE: 100.3414\n",
      "Epoch 6/200\n",
      "58/58 [==============================] - 4s 69ms/step - loss: 43.4204 - SMAPE: 120.0789 - val_loss: 27.0997 - val_SMAPE: 91.8631\n",
      "Epoch 7/200\n",
      "58/58 [==============================] - 4s 68ms/step - loss: 41.9306 - SMAPE: 113.1782 - val_loss: 25.6314 - val_SMAPE: 84.0301\n",
      "Epoch 8/200\n",
      "58/58 [==============================] - 4s 69ms/step - loss: 40.4648 - SMAPE: 106.8161 - val_loss: 24.1879 - val_SMAPE: 76.7509\n",
      "Epoch 9/200\n",
      "58/58 [==============================] - 4s 69ms/step - loss: 39.0203 - SMAPE: 100.7677 - val_loss: 22.7687 - val_SMAPE: 69.9666\n",
      "Epoch 10/200\n",
      "58/58 [==============================] - 4s 69ms/step - loss: 37.5950 - SMAPE: 95.1417 - val_loss: 21.3802 - val_SMAPE: 63.6783\n",
      "Epoch 11/200\n",
      "58/58 [==============================] - 4s 70ms/step - loss: 36.1882 - SMAPE: 89.5534 - val_loss: 20.0186 - val_SMAPE: 57.8136\n",
      "Epoch 12/200\n",
      "58/58 [==============================] - 4s 70ms/step - loss: 34.7951 - SMAPE: 84.2749 - val_loss: 18.6875 - val_SMAPE: 52.3639\n",
      "Epoch 13/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 33.4012 - SMAPE: 79.9382 - val_loss: 17.3988 - val_SMAPE: 47.3470\n",
      "Epoch 14/200\n",
      "58/58 [==============================] - 5s 78ms/step - loss: 32.0207 - SMAPE: 74.8949 - val_loss: 16.1012 - val_SMAPE: 42.5165\n",
      "Epoch 15/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 30.6694 - SMAPE: 70.8481 - val_loss: 14.8577 - val_SMAPE: 38.1486\n",
      "Epoch 16/200\n",
      "58/58 [==============================] - 5s 80ms/step - loss: 29.2950 - SMAPE: 66.0192 - val_loss: 13.6653 - val_SMAPE: 34.2500\n",
      "Epoch 17/200\n",
      "58/58 [==============================] - 4s 76ms/step - loss: 27.9753 - SMAPE: 62.3832 - val_loss: 12.5472 - val_SMAPE: 30.8526\n",
      "Epoch 18/200\n",
      "58/58 [==============================] - 4s 76ms/step - loss: 26.6434 - SMAPE: 58.0426 - val_loss: 11.6078 - val_SMAPE: 28.2248\n",
      "Epoch 19/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 25.3438 - SMAPE: 53.7323 - val_loss: 10.5280 - val_SMAPE: 25.3163\n",
      "Epoch 20/200\n",
      "58/58 [==============================] - 5s 79ms/step - loss: 24.0971 - SMAPE: 50.7502 - val_loss: 9.8963 - val_SMAPE: 23.9156\n",
      "Epoch 21/200\n",
      "58/58 [==============================] - 5s 79ms/step - loss: 22.8379 - SMAPE: 47.7222 - val_loss: 9.0475 - val_SMAPE: 21.8182\n",
      "Epoch 22/200\n",
      "58/58 [==============================] - 5s 79ms/step - loss: 21.6201 - SMAPE: 43.9020 - val_loss: 8.2560 - val_SMAPE: 19.6096\n",
      "Epoch 23/200\n",
      "58/58 [==============================] - 5s 81ms/step - loss: 20.4638 - SMAPE: 41.0260 - val_loss: 7.6544 - val_SMAPE: 18.1519\n",
      "Epoch 24/200\n",
      "58/58 [==============================] - 5s 79ms/step - loss: 19.2611 - SMAPE: 38.2743 - val_loss: 7.2607 - val_SMAPE: 17.6677\n",
      "Epoch 25/200\n",
      "58/58 [==============================] - 5s 79ms/step - loss: 18.1403 - SMAPE: 35.8664 - val_loss: 6.9418 - val_SMAPE: 17.0745\n",
      "Epoch 26/200\n",
      "58/58 [==============================] - 5s 78ms/step - loss: 17.0538 - SMAPE: 32.7484 - val_loss: 6.2830 - val_SMAPE: 15.3524\n",
      "Epoch 27/200\n",
      "58/58 [==============================] - 5s 78ms/step - loss: 16.0570 - SMAPE: 30.5464 - val_loss: 6.0597 - val_SMAPE: 14.8805\n",
      "Epoch 28/200\n",
      "58/58 [==============================] - 5s 79ms/step - loss: 15.1045 - SMAPE: 28.3802 - val_loss: 6.1894 - val_SMAPE: 15.7214\n",
      "Epoch 29/200\n",
      "58/58 [==============================] - 5s 83ms/step - loss: 14.2331 - SMAPE: 26.8976 - val_loss: 5.8281 - val_SMAPE: 14.6439\n",
      "Epoch 30/200\n",
      "58/58 [==============================] - 5s 78ms/step - loss: 13.4388 - SMAPE: 25.1791 - val_loss: 6.1443 - val_SMAPE: 15.2454\n",
      "Epoch 31/200\n",
      "58/58 [==============================] - 4s 78ms/step - loss: 12.7155 - SMAPE: 23.7848 - val_loss: 6.5157 - val_SMAPE: 16.3340\n",
      "Epoch 32/200\n",
      "58/58 [==============================] - 5s 78ms/step - loss: 12.0354 - SMAPE: 21.9511 - val_loss: 5.8845 - val_SMAPE: 14.2741\n",
      "Epoch 33/200\n",
      "58/58 [==============================] - 5s 78ms/step - loss: 11.5271 - SMAPE: 21.1159 - val_loss: 5.7602 - val_SMAPE: 14.4704\n",
      "Epoch 34/200\n",
      "58/58 [==============================] - 5s 78ms/step - loss: 11.0460 - SMAPE: 20.1463 - val_loss: 6.3706 - val_SMAPE: 16.0944\n",
      "Epoch 35/200\n",
      "58/58 [==============================] - 5s 78ms/step - loss: 10.4260 - SMAPE: 18.8354 - val_loss: 6.9513 - val_SMAPE: 16.7232\n",
      "Epoch 36/200\n",
      "58/58 [==============================] - 5s 81ms/step - loss: 10.0501 - SMAPE: 18.4467 - val_loss: 6.7669 - val_SMAPE: 16.3920\n",
      "Epoch 37/200\n",
      "58/58 [==============================] - 5s 80ms/step - loss: 9.6106 - SMAPE: 17.3889 - val_loss: 6.2549 - val_SMAPE: 15.3314\n",
      "Epoch 38/200\n",
      "58/58 [==============================] - 5s 82ms/step - loss: 9.1800 - SMAPE: 16.3592 - val_loss: 6.0509 - val_SMAPE: 14.8547\n",
      "Epoch 39/200\n",
      "58/58 [==============================] - 5s 89ms/step - loss: 8.8092 - SMAPE: 15.6813 - val_loss: 4.9344 - val_SMAPE: 12.5177\n",
      "Epoch 40/200\n",
      "58/58 [==============================] - 5s 81ms/step - loss: 8.4294 - SMAPE: 14.9869 - val_loss: 4.4892 - val_SMAPE: 11.5279\n",
      "Epoch 41/200\n",
      "58/58 [==============================] - 5s 81ms/step - loss: 8.1055 - SMAPE: 14.8161 - val_loss: 4.9154 - val_SMAPE: 12.6447\n",
      "Epoch 42/200\n",
      "58/58 [==============================] - 5s 90ms/step - loss: 7.7638 - SMAPE: 14.0358 - val_loss: 4.7557 - val_SMAPE: 12.2463\n",
      "Epoch 43/200\n",
      "58/58 [==============================] - 5s 78ms/step - loss: 7.4789 - SMAPE: 13.4571 - val_loss: 4.1744 - val_SMAPE: 10.6562\n",
      "Epoch 44/200\n",
      "58/58 [==============================] - 4s 77ms/step - loss: 7.0869 - SMAPE: 12.8707 - val_loss: 4.3050 - val_SMAPE: 11.0990\n",
      "Epoch 45/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 6.8592 - SMAPE: 12.2133 - val_loss: 4.0398 - val_SMAPE: 10.4692\n",
      "Epoch 46/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 6.6029 - SMAPE: 11.9040 - val_loss: 4.0187 - val_SMAPE: 10.4885\n",
      "Epoch 47/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 6.3731 - SMAPE: 11.2724 - val_loss: 4.1091 - val_SMAPE: 10.7941\n",
      "Epoch 48/200\n",
      "58/58 [==============================] - 4s 69ms/step - loss: 6.2365 - SMAPE: 11.0751 - val_loss: 3.8580 - val_SMAPE: 10.0517\n",
      "Epoch 49/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 5.9498 - SMAPE: 10.6119 - val_loss: 4.0627 - val_SMAPE: 10.6839\n",
      "Epoch 50/200\n",
      "58/58 [==============================] - 4s 71ms/step - loss: 5.8950 - SMAPE: 10.4671 - val_loss: 3.9183 - val_SMAPE: 10.4531\n",
      "Epoch 51/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 5.6197 - SMAPE: 10.0507 - val_loss: 3.6973 - val_SMAPE: 9.6648\n",
      "Epoch 52/200\n",
      "58/58 [==============================] - 5s 77ms/step - loss: 5.4232 - SMAPE: 9.6615 - val_loss: 3.8229 - val_SMAPE: 10.0488\n",
      "Epoch 53/200\n",
      "58/58 [==============================] - 4s 71ms/step - loss: 5.2651 - SMAPE: 9.3385 - val_loss: 4.1180 - val_SMAPE: 11.0597\n",
      "Epoch 54/200\n",
      "58/58 [==============================] - 4s 71ms/step - loss: 5.1484 - SMAPE: 9.3999 - val_loss: 3.9368 - val_SMAPE: 10.4121\n",
      "Epoch 55/200\n",
      "58/58 [==============================] - 4s 66ms/step - loss: 5.1759 - SMAPE: 9.3046 - val_loss: 3.9705 - val_SMAPE: 10.3187\n",
      "Epoch 56/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 4.8979 - SMAPE: 8.7527 - val_loss: 3.4132 - val_SMAPE: 9.1312\n",
      "Epoch 57/200\n",
      "58/58 [==============================] - 4s 71ms/step - loss: 4.7182 - SMAPE: 8.4113 - val_loss: 3.6445 - val_SMAPE: 9.7054\n",
      "Epoch 58/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 4.6560 - SMAPE: 8.3379 - val_loss: 3.3392 - val_SMAPE: 9.1037\n",
      "Epoch 59/200\n",
      "58/58 [==============================] - 4s 68ms/step - loss: 4.4387 - SMAPE: 8.2393 - val_loss: 3.1976 - val_SMAPE: 8.7123\n",
      "Epoch 60/200\n",
      "58/58 [==============================] - 4s 67ms/step - loss: 4.3263 - SMAPE: 7.8962 - val_loss: 3.3558 - val_SMAPE: 9.2007\n",
      "Epoch 61/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 4.2467 - SMAPE: 7.7100 - val_loss: 3.3928 - val_SMAPE: 9.2684\n",
      "Epoch 62/200\n",
      "58/58 [==============================] - 4s 67ms/step - loss: 4.1374 - SMAPE: 7.4302 - val_loss: 3.3190 - val_SMAPE: 9.0055\n",
      "Epoch 63/200\n",
      "58/58 [==============================] - 4s 68ms/step - loss: 4.0673 - SMAPE: 7.4665 - val_loss: 3.3541 - val_SMAPE: 9.4891\n",
      "Epoch 64/200\n",
      "58/58 [==============================] - 4s 70ms/step - loss: 3.9087 - SMAPE: 7.0885 - val_loss: 3.2599 - val_SMAPE: 9.1016\n",
      "Epoch 65/200\n",
      "58/58 [==============================] - 4s 68ms/step - loss: 3.8604 - SMAPE: 6.9912 - val_loss: 3.0526 - val_SMAPE: 8.3714\n",
      "Epoch 66/200\n",
      "58/58 [==============================] - 4s 71ms/step - loss: 3.7342 - SMAPE: 6.8340 - val_loss: 3.1421 - val_SMAPE: 8.8317\n",
      "Epoch 67/200\n",
      "58/58 [==============================] - 4s 69ms/step - loss: 3.6954 - SMAPE: 6.7124 - val_loss: 2.9610 - val_SMAPE: 8.1296\n",
      "Epoch 68/200\n",
      "58/58 [==============================] - 4s 70ms/step - loss: 3.6173 - SMAPE: 6.5846 - val_loss: 3.0837 - val_SMAPE: 8.7798\n",
      "Epoch 69/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 3.6206 - SMAPE: 6.6930 - val_loss: 3.1051 - val_SMAPE: 8.5479\n",
      "Epoch 70/200\n",
      "58/58 [==============================] - 4s 71ms/step - loss: 3.5175 - SMAPE: 6.4420 - val_loss: 2.8956 - val_SMAPE: 8.0881\n",
      "Epoch 71/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 3.4583 - SMAPE: 6.2945 - val_loss: 3.2398 - val_SMAPE: 8.8425\n",
      "Epoch 72/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 3.4163 - SMAPE: 6.2996 - val_loss: 3.1181 - val_SMAPE: 8.8626\n",
      "Epoch 73/200\n",
      "58/58 [==============================] - 4s 71ms/step - loss: 3.3544 - SMAPE: 6.1328 - val_loss: 3.0145 - val_SMAPE: 8.2394\n",
      "Epoch 74/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 3.3245 - SMAPE: 6.1022 - val_loss: 3.3334 - val_SMAPE: 9.3292\n",
      "Epoch 75/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 3.2642 - SMAPE: 6.0311 - val_loss: 3.1102 - val_SMAPE: 8.6813\n",
      "Epoch 76/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 3.1888 - SMAPE: 5.9109 - val_loss: 3.1870 - val_SMAPE: 9.0147\n",
      "Epoch 77/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 3.1315 - SMAPE: 5.7972 - val_loss: 3.1131 - val_SMAPE: 8.4354\n",
      "Epoch 78/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 3.1420 - SMAPE: 5.8563 - val_loss: 3.0952 - val_SMAPE: 8.6696\n",
      "Epoch 79/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 3.0867 - SMAPE: 5.7489 - val_loss: 2.9827 - val_SMAPE: 8.4009\n",
      "Epoch 80/200\n",
      "58/58 [==============================] - 5s 78ms/step - loss: 3.0281 - SMAPE: 5.5720 - val_loss: 2.9404 - val_SMAPE: 8.2023\n"
     ]
    }
   ],
   "source": [
    "nn3 = compile_fit(nn, (X_train, y_train), (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSO</th>\n",
       "      <th>nn1</th>\n",
       "      <th>nn2</th>\n",
       "      <th>nn3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sMAPE_train</th>\n",
       "      <td>16.030</td>\n",
       "      <td>2.910315</td>\n",
       "      <td>3.962906</td>\n",
       "      <td>6.398275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sMAPE_val</th>\n",
       "      <td>16.922</td>\n",
       "      <td>4.179681</td>\n",
       "      <td>3.454599</td>\n",
       "      <td>7.789913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_train</th>\n",
       "      <td>0.954</td>\n",
       "      <td>0.980623</td>\n",
       "      <td>0.983838</td>\n",
       "      <td>0.869208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_val</th>\n",
       "      <td>0.971</td>\n",
       "      <td>0.977432</td>\n",
       "      <td>0.980697</td>\n",
       "      <td>0.853570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                TSO       nn1       nn2       nn3\n",
       "sMAPE_train  16.030  2.910315  3.962906  6.398275\n",
       "sMAPE_val    16.922  4.179681  3.454599  7.789913\n",
       "r2_train      0.954  0.980623  0.983838  0.869208\n",
       "r2_val        0.971  0.977432  0.980697  0.853570"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_actual['nn3'] = compute_metrics(nn3,(X_train,y_train), (X_val,y_val))\n",
    "results_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "# Instantiate model and build layers\n",
    "nn = models.Sequential()\n",
    "nn.add(layers.LSTM(83, activation='tanh', input_shape=input_shape))\n",
    "nn.add(layers.RepeatVector(y_train.shape[1]))\n",
    "nn.add(layers.LSTM(24, activation='tanh', return_sequences=True))\n",
    "nn.add(TimeDistributed(layers.Dense(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "58/58 [==============================] - 9s 115ms/step - loss: 53.0826 - SMAPE: 173.9812 - val_loss: 34.9559 - val_SMAPE: 142.9651\n",
      "Epoch 2/200\n",
      "58/58 [==============================] - 6s 109ms/step - loss: 49.5362 - SMAPE: 150.9076 - val_loss: 33.0619 - val_SMAPE: 128.9688\n",
      "Epoch 3/200\n",
      "58/58 [==============================] - 7s 114ms/step - loss: 47.8252 - SMAPE: 141.9558 - val_loss: 31.4508 - val_SMAPE: 117.9920\n",
      "Epoch 4/200\n",
      "58/58 [==============================] - 6s 109ms/step - loss: 46.2551 - SMAPE: 133.8312 - val_loss: 29.9100 - val_SMAPE: 108.1947\n",
      "Epoch 5/200\n",
      "58/58 [==============================] - 7s 120ms/step - loss: 44.7333 - SMAPE: 126.7064 - val_loss: 28.4060 - val_SMAPE: 99.2231\n",
      "Epoch 6/200\n",
      "58/58 [==============================] - 6s 112ms/step - loss: 43.2401 - SMAPE: 118.9267 - val_loss: 26.9321 - val_SMAPE: 90.9449\n",
      "Epoch 7/200\n",
      "58/58 [==============================] - 6s 111ms/step - loss: 41.7710 - SMAPE: 112.6276 - val_loss: 25.4815 - val_SMAPE: 83.2552\n",
      "Epoch 8/200\n",
      "58/58 [==============================] - 6s 111ms/step - loss: 40.3222 - SMAPE: 106.4034 - val_loss: 24.0542 - val_SMAPE: 76.0955\n",
      "Epoch 9/200\n",
      "58/58 [==============================] - 6s 111ms/step - loss: 38.8916 - SMAPE: 100.3831 - val_loss: 22.6485 - val_SMAPE: 69.4085\n",
      "Epoch 10/200\n",
      "58/58 [==============================] - 6s 109ms/step - loss: 37.4780 - SMAPE: 94.8776 - val_loss: 21.2707 - val_SMAPE: 63.1951\n",
      "Epoch 11/200\n",
      "58/58 [==============================] - 6s 110ms/step - loss: 36.0807 - SMAPE: 89.6828 - val_loss: 19.9223 - val_SMAPE: 57.4090\n",
      "Epoch 12/200\n",
      "58/58 [==============================] - 7s 115ms/step - loss: 34.6975 - SMAPE: 84.4981 - val_loss: 18.5981 - val_SMAPE: 52.0070\n",
      "Epoch 13/200\n",
      "58/58 [==============================] - 6s 111ms/step - loss: 33.3288 - SMAPE: 79.6008 - val_loss: 17.2992 - val_SMAPE: 46.9473\n",
      "Epoch 14/200\n",
      "58/58 [==============================] - 6s 110ms/step - loss: 31.9722 - SMAPE: 74.3512 - val_loss: 16.0288 - val_SMAPE: 42.2515\n",
      "Epoch 15/200\n",
      "58/58 [==============================] - 6s 110ms/step - loss: 30.6097 - SMAPE: 69.9676 - val_loss: 14.7871 - val_SMAPE: 38.0187\n",
      "Epoch 16/200\n",
      "58/58 [==============================] - 6s 110ms/step - loss: 29.2911 - SMAPE: 66.1647 - val_loss: 13.6569 - val_SMAPE: 34.2216\n",
      "Epoch 17/200\n",
      "58/58 [==============================] - 6s 103ms/step - loss: 27.9402 - SMAPE: 62.0668 - val_loss: 12.5522 - val_SMAPE: 30.8606\n",
      "Epoch 18/200\n",
      "58/58 [==============================] - 6s 104ms/step - loss: 26.6219 - SMAPE: 58.2891 - val_loss: 11.4426 - val_SMAPE: 27.7477\n",
      "Epoch 19/200\n",
      "58/58 [==============================] - 6s 105ms/step - loss: 25.3116 - SMAPE: 53.9854 - val_loss: 10.6455 - val_SMAPE: 25.7268\n",
      "Epoch 20/200\n",
      "58/58 [==============================] - 6s 100ms/step - loss: 24.0348 - SMAPE: 50.0483 - val_loss: 9.9129 - val_SMAPE: 23.9680\n",
      "Epoch 21/200\n",
      "58/58 [==============================] - 5s 92ms/step - loss: 22.8120 - SMAPE: 47.1704 - val_loss: 9.3150 - val_SMAPE: 22.5713\n",
      "Epoch 22/200\n",
      "58/58 [==============================] - 5s 95ms/step - loss: 21.6637 - SMAPE: 43.9233 - val_loss: 8.5308 - val_SMAPE: 20.7063\n",
      "Epoch 23/200\n",
      "58/58 [==============================] - 5s 90ms/step - loss: 20.4143 - SMAPE: 41.2565 - val_loss: 7.5838 - val_SMAPE: 17.9901\n",
      "Epoch 24/200\n",
      "58/58 [==============================] - 5s 88ms/step - loss: 19.2503 - SMAPE: 38.6822 - val_loss: 7.2330 - val_SMAPE: 17.3220\n",
      "Epoch 25/200\n",
      "58/58 [==============================] - 5s 89ms/step - loss: 18.1064 - SMAPE: 35.1629 - val_loss: 6.7119 - val_SMAPE: 16.1162\n",
      "Epoch 26/200\n",
      "58/58 [==============================] - 5s 88ms/step - loss: 17.0871 - SMAPE: 33.3659 - val_loss: 6.6001 - val_SMAPE: 16.2012\n",
      "Epoch 27/200\n",
      "58/58 [==============================] - 5s 88ms/step - loss: 16.0338 - SMAPE: 30.3473 - val_loss: 6.1709 - val_SMAPE: 15.2121\n",
      "Epoch 28/200\n",
      "58/58 [==============================] - 5s 88ms/step - loss: 15.1046 - SMAPE: 28.8735 - val_loss: 6.5177 - val_SMAPE: 16.5046\n",
      "Epoch 29/200\n",
      "58/58 [==============================] - 5s 91ms/step - loss: 14.2719 - SMAPE: 26.5232 - val_loss: 6.1015 - val_SMAPE: 15.2303\n",
      "Epoch 30/200\n",
      "58/58 [==============================] - 6s 99ms/step - loss: 13.5406 - SMAPE: 25.0490 - val_loss: 6.8308 - val_SMAPE: 17.8982\n",
      "Epoch 31/200\n",
      "58/58 [==============================] - 5s 93ms/step - loss: 13.0750 - SMAPE: 24.0811 - val_loss: 8.5015 - val_SMAPE: 23.0571\n",
      "Epoch 32/200\n",
      "58/58 [==============================] - 5s 92ms/step - loss: 12.2835 - SMAPE: 22.8935 - val_loss: 8.0141 - val_SMAPE: 20.5470\n",
      "Epoch 33/200\n",
      "58/58 [==============================] - 6s 97ms/step - loss: 11.6586 - SMAPE: 21.3427 - val_loss: 6.2931 - val_SMAPE: 15.8071\n",
      "Epoch 34/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 11.1574 - SMAPE: 20.6124 - val_loss: 6.8705 - val_SMAPE: 17.3878\n",
      "Epoch 35/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 10.5446 - SMAPE: 19.4753 - val_loss: 6.5463 - val_SMAPE: 16.2771\n",
      "Epoch 36/200\n",
      "58/58 [==============================] - 6s 97ms/step - loss: 10.1086 - SMAPE: 18.1892 - val_loss: 6.0280 - val_SMAPE: 15.3112\n",
      "Epoch 37/200\n",
      "58/58 [==============================] - 6s 99ms/step - loss: 9.6774 - SMAPE: 17.4095 - val_loss: 6.5858 - val_SMAPE: 16.7705\n"
     ]
    }
   ],
   "source": [
    "nn4 = compile_fit(nn, (X_train, y_train), (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSO</th>\n",
       "      <th>nn1</th>\n",
       "      <th>nn2</th>\n",
       "      <th>nn3</th>\n",
       "      <th>nn4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sMAPE_train</th>\n",
       "      <td>16.030</td>\n",
       "      <td>2.910315</td>\n",
       "      <td>3.962906</td>\n",
       "      <td>6.398275</td>\n",
       "      <td>29.473468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sMAPE_val</th>\n",
       "      <td>16.922</td>\n",
       "      <td>4.179681</td>\n",
       "      <td>3.454599</td>\n",
       "      <td>7.789913</td>\n",
       "      <td>15.500838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_train</th>\n",
       "      <td>0.954</td>\n",
       "      <td>0.980623</td>\n",
       "      <td>0.983838</td>\n",
       "      <td>0.869208</td>\n",
       "      <td>0.234718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_val</th>\n",
       "      <td>0.971</td>\n",
       "      <td>0.977432</td>\n",
       "      <td>0.980697</td>\n",
       "      <td>0.853570</td>\n",
       "      <td>0.365850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                TSO       nn1       nn2       nn3        nn4\n",
       "sMAPE_train  16.030  2.910315  3.962906  6.398275  29.473468\n",
       "sMAPE_val    16.922  4.179681  3.454599  7.789913  15.500838\n",
       "r2_train      0.954  0.980623  0.983838  0.869208   0.234718\n",
       "r2_val        0.971  0.977432  0.980697  0.853570   0.365850"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_actual['nn4'] = compute_metrics(nn4,(X_train,y_train), (X_val,y_val))\n",
    "results_actual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Model (LSTM-DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and validation\n",
    "X_train, y_train, X_val, y_val = split_data(df_lag.drop(columns=price_drop), 2020, 'price_actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the x cols for lstm network, lagged cols\n",
    "X_train_lstm = X_train.filter(regex='lag')\n",
    "X_train_dnn = X_train.drop(columns=X_train_lstm.columns)\n",
    "\n",
    "# Get the x cols for dnn network, forecast cols\n",
    "X_val_lstm = X_val.filter(regex='lag')\n",
    "X_val_dnn = X_val.drop(columns=X_val_lstm.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorganize the training and testing data into batches\n",
    "X_train_dnn, y_train_dnn = resample((X_train_dnn, y_train), 24, 24, 24)\n",
    "X_val_dnn, y_val_dnn = resample((X_val_dnn, y_val), 24, 24, 24)\n",
    "\n",
    "# LSTM\n",
    "X_train_lstm, y_train_lstm = resample((X_train_lstm, y_train), 24, 24, 24)\n",
    "X_val_lstm, y_val_lstm = resample((X_val_lstm, y_val), 24, 24, 24)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (X_train_dnn.shape[1], X_train_dnn.shape[2])\n",
    "# Instantiate model and build layers\n",
    "nn = models.Sequential()\n",
    "nn.add(layers.Dense(59, activation='relu', input_shape=input_shape))\n",
    "nn.add(layers.Dense(239, activation='relu'))\n",
    "nn.add(layers.Dense(162, activation='relu'))\n",
    "nn.add(TimeDistributed(layers.Dense(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 8.8587 - SMAPE: 22.0936 - val_loss: 1.9343 - val_SMAPE: 7.1471\n",
      "Epoch 2/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 2.7592 - SMAPE: 6.2133 - val_loss: 2.1643 - val_SMAPE: 6.3035\n",
      "Epoch 3/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 2.5873 - SMAPE: 5.3551 - val_loss: 3.7219 - val_SMAPE: 9.7954\n",
      "Epoch 4/200\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 2.6200 - SMAPE: 5.1111 - val_loss: 1.8945 - val_SMAPE: 5.8856\n",
      "Epoch 5/200\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 2.3450 - SMAPE: 4.5875 - val_loss: 2.3989 - val_SMAPE: 6.9441\n",
      "Epoch 6/200\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 2.3966 - SMAPE: 4.6159 - val_loss: 2.5255 - val_SMAPE: 7.2377\n",
      "Epoch 7/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 2.2005 - SMAPE: 4.2830 - val_loss: 1.8122 - val_SMAPE: 5.5049\n",
      "Epoch 8/200\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 2.4035 - SMAPE: 4.5953 - val_loss: 3.6721 - val_SMAPE: 9.7363\n",
      "Epoch 9/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 2.1787 - SMAPE: 4.1744 - val_loss: 2.1163 - val_SMAPE: 6.2281\n",
      "Epoch 10/200\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 2.2490 - SMAPE: 4.2831 - val_loss: 3.3664 - val_SMAPE: 8.9449\n",
      "Epoch 11/200\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 2.2419 - SMAPE: 4.2653 - val_loss: 2.9761 - val_SMAPE: 8.1303\n",
      "Epoch 12/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 2.1473 - SMAPE: 4.3315 - val_loss: 2.0925 - val_SMAPE: 6.0507\n",
      "Epoch 13/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 2.2407 - SMAPE: 4.3257 - val_loss: 4.0334 - val_SMAPE: 10.5091\n",
      "Epoch 14/200\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 2.3536 - SMAPE: 4.5180 - val_loss: 3.8712 - val_SMAPE: 10.1265\n",
      "Epoch 15/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 2.1658 - SMAPE: 4.1148 - val_loss: 3.4934 - val_SMAPE: 9.2750\n",
      "Epoch 16/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 2.1524 - SMAPE: 4.1160 - val_loss: 3.0157 - val_SMAPE: 8.1908\n",
      "Epoch 17/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 2.2919 - SMAPE: 4.3125 - val_loss: 3.0206 - val_SMAPE: 8.2461\n"
     ]
    }
   ],
   "source": [
    "dnn = compile_fit(nn, (X_train_dnn, y_train_dnn), (X_val_dnn, y_val_dnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.156025545421572, 5.529825922826223, 0.9587082867775397, 0.9592410961929292]"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(dnn, (X_train_dnn, y_train_dnn), (X_val_dnn, y_val_dnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "58/58 [==============================] - 4s 32ms/step - loss: 52.4887 - SMAPE: 170.0182 - val_loss: 32.4569 - val_SMAPE: 137.9465\n",
      "Epoch 2/200\n",
      "58/58 [==============================] - 1s 23ms/step - loss: 49.1854 - SMAPE: 149.8244 - val_loss: 30.5765 - val_SMAPE: 124.0315\n",
      "Epoch 3/200\n",
      "58/58 [==============================] - 1s 23ms/step - loss: 47.4650 - SMAPE: 140.6329 - val_loss: 28.9659 - val_SMAPE: 113.1006\n",
      "Epoch 4/200\n",
      "58/58 [==============================] - 1s 24ms/step - loss: 45.8898 - SMAPE: 132.3641 - val_loss: 27.4319 - val_SMAPE: 103.4150\n",
      "Epoch 5/200\n",
      "58/58 [==============================] - 1s 24ms/step - loss: 44.3654 - SMAPE: 124.6539 - val_loss: 25.9401 - val_SMAPE: 94.6012\n",
      "Epoch 6/200\n",
      "58/58 [==============================] - 1s 23ms/step - loss: 42.8722 - SMAPE: 117.7993 - val_loss: 24.4839 - val_SMAPE: 86.5248\n",
      "Epoch 7/200\n",
      "58/58 [==============================] - 1s 23ms/step - loss: 41.4040 - SMAPE: 110.9791 - val_loss: 23.0612 - val_SMAPE: 79.0947\n",
      "Epoch 8/200\n",
      "58/58 [==============================] - 1s 25ms/step - loss: 39.9570 - SMAPE: 105.0027 - val_loss: 21.6703 - val_SMAPE: 72.2325\n",
      "Epoch 9/200\n",
      "58/58 [==============================] - 1s 24ms/step - loss: 38.5276 - SMAPE: 98.9514 - val_loss: 20.3150 - val_SMAPE: 65.8997\n",
      "Epoch 10/200\n",
      "58/58 [==============================] - 1s 23ms/step - loss: 37.1170 - SMAPE: 93.4059 - val_loss: 19.0003 - val_SMAPE: 60.0724\n",
      "Epoch 11/200\n",
      "58/58 [==============================] - 1s 26ms/step - loss: 35.7219 - SMAPE: 87.8896 - val_loss: 17.7327 - val_SMAPE: 54.7382\n",
      "Epoch 12/200\n",
      "58/58 [==============================] - 1s 23ms/step - loss: 34.3416 - SMAPE: 83.1769 - val_loss: 16.5120 - val_SMAPE: 49.8477\n",
      "Epoch 13/200\n",
      "58/58 [==============================] - 1s 23ms/step - loss: 32.9752 - SMAPE: 77.5979 - val_loss: 15.3496 - val_SMAPE: 45.4004\n",
      "Epoch 14/200\n",
      "58/58 [==============================] - 1s 23ms/step - loss: 31.6196 - SMAPE: 73.9414 - val_loss: 14.2614 - val_SMAPE: 41.4189\n",
      "Epoch 15/200\n",
      "58/58 [==============================] - 1s 23ms/step - loss: 30.2814 - SMAPE: 69.1114 - val_loss: 13.2353 - val_SMAPE: 37.8200\n",
      "Epoch 16/200\n",
      "58/58 [==============================] - 1s 23ms/step - loss: 28.9585 - SMAPE: 65.3610 - val_loss: 12.3003 - val_SMAPE: 34.6622\n",
      "Epoch 17/200\n",
      "58/58 [==============================] - 1s 24ms/step - loss: 27.6586 - SMAPE: 61.0043 - val_loss: 11.4693 - val_SMAPE: 31.9523\n",
      "Epoch 18/200\n",
      "58/58 [==============================] - 1s 23ms/step - loss: 26.3815 - SMAPE: 57.1770 - val_loss: 10.7598 - val_SMAPE: 29.7085\n",
      "Epoch 19/200\n",
      "58/58 [==============================] - 1s 23ms/step - loss: 25.1292 - SMAPE: 54.1115 - val_loss: 10.1801 - val_SMAPE: 27.9193\n",
      "Epoch 20/200\n",
      "58/58 [==============================] - 1s 24ms/step - loss: 23.9029 - SMAPE: 50.3400 - val_loss: 9.7361 - val_SMAPE: 26.5676\n",
      "Epoch 21/200\n",
      "58/58 [==============================] - 1s 23ms/step - loss: 22.7066 - SMAPE: 46.7188 - val_loss: 9.4131 - val_SMAPE: 25.5827\n",
      "Epoch 22/200\n",
      "58/58 [==============================] - 1s 23ms/step - loss: 21.5495 - SMAPE: 44.0158 - val_loss: 9.2052 - val_SMAPE: 24.9262\n",
      "Epoch 23/200\n",
      "58/58 [==============================] - 1s 23ms/step - loss: 20.4248 - SMAPE: 42.8674 - val_loss: 9.0999 - val_SMAPE: 24.5477\n",
      "Epoch 24/200\n",
      "58/58 [==============================] - 1s 23ms/step - loss: 19.3789 - SMAPE: 38.3082 - val_loss: 9.0922 - val_SMAPE: 24.4332\n",
      "Epoch 25/200\n",
      "58/58 [==============================] - 1s 24ms/step - loss: 18.3588 - SMAPE: 35.8953 - val_loss: 9.1849 - val_SMAPE: 24.5629\n",
      "Epoch 26/200\n",
      "58/58 [==============================] - 1s 25ms/step - loss: 17.4013 - SMAPE: 33.6690 - val_loss: 9.3775 - val_SMAPE: 24.9171\n",
      "Epoch 27/200\n",
      "58/58 [==============================] - 1s 24ms/step - loss: 16.5028 - SMAPE: 32.0531 - val_loss: 9.6610 - val_SMAPE: 25.4624\n",
      "Epoch 28/200\n",
      "58/58 [==============================] - 2s 26ms/step - loss: 15.6800 - SMAPE: 30.4062 - val_loss: 10.0272 - val_SMAPE: 26.1683\n",
      "Epoch 29/200\n",
      "58/58 [==============================] - 1s 23ms/step - loss: 14.9289 - SMAPE: 28.1898 - val_loss: 10.4515 - val_SMAPE: 26.9792\n",
      "Epoch 30/200\n",
      "58/58 [==============================] - 1s 22ms/step - loss: 14.2632 - SMAPE: 26.8545 - val_loss: 10.9229 - val_SMAPE: 27.8727\n",
      "Epoch 31/200\n",
      "58/58 [==============================] - 1s 22ms/step - loss: 13.6686 - SMAPE: 25.6133 - val_loss: 11.4219 - val_SMAPE: 28.8048\n",
      "Epoch 32/200\n",
      "58/58 [==============================] - 1s 23ms/step - loss: 13.1487 - SMAPE: 24.3972 - val_loss: 11.9504 - val_SMAPE: 29.7815\n",
      "Epoch 33/200\n",
      "58/58 [==============================] - 1s 24ms/step - loss: 12.7161 - SMAPE: 23.5019 - val_loss: 12.4649 - val_SMAPE: 30.7194\n",
      "Epoch 34/200\n",
      "58/58 [==============================] - 1s 25ms/step - loss: 12.3491 - SMAPE: 22.8559 - val_loss: 12.9633 - val_SMAPE: 31.6176\n"
     ]
    }
   ],
   "source": [
    "input_shape = (X_train_lstm.shape[1], X_train_lstm.shape[2])\n",
    "# Instantiate model and build layers\n",
    "nn = models.Sequential()\n",
    "nn.add(layers.LSTM(83, activation='tanh', input_shape=input_shape))\n",
    "nn.add(layers.RepeatVector(y_train_lstm.shape[1]))\n",
    "nn.add(layers.LSTM(24, activation='tanh', return_sequences=True))\n",
    "nn.add(TimeDistributed(layers.Dense(1)))\n",
    "\n",
    "lstm = compile_fit(nn, (X_train_lstm, y_train_lstm), (X_val_lstm, y_val_lstm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn5 = ensemble_nn([dnn, lstm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "58/58 [==============================] - 3s 19ms/step - loss: 2.0467 - SMAPE: 3.9244 - val_loss: 2.8477 - val_SMAPE: 7.9937\n",
      "Epoch 2/200\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 2.0353 - SMAPE: 3.9383 - val_loss: 2.6392 - val_SMAPE: 7.4816\n",
      "Epoch 3/200\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 2.0987 - SMAPE: 4.0259 - val_loss: 3.1108 - val_SMAPE: 8.5925\n",
      "Epoch 4/200\n",
      "58/58 [==============================] - 1s 12ms/step - loss: 2.0396 - SMAPE: 3.9123 - val_loss: 2.8235 - val_SMAPE: 7.9280\n",
      "Epoch 5/200\n",
      "58/58 [==============================] - 1s 12ms/step - loss: 2.0362 - SMAPE: 3.9659 - val_loss: 2.8346 - val_SMAPE: 7.9490\n",
      "Epoch 6/200\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 2.0499 - SMAPE: 3.9636 - val_loss: 2.7079 - val_SMAPE: 7.6538\n",
      "Epoch 7/200\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 2.0358 - SMAPE: 3.9406 - val_loss: 2.4815 - val_SMAPE: 7.0973\n",
      "Epoch 8/200\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 2.0589 - SMAPE: 4.0033 - val_loss: 2.8991 - val_SMAPE: 8.1163\n",
      "Epoch 9/200\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 2.0579 - SMAPE: 3.9692 - val_loss: 2.6812 - val_SMAPE: 7.5828\n",
      "Epoch 10/200\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 2.0379 - SMAPE: 4.0142 - val_loss: 3.2973 - val_SMAPE: 9.0543\n",
      "Epoch 11/200\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 2.0913 - SMAPE: 4.1511 - val_loss: 2.8279 - val_SMAPE: 7.9306\n",
      "Epoch 12/200\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 2.0792 - SMAPE: 4.0283 - val_loss: 2.7650 - val_SMAPE: 7.7813\n",
      "Epoch 13/200\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 2.0498 - SMAPE: 3.9632 - val_loss: 3.0836 - val_SMAPE: 8.5448\n",
      "Epoch 14/200\n",
      "58/58 [==============================] - 1s 12ms/step - loss: 2.0654 - SMAPE: 4.0741 - val_loss: 3.0295 - val_SMAPE: 8.4249\n",
      "Epoch 15/200\n",
      "58/58 [==============================] - 1s 12ms/step - loss: 2.0317 - SMAPE: 4.0362 - val_loss: 2.8081 - val_SMAPE: 7.8889\n",
      "Epoch 16/200\n",
      "58/58 [==============================] - 1s 12ms/step - loss: 2.0492 - SMAPE: 4.2498 - val_loss: 3.0313 - val_SMAPE: 8.4187\n",
      "Epoch 17/200\n",
      "58/58 [==============================] - 1s 12ms/step - loss: 2.0359 - SMAPE: 3.9331 - val_loss: 3.2034 - val_SMAPE: 8.8367\n"
     ]
    }
   ],
   "source": [
    "ensemble = compile_fit(nn5, ([X_train_dnn, X_train_lstm], y_train_dnn), ([X_val_dnn, X_val_lstm], y_val_dnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.092027495943533, 7.146394956377796, 0.9588267237215046, 0.9596074221172163]"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(ensemble, ([X_train_dnn, X_train_lstm], y_train_dnn), ([X_val_dnn, X_val_lstm], y_val_dnn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REPEAT BUT WITH NEW DNN and LSTM as provided by the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and validation\n",
    "X_train, y_train, X_val, y_val = split_data(df_lag.drop(columns=price_drop), 2020, 'price_actual')\n",
    "\n",
    "# Get the x cols for lstm network, lagged cols\n",
    "X_train_lstm = X_train.filter(regex='lag')\n",
    "X_train_dnn = X_train.drop(columns=X_train_lstm.columns)\n",
    "\n",
    "# Get the x cols for dnn network, forecast cols\n",
    "X_val_lstm = X_val.filter(regex='lag')\n",
    "X_val_dnn = X_val.drop(columns=X_val_lstm.columns)\n",
    "\n",
    "# Reorganize the training and testing data into batches\n",
    "X_train_dnn, y_train_dnn = resample((X_train_dnn, y_train), 24, 24, 24)\n",
    "X_val_dnn, y_val_dnn = resample((X_val_dnn, y_val), 24, 24, 24)\n",
    "\n",
    "# LSTM\n",
    "X_train_lstm, y_train_lstm = resample((X_train_lstm, y_train), 24*7, 24, 24)\n",
    "X_val_lstm, y_val_lstm = resample((X_val_lstm, y_val), 24*7, 24, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "58/58 [==============================] - 1s 5ms/step - loss: 12.1998 - SMAPE: 31.6851 - val_loss: 2.0293 - val_SMAPE: 7.7098\n",
      "Epoch 2/200\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 2.8323 - SMAPE: 6.6092 - val_loss: 1.8841 - val_SMAPE: 6.4578\n",
      "Epoch 3/200\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 2.6425 - SMAPE: 5.7300 - val_loss: 1.8081 - val_SMAPE: 5.5943\n",
      "Epoch 4/200\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 2.4959 - SMAPE: 5.0317 - val_loss: 2.0479 - val_SMAPE: 6.3141\n",
      "Epoch 5/200\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 2.4786 - SMAPE: 4.9195 - val_loss: 3.2881 - val_SMAPE: 9.0273\n",
      "Epoch 6/200\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 2.4749 - SMAPE: 4.9809 - val_loss: 2.1763 - val_SMAPE: 6.4997\n",
      "Epoch 7/200\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 2.2631 - SMAPE: 4.5334 - val_loss: 2.4584 - val_SMAPE: 7.1421\n",
      "Epoch 8/200\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 2.2712 - SMAPE: 4.5981 - val_loss: 2.5669 - val_SMAPE: 7.4399\n",
      "Epoch 9/200\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 2.2303 - SMAPE: 4.3549 - val_loss: 3.0633 - val_SMAPE: 8.4844\n",
      "Epoch 10/200\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 2.2809 - SMAPE: 4.4076 - val_loss: 2.0590 - val_SMAPE: 6.2013\n",
      "Epoch 11/200\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 2.2246 - SMAPE: 4.2875 - val_loss: 1.9352 - val_SMAPE: 5.8788\n",
      "Epoch 12/200\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 2.2211 - SMAPE: 4.3898 - val_loss: 2.9989 - val_SMAPE: 8.2988\n",
      "Epoch 13/200\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 2.2851 - SMAPE: 4.3705 - val_loss: 2.7882 - val_SMAPE: 7.7487\n"
     ]
    }
   ],
   "source": [
    "# Define dnn input shape\n",
    "input_shape = (X_train_dnn.shape[1], X_train_dnn.shape[2])\n",
    "\n",
    "# Instantiate model and build layers\n",
    "nn = models.Sequential()\n",
    "nn.add(layers.Dense(59, activation='relu', input_shape=input_shape))\n",
    "nn.add(layers.Dense(184, activation='relu'))\n",
    "nn.add(TimeDistributed(layers.Dense(1)))\n",
    "\n",
    "dnn = compile_fit(nn, (X_train_dnn, y_train_dnn), (X_val_dnn, y_val_dnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "58/58 [==============================] - 7s 88ms/step - loss: 52.3485 - SMAPE: 169.1976 - val_loss: 32.6204 - val_SMAPE: 139.2095\n",
      "Epoch 2/200\n",
      "58/58 [==============================] - 5s 83ms/step - loss: 49.4839 - SMAPE: 151.6029 - val_loss: 30.9504 - val_SMAPE: 126.6914\n",
      "Epoch 3/200\n",
      "58/58 [==============================] - 5s 85ms/step - loss: 47.8517 - SMAPE: 142.4603 - val_loss: 29.3624 - val_SMAPE: 115.7127\n",
      "Epoch 4/200\n",
      "58/58 [==============================] - 6s 102ms/step - loss: 46.2972 - SMAPE: 134.0880 - val_loss: 27.8452 - val_SMAPE: 105.9593\n",
      "Epoch 5/200\n",
      "58/58 [==============================] - 6s 111ms/step - loss: 44.7869 - SMAPE: 126.8512 - val_loss: 26.3623 - val_SMAPE: 97.0376\n",
      "Epoch 6/200\n",
      "58/58 [==============================] - 7s 115ms/step - loss: 43.3027 - SMAPE: 119.7703 - val_loss: 24.9107 - val_SMAPE: 88.8404\n",
      "Epoch 7/200\n",
      "58/58 [==============================] - 6s 103ms/step - loss: 41.8404 - SMAPE: 112.9714 - val_loss: 23.4879 - val_SMAPE: 81.2774\n",
      "Epoch 8/200\n",
      "58/58 [==============================] - 6s 106ms/step - loss: 40.3973 - SMAPE: 106.7365 - val_loss: 22.0974 - val_SMAPE: 74.2992\n",
      "Epoch 9/200\n",
      "58/58 [==============================] - 6s 104ms/step - loss: 38.9717 - SMAPE: 99.3866 - val_loss: 20.7388 - val_SMAPE: 67.8435\n",
      "Epoch 10/200\n",
      "58/58 [==============================] - 6s 105ms/step - loss: 37.5784 - SMAPE: 95.1006 - val_loss: 19.4339 - val_SMAPE: 61.9610\n",
      "Epoch 11/200\n",
      "58/58 [==============================] - 6s 110ms/step - loss: 36.1867 - SMAPE: 89.7480 - val_loss: 18.1529 - val_SMAPE: 56.4767\n",
      "Epoch 12/200\n",
      "58/58 [==============================] - 7s 123ms/step - loss: 34.8050 - SMAPE: 84.9995 - val_loss: 16.9186 - val_SMAPE: 51.4513\n",
      "Epoch 13/200\n",
      "58/58 [==============================] - 8s 133ms/step - loss: 33.4376 - SMAPE: 79.9062 - val_loss: 15.7400 - val_SMAPE: 46.8715\n",
      "Epoch 14/200\n",
      "58/58 [==============================] - 7s 124ms/step - loss: 32.0818 - SMAPE: 75.3390 - val_loss: 14.6288 - val_SMAPE: 42.7431\n",
      "Epoch 15/200\n",
      "58/58 [==============================] - 7s 126ms/step - loss: 30.7407 - SMAPE: 70.8725 - val_loss: 13.5840 - val_SMAPE: 39.0268\n",
      "Epoch 16/200\n",
      "58/58 [==============================] - 7s 124ms/step - loss: 29.4156 - SMAPE: 66.2216 - val_loss: 12.6153 - val_SMAPE: 35.7128\n",
      "Epoch 17/200\n",
      "58/58 [==============================] - 7s 127ms/step - loss: 28.1102 - SMAPE: 62.7919 - val_loss: 11.7468 - val_SMAPE: 32.8473\n",
      "Epoch 18/200\n",
      "58/58 [==============================] - 9s 151ms/step - loss: 26.8264 - SMAPE: 58.9374 - val_loss: 10.9942 - val_SMAPE: 30.4422\n",
      "Epoch 19/200\n",
      "58/58 [==============================] - 10s 165ms/step - loss: 25.5661 - SMAPE: 55.0141 - val_loss: 10.3696 - val_SMAPE: 28.5000\n",
      "Epoch 20/200\n",
      "58/58 [==============================] - 9s 152ms/step - loss: 24.3340 - SMAPE: 51.7216 - val_loss: 9.8766 - val_SMAPE: 26.9944\n",
      "Epoch 21/200\n",
      "58/58 [==============================] - 9s 154ms/step - loss: 23.1265 - SMAPE: 48.2979 - val_loss: 9.5155 - val_SMAPE: 25.8959\n",
      "Epoch 22/200\n",
      "58/58 [==============================] - 9s 155ms/step - loss: 21.9545 - SMAPE: 44.9614 - val_loss: 9.2660 - val_SMAPE: 25.1238\n",
      "Epoch 23/200\n",
      "58/58 [==============================] - 10s 172ms/step - loss: 20.8175 - SMAPE: 42.5345 - val_loss: 9.1260 - val_SMAPE: 24.6511\n",
      "Epoch 24/200\n",
      "58/58 [==============================] - 9s 150ms/step - loss: 19.7210 - SMAPE: 39.9236 - val_loss: 9.0847 - val_SMAPE: 24.4446\n",
      "Epoch 25/200\n",
      "58/58 [==============================] - 8s 130ms/step - loss: 18.6729 - SMAPE: 36.8675 - val_loss: 9.1456 - val_SMAPE: 24.4984\n",
      "Epoch 26/200\n",
      "58/58 [==============================] - 8s 134ms/step - loss: 17.6877 - SMAPE: 34.5324 - val_loss: 9.3067 - val_SMAPE: 24.7828\n",
      "Epoch 27/200\n",
      "58/58 [==============================] - 9s 147ms/step - loss: 16.7692 - SMAPE: 32.5412 - val_loss: 9.5662 - val_SMAPE: 25.2797\n",
      "Epoch 28/200\n",
      "58/58 [==============================] - 8s 136ms/step - loss: 15.9252 - SMAPE: 30.5805 - val_loss: 9.9059 - val_SMAPE: 25.9349\n",
      "Epoch 29/200\n",
      "58/58 [==============================] - 7s 128ms/step - loss: 15.1522 - SMAPE: 28.9963 - val_loss: 10.3127 - val_SMAPE: 26.7147\n",
      "Epoch 30/200\n",
      "58/58 [==============================] - 8s 142ms/step - loss: 14.4610 - SMAPE: 27.2027 - val_loss: 10.7753 - val_SMAPE: 27.5943\n",
      "Epoch 31/200\n",
      "58/58 [==============================] - 8s 133ms/step - loss: 13.8490 - SMAPE: 25.8313 - val_loss: 11.2566 - val_SMAPE: 28.4972\n",
      "Epoch 32/200\n",
      "58/58 [==============================] - 8s 133ms/step - loss: 13.3136 - SMAPE: 24.7386 - val_loss: 11.7689 - val_SMAPE: 29.4477\n",
      "Epoch 33/200\n",
      "58/58 [==============================] - 7s 125ms/step - loss: 12.8478 - SMAPE: 24.2420 - val_loss: 12.3041 - val_SMAPE: 30.4273\n",
      "Epoch 34/200\n",
      "58/58 [==============================] - 7s 117ms/step - loss: 12.4458 - SMAPE: 23.5942 - val_loss: 12.8331 - val_SMAPE: 31.3840\n"
     ]
    }
   ],
   "source": [
    "# Define lstm input shape\n",
    "input_shape = (X_train_lstm.shape[1], X_train_lstm.shape[2])\n",
    "\n",
    "# Instantiate model and build layers\n",
    "nn = models.Sequential()\n",
    "nn.add(layers.LSTM(83, activation='tanh', input_shape=input_shape))\n",
    "nn.add(layers.RepeatVector(y_train_lstm.shape[1]))\n",
    "nn.add(layers.LSTM(24, activation='tanh', return_sequences=True))\n",
    "nn.add(TimeDistributed(layers.Dense(1)))\n",
    "\n",
    "lstm = compile_fit(nn, (X_train_lstm, y_train_lstm), (X_val_lstm, y_val_lstm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "58/58 [==============================] - 5s 49ms/step - loss: 48.8106 - SMAPE: 152.4004 - val_loss: 25.1914 - val_SMAPE: 95.4864\n",
      "Epoch 2/200\n",
      "58/58 [==============================] - 2s 41ms/step - loss: 25.9820 - SMAPE: 60.0860 - val_loss: 5.1566 - val_SMAPE: 13.1575\n",
      "Epoch 3/200\n",
      "58/58 [==============================] - 2s 41ms/step - loss: 4.5506 - SMAPE: 8.4486 - val_loss: 4.5524 - val_SMAPE: 12.5807\n",
      "Epoch 4/200\n",
      "58/58 [==============================] - 2s 41ms/step - loss: 2.5549 - SMAPE: 4.9189 - val_loss: 4.2453 - val_SMAPE: 11.4921\n",
      "Epoch 5/200\n",
      "58/58 [==============================] - 2s 41ms/step - loss: 2.3918 - SMAPE: 4.5476 - val_loss: 3.7181 - val_SMAPE: 10.0014\n",
      "Epoch 6/200\n",
      "58/58 [==============================] - 2s 42ms/step - loss: 2.2978 - SMAPE: 4.4350 - val_loss: 3.3594 - val_SMAPE: 9.0714\n",
      "Epoch 7/200\n",
      "58/58 [==============================] - 2s 42ms/step - loss: 2.2374 - SMAPE: 4.2825 - val_loss: 3.3860 - val_SMAPE: 9.1491\n",
      "Epoch 8/200\n",
      "58/58 [==============================] - 2s 42ms/step - loss: 2.1948 - SMAPE: 4.2185 - val_loss: 3.2526 - val_SMAPE: 8.8492\n",
      "Epoch 9/200\n",
      "58/58 [==============================] - 2s 43ms/step - loss: 2.1696 - SMAPE: 4.1611 - val_loss: 3.1300 - val_SMAPE: 8.5682\n",
      "Epoch 10/200\n",
      "58/58 [==============================] - 2s 41ms/step - loss: 2.1615 - SMAPE: 4.3964 - val_loss: 2.9795 - val_SMAPE: 8.2054\n",
      "Epoch 11/200\n",
      "58/58 [==============================] - 2s 41ms/step - loss: 2.1466 - SMAPE: 4.1154 - val_loss: 2.9447 - val_SMAPE: 8.1094\n",
      "Epoch 12/200\n",
      "58/58 [==============================] - 2s 41ms/step - loss: 2.1443 - SMAPE: 4.2284 - val_loss: 2.8840 - val_SMAPE: 7.9829\n",
      "Epoch 13/200\n",
      "58/58 [==============================] - 2s 43ms/step - loss: 2.1427 - SMAPE: 4.1157 - val_loss: 2.8816 - val_SMAPE: 7.9870\n",
      "Epoch 14/200\n",
      "58/58 [==============================] - 2s 42ms/step - loss: 2.1459 - SMAPE: 4.1063 - val_loss: 2.9070 - val_SMAPE: 8.0611\n",
      "Epoch 15/200\n",
      "58/58 [==============================] - 2s 42ms/step - loss: 2.1363 - SMAPE: 4.1035 - val_loss: 2.8059 - val_SMAPE: 7.8110\n",
      "Epoch 16/200\n",
      "58/58 [==============================] - 3s 43ms/step - loss: 2.1469 - SMAPE: 4.1158 - val_loss: 2.8624 - val_SMAPE: 7.9710\n",
      "Epoch 17/200\n",
      "58/58 [==============================] - 3s 46ms/step - loss: 2.1345 - SMAPE: 4.1570 - val_loss: 2.7104 - val_SMAPE: 7.5948\n",
      "Epoch 18/200\n",
      "58/58 [==============================] - 3s 46ms/step - loss: 2.1390 - SMAPE: 4.1033 - val_loss: 2.6739 - val_SMAPE: 7.5014\n",
      "Epoch 19/200\n",
      "58/58 [==============================] - 3s 49ms/step - loss: 2.1357 - SMAPE: 4.1020 - val_loss: 2.7271 - val_SMAPE: 7.6429\n",
      "Epoch 20/200\n",
      "58/58 [==============================] - 3s 53ms/step - loss: 2.1348 - SMAPE: 4.1077 - val_loss: 2.8548 - val_SMAPE: 7.9637\n",
      "Epoch 21/200\n",
      "58/58 [==============================] - 3s 43ms/step - loss: 2.1437 - SMAPE: 4.1093 - val_loss: 2.8577 - val_SMAPE: 7.9797\n",
      "Epoch 22/200\n",
      "58/58 [==============================] - 3s 44ms/step - loss: 2.1319 - SMAPE: 4.0999 - val_loss: 2.6986 - val_SMAPE: 7.5892\n",
      "Epoch 23/200\n",
      "58/58 [==============================] - 3s 43ms/step - loss: 2.1314 - SMAPE: 4.2001 - val_loss: 2.7340 - val_SMAPE: 7.6810\n",
      "Epoch 24/200\n",
      "58/58 [==============================] - 3s 46ms/step - loss: 2.1380 - SMAPE: 4.1270 - val_loss: 2.6790 - val_SMAPE: 7.5537\n",
      "Epoch 25/200\n",
      "58/58 [==============================] - 3s 44ms/step - loss: 2.1462 - SMAPE: 4.2238 - val_loss: 2.8003 - val_SMAPE: 7.8586\n",
      "Epoch 26/200\n",
      "58/58 [==============================] - 3s 43ms/step - loss: 2.1346 - SMAPE: 4.1114 - val_loss: 2.7904 - val_SMAPE: 7.8544\n",
      "Epoch 27/200\n",
      "58/58 [==============================] - 2s 42ms/step - loss: 2.1477 - SMAPE: 4.1327 - val_loss: 3.0430 - val_SMAPE: 8.4731\n",
      "Epoch 28/200\n",
      "58/58 [==============================] - 3s 46ms/step - loss: 2.1310 - SMAPE: 4.1111 - val_loss: 2.5783 - val_SMAPE: 7.3190\n",
      "Epoch 29/200\n",
      "58/58 [==============================] - 3s 43ms/step - loss: 2.1409 - SMAPE: 4.1070 - val_loss: 2.9699 - val_SMAPE: 8.2984\n",
      "Epoch 30/200\n",
      "58/58 [==============================] - 3s 44ms/step - loss: 2.1383 - SMAPE: 4.0934 - val_loss: 3.1693 - val_SMAPE: 8.7931\n",
      "Epoch 31/200\n",
      "58/58 [==============================] - 3s 46ms/step - loss: 2.1289 - SMAPE: 4.0707 - val_loss: 2.6959 - val_SMAPE: 7.6259\n",
      "Epoch 32/200\n",
      "58/58 [==============================] - 3s 46ms/step - loss: 2.1374 - SMAPE: 4.1358 - val_loss: 2.9115 - val_SMAPE: 8.1605\n",
      "Epoch 33/200\n",
      "58/58 [==============================] - 3s 44ms/step - loss: 2.1314 - SMAPE: 4.0716 - val_loss: 2.9207 - val_SMAPE: 8.1922\n",
      "Epoch 34/200\n",
      "58/58 [==============================] - 3s 48ms/step - loss: 2.1297 - SMAPE: 4.0795 - val_loss: 2.7067 - val_SMAPE: 7.6580\n",
      "Epoch 35/200\n",
      "58/58 [==============================] - 3s 52ms/step - loss: 2.1344 - SMAPE: 4.1455 - val_loss: 2.8942 - val_SMAPE: 8.1272\n",
      "Epoch 36/200\n",
      "58/58 [==============================] - 3s 56ms/step - loss: 2.1394 - SMAPE: 4.1070 - val_loss: 2.4442 - val_SMAPE: 6.9810\n",
      "Epoch 37/200\n",
      "58/58 [==============================] - 3s 58ms/step - loss: 2.1499 - SMAPE: 4.1245 - val_loss: 3.1595 - val_SMAPE: 8.7761\n",
      "Epoch 38/200\n",
      "58/58 [==============================] - 3s 54ms/step - loss: 2.1366 - SMAPE: 4.1204 - val_loss: 2.8268 - val_SMAPE: 7.9691\n",
      "Epoch 39/200\n",
      "58/58 [==============================] - 3s 57ms/step - loss: 2.1345 - SMAPE: 4.1734 - val_loss: 2.8479 - val_SMAPE: 8.0256\n",
      "Epoch 40/200\n",
      "58/58 [==============================] - 3s 55ms/step - loss: 2.1312 - SMAPE: 4.0638 - val_loss: 3.1032 - val_SMAPE: 8.6610\n",
      "Epoch 41/200\n",
      "58/58 [==============================] - 3s 57ms/step - loss: 2.1446 - SMAPE: 4.1294 - val_loss: 3.0838 - val_SMAPE: 8.6135\n",
      "Epoch 42/200\n",
      "58/58 [==============================] - 3s 57ms/step - loss: 2.1332 - SMAPE: 4.1231 - val_loss: 2.6994 - val_SMAPE: 7.6976\n",
      "Epoch 43/200\n",
      "58/58 [==============================] - 3s 60ms/step - loss: 2.1364 - SMAPE: 4.1053 - val_loss: 2.8064 - val_SMAPE: 7.9477\n",
      "Epoch 44/200\n",
      "58/58 [==============================] - 3s 57ms/step - loss: 2.1487 - SMAPE: 4.1560 - val_loss: 2.7599 - val_SMAPE: 7.8263\n",
      "Epoch 45/200\n",
      "58/58 [==============================] - 3s 55ms/step - loss: 2.1379 - SMAPE: 4.1003 - val_loss: 2.8775 - val_SMAPE: 8.1157\n",
      "Epoch 46/200\n",
      "58/58 [==============================] - 3s 54ms/step - loss: 2.1280 - SMAPE: 4.0991 - val_loss: 2.9246 - val_SMAPE: 8.2415\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.285381318820285, 7.017124841839628, 0.9548516932368862, 0.9639203045491993]"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define and fit ensemble combining dnn and lstm\n",
    "nn6 = ensemble_nn([dnn, lstm])\n",
    "nn6 = compile_fit(nn6, ([X_train_dnn, X_train_lstm], y_train_dnn), ([X_val_dnn, X_val_lstm], y_val_dnn))\n",
    "compute_metrics(nn6, ([X_train_dnn, X_train_lstm], y_train_dnn), ([X_val_dnn, X_val_lstm], y_val_dnn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REPEAT lstm 14 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and validation\n",
    "X_train, y_train, X_val, y_val = split_data(df_lag.drop(columns=price_drop), 2020, 'price_actual')\n",
    "\n",
    "# Get the x cols for lstm network, lagged cols\n",
    "X_train_lstm = X_train.filter(regex='lag')\n",
    "X_train_dnn = X_train.drop(columns=X_train_lstm.columns)\n",
    "\n",
    "# Get the x cols for dnn network, forecast cols\n",
    "X_val_lstm = X_val.filter(regex='lag')\n",
    "X_val_dnn = X_val.drop(columns=X_val_lstm.columns)\n",
    "\n",
    "# Reorganize the training and testing data into batches\n",
    "X_train_dnn, y_train_dnn = resample((X_train_dnn, y_train), 24, 24, 24)\n",
    "X_val_dnn, y_val_dnn = resample((X_val_dnn, y_val), 24, 24, 24)\n",
    "\n",
    "\n",
    "# LSTM\n",
    "X_train_lstm, y_train_lstm = resample((X_train_lstm, y_train), 24*14, 24, 24)\n",
    "X_val_lstm, y_val_lstm = resample((X_val_lstm, y_val), 24*14, 24, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "58/58 [==============================] - 16s 231ms/step - loss: 50.6805 - SMAPE: 159.3007 - val_loss: 30.1632 - val_SMAPE: 121.1758\n",
      "Epoch 2/200\n",
      "58/58 [==============================] - 14s 247ms/step - loss: 46.9471 - SMAPE: 137.8129 - val_loss: 28.4009 - val_SMAPE: 109.4670\n",
      "Epoch 3/200\n",
      "58/58 [==============================] - 18s 310ms/step - loss: 45.3050 - SMAPE: 128.6257 - val_loss: 26.8415 - val_SMAPE: 99.8647\n",
      "Epoch 4/200\n",
      "58/58 [==============================] - 17s 299ms/step - loss: 43.7657 - SMAPE: 121.8247 - val_loss: 25.3457 - val_SMAPE: 91.2498\n",
      "Epoch 5/200\n",
      "58/58 [==============================] - 14s 240ms/step - loss: 42.2706 - SMAPE: 114.7420 - val_loss: 23.8941 - val_SMAPE: 83.3942\n",
      "Epoch 6/200\n",
      "58/58 [==============================] - 15s 260ms/step - loss: 40.8053 - SMAPE: 108.3950 - val_loss: 22.4802 - val_SMAPE: 76.1848\n",
      "Epoch 7/200\n",
      "58/58 [==============================] - 14s 243ms/step - loss: 39.3615 - SMAPE: 102.4579 - val_loss: 21.1020 - val_SMAPE: 69.5380\n",
      "Epoch 8/200\n",
      "58/58 [==============================] - 15s 255ms/step - loss: 37.9374 - SMAPE: 96.5766 - val_loss: 19.7602 - val_SMAPE: 63.4062\n",
      "Epoch 9/200\n",
      "58/58 [==============================] - 14s 249ms/step - loss: 36.5309 - SMAPE: 90.8981 - val_loss: 18.4649 - val_SMAPE: 57.7880\n",
      "Epoch 10/200\n",
      "58/58 [==============================] - 14s 244ms/step - loss: 35.1405 - SMAPE: 85.5642 - val_loss: 17.2140 - val_SMAPE: 52.6341\n",
      "Epoch 11/200\n",
      "58/58 [==============================] - 14s 243ms/step - loss: 33.7639 - SMAPE: 81.2237 - val_loss: 16.0161 - val_SMAPE: 47.9272\n",
      "Epoch 12/200\n",
      "58/58 [==============================] - 15s 261ms/step - loss: 32.4008 - SMAPE: 76.2169 - val_loss: 14.8825 - val_SMAPE: 43.6704\n",
      "Epoch 13/200\n",
      "58/58 [==============================] - 14s 236ms/step - loss: 31.0512 - SMAPE: 71.7858 - val_loss: 13.8180 - val_SMAPE: 39.8473\n",
      "Epoch 14/200\n",
      "58/58 [==============================] - 12s 200ms/step - loss: 29.7176 - SMAPE: 67.7003 - val_loss: 12.8276 - val_SMAPE: 36.4295\n",
      "Epoch 15/200\n",
      "58/58 [==============================] - 11s 187ms/step - loss: 28.4033 - SMAPE: 63.3672 - val_loss: 11.9328 - val_SMAPE: 33.4539\n",
      "Epoch 16/200\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 27.1106 - SMAPE: 59.3128 - val_loss: 11.1513 - val_SMAPE: 30.9393\n",
      "Epoch 17/200\n",
      "58/58 [==============================] - 10s 181ms/step - loss: 25.8422 - SMAPE: 55.3443 - val_loss: 10.4952 - val_SMAPE: 28.8876\n",
      "Epoch 18/200\n",
      "58/58 [==============================] - 10s 180ms/step - loss: 24.6024 - SMAPE: 52.5145 - val_loss: 9.9743 - val_SMAPE: 27.2921\n",
      "Epoch 19/200\n",
      "58/58 [==============================] - 11s 184ms/step - loss: 23.3868 - SMAPE: 49.2351 - val_loss: 9.5837 - val_SMAPE: 26.1044\n",
      "Epoch 20/200\n",
      "58/58 [==============================] - 11s 189ms/step - loss: 22.2020 - SMAPE: 46.1210 - val_loss: 9.3092 - val_SMAPE: 25.2608\n",
      "Epoch 21/200\n",
      "58/58 [==============================] - 11s 198ms/step - loss: 21.0543 - SMAPE: 42.3878 - val_loss: 9.1473 - val_SMAPE: 24.7285\n",
      "Epoch 22/200\n",
      "58/58 [==============================] - 12s 203ms/step - loss: 19.9467 - SMAPE: 40.2343 - val_loss: 9.0853 - val_SMAPE: 24.4666\n",
      "Epoch 23/200\n",
      "58/58 [==============================] - 13s 226ms/step - loss: 18.8846 - SMAPE: 37.2289 - val_loss: 9.1255 - val_SMAPE: 24.4691\n",
      "Epoch 24/200\n",
      "58/58 [==============================] - 13s 231ms/step - loss: 17.8814 - SMAPE: 34.8963 - val_loss: 9.2658 - val_SMAPE: 24.7071\n",
      "Epoch 25/200\n",
      "58/58 [==============================] - 13s 233ms/step - loss: 16.9468 - SMAPE: 32.9460 - val_loss: 9.5095 - val_SMAPE: 25.1709\n",
      "Epoch 26/200\n",
      "58/58 [==============================] - 14s 244ms/step - loss: 16.0835 - SMAPE: 30.9769 - val_loss: 9.8338 - val_SMAPE: 25.7960\n",
      "Epoch 27/200\n",
      "58/58 [==============================] - 15s 254ms/step - loss: 15.2941 - SMAPE: 29.1434 - val_loss: 10.2325 - val_SMAPE: 26.5617\n",
      "Epoch 28/200\n",
      "58/58 [==============================] - 15s 257ms/step - loss: 14.5810 - SMAPE: 27.6399 - val_loss: 10.6832 - val_SMAPE: 27.4201\n",
      "Epoch 29/200\n",
      "58/58 [==============================] - 14s 243ms/step - loss: 13.9539 - SMAPE: 26.2562 - val_loss: 11.1722 - val_SMAPE: 28.3397\n",
      "Epoch 30/200\n",
      "58/58 [==============================] - 15s 255ms/step - loss: 13.3965 - SMAPE: 24.9391 - val_loss: 11.6887 - val_SMAPE: 29.2995\n",
      "Epoch 31/200\n",
      "58/58 [==============================] - 14s 239ms/step - loss: 12.9201 - SMAPE: 24.1357 - val_loss: 12.2156 - val_SMAPE: 30.2662\n",
      "Epoch 32/200\n",
      "58/58 [==============================] - 15s 257ms/step - loss: 12.5102 - SMAPE: 23.2740 - val_loss: 12.7424 - val_SMAPE: 31.2210\n"
     ]
    }
   ],
   "source": [
    "input_shape = (X_train_lstm.shape[1], X_train_lstm.shape[2])\n",
    "# Instantiate model and build layers\n",
    "nn = models.Sequential()\n",
    "nn.add(layers.LSTM(83, activation='tanh', input_shape=input_shape))\n",
    "nn.add(layers.RepeatVector(y_train_lstm.shape[1]))\n",
    "nn.add(layers.LSTM(24, activation='tanh', return_sequences=True))\n",
    "nn.add(TimeDistributed(layers.Dense(1)))\n",
    "\n",
    "lstm = compile_fit(nn, (X_train_lstm, y_train_lstm), (X_val_lstm, y_val_lstm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[38.70429814577969,\n",
       " 24.199855281584426,\n",
       " 0.006188302756964411,\n",
       " 0.006700144850133799]"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(lstm, (X_train_lstm, y_train_lstm), (X_val_lstm, y_val_lstm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "58/58 [==============================] - 9s 106ms/step - loss: 33.9910 - SMAPE: 92.0138 - val_loss: 11.0794 - val_SMAPE: 33.5418\n",
      "Epoch 2/200\n",
      "58/58 [==============================] - 5s 84ms/step - loss: 5.0876 - SMAPE: 10.0422 - val_loss: 1.9969 - val_SMAPE: 5.7985\n",
      "Epoch 3/200\n",
      "58/58 [==============================] - 5s 79ms/step - loss: 2.1946 - SMAPE: 4.2587 - val_loss: 2.4026 - val_SMAPE: 6.8783\n",
      "Epoch 4/200\n",
      "58/58 [==============================] - 5s 83ms/step - loss: 2.1666 - SMAPE: 4.2156 - val_loss: 2.5428 - val_SMAPE: 7.2214\n",
      "Epoch 5/200\n",
      "58/58 [==============================] - 5s 79ms/step - loss: 2.1531 - SMAPE: 4.1695 - val_loss: 2.6565 - val_SMAPE: 7.5595\n",
      "Epoch 6/200\n",
      "58/58 [==============================] - 4s 77ms/step - loss: 2.1440 - SMAPE: 4.2788 - val_loss: 2.7295 - val_SMAPE: 7.7558\n",
      "Epoch 7/200\n",
      "58/58 [==============================] - 4s 75ms/step - loss: 2.1413 - SMAPE: 4.1259 - val_loss: 2.7389 - val_SMAPE: 7.7705\n",
      "Epoch 8/200\n",
      "58/58 [==============================] - 4s 75ms/step - loss: 2.1504 - SMAPE: 4.1446 - val_loss: 2.8860 - val_SMAPE: 8.1539\n",
      "Epoch 9/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 2.1381 - SMAPE: 4.1078 - val_loss: 2.8130 - val_SMAPE: 7.9532\n",
      "Epoch 10/200\n",
      "58/58 [==============================] - 5s 83ms/step - loss: 2.1398 - SMAPE: 4.1217 - val_loss: 2.7649 - val_SMAPE: 7.8246\n",
      "Epoch 11/200\n",
      "58/58 [==============================] - 5s 80ms/step - loss: 2.1385 - SMAPE: 4.1367 - val_loss: 2.8981 - val_SMAPE: 8.1641\n",
      "Epoch 12/200\n",
      "58/58 [==============================] - 5s 84ms/step - loss: 2.1342 - SMAPE: 4.1538 - val_loss: 2.7060 - val_SMAPE: 7.6827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.421217783894029, 5.816508209817018, 0.9536169132453041, 0.9648005251925975]"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define and fit ensemble combining dnn and lstm\n",
    "nn7 = ensemble_nn([dnn, lstm])\n",
    "nn7 = compile_fit(nn7, ([X_train_dnn, X_train_lstm], y_train_dnn), ([X_val_dnn, X_val_lstm], y_val_dnn))\n",
    "compute_metrics(nn7, ([X_train_dnn, X_train_lstm], y_train_dnn), ([X_val_dnn, X_val_lstm], y_val_dnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ENCODER/DECODER LSTM\n",
    "\n",
    "**ENCODER**:<br>\n",
    "One or more LSTM layers can be used to implement the encoder model. The output is a fixed-size vector that represents the internal represntation of the input sequence. The number of memory cells in this layer defines the length of this fixed-size vector.\n",
    "* Produces a two dimensional matrix of outputs, where the length is defined by the number of memory cells in the layer.\n",
    "\n",
    "**DECODER**:\n",
    "Must transform the learned interal representation of the input sequence into the correct output sequence. The output should be a TimeDistributed layer.\n",
    "* Expects a 3D input of [samples, time steps, features] in order to produce a decoded sequence of some different length define by the problem\n",
    "\n",
    "**Repeat Vector**:\n",
    "* Repeats the provided 2D input multiple times to create a 3D output\n",
    "* Use to transition from ENCODER - DECORDER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val = split_data(df_lag.drop(columns = price_drop), 2020, 'price_actual')\n",
    "\n",
    "# Reorganize the training and testing data into batches\n",
    "X_train, y_train = resample((X_train, y_train), 24, 24, 24)\n",
    "X_val, y_val = resample((X_val, y_val), 24, 24, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1825, 24, 60)"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(366, 24, 60)"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define input_shape\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "cnn = models.Sequential()\n",
    "cnn.add(layers.Dense(60, activation='relu', input_shape=input_shape))\n",
    "cnn.add(layers.ConvLSTM1D())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Modeling Proce Components\n",
    "### 4.1 One-to-one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, y_train, X_val, y_val = split_data(df_lag.drop(columns=['price_actual', 'price_day_ahead']), 2020, list(price_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43800, 14)"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1369/1369 [==============================] - 3s 2ms/step - loss: 0.6098 - SMAPE: nan - val_loss: 0.6820 - val_SMAPE: nan\n",
      "Epoch 2/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 0.6050 - SMAPE: nan - val_loss: 0.6824 - val_SMAPE: nan\n",
      "Epoch 3/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 0.6035 - SMAPE: nan - val_loss: 0.6841 - val_SMAPE: nan\n",
      "Epoch 4/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 0.6024 - SMAPE: nan - val_loss: 0.6822 - val_SMAPE: nan\n",
      "Epoch 5/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 0.6017 - SMAPE: nan - val_loss: 0.6839 - val_SMAPE: nan\n",
      "Epoch 6/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 0.6014 - SMAPE: nan - val_loss: 0.6835 - val_SMAPE: nan\n",
      "Epoch 7/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 0.6010 - SMAPE: nan - val_loss: 0.6838 - val_SMAPE: nan\n",
      "Epoch 8/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 0.6008 - SMAPE: nan - val_loss: 0.6837 - val_SMAPE: nan\n",
      "Epoch 9/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 0.6007 - SMAPE: nan - val_loss: 0.6840 - val_SMAPE: nan\n",
      "Epoch 10/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 0.6005 - SMAPE: nan - val_loss: 0.6827 - val_SMAPE: nan\n"
     ]
    }
   ],
   "source": [
    "# Define input_shape\n",
    "input_shape = (X_train.shape[1],)\n",
    "\n",
    "# Instantiate model and build layers\n",
    "nn = models.Sequential()\n",
    "nn.add(layers.Dense(X_train.shape[1], activation='relu', input_shape=input_shape))\n",
    "nn.add(layers.Dense(239, activation='relu'))\n",
    "nn.add(layers.Dense(162, activation='relu'))\n",
    "nn.add(layers.Dense(14, activation='relu'))\n",
    "\n",
    "nn8 = compile_fit(nn, (X_train,y_train), (X_val, y_val), patience=10,\n",
    "                  loss = tf.keras.metrics.mean_absolute_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = nn8.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43800, 14)"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1369/1369 [==============================] - 3s 2ms/step - loss: 2.0712 - SMAPE: 4.3372 - val_loss: 1.4228 - val_SMAPE: 4.1740\n",
      "Epoch 2/200\n",
      "1369/1369 [==============================] - 2s 1ms/step - loss: 1.4814 - SMAPE: 2.8341 - val_loss: 1.5818 - val_SMAPE: 4.6781\n",
      "Epoch 3/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 1.4051 - SMAPE: 2.6793 - val_loss: 1.5677 - val_SMAPE: 4.7071\n",
      "Epoch 4/200\n",
      "1369/1369 [==============================] - 3s 2ms/step - loss: 1.3545 - SMAPE: 2.5828 - val_loss: 1.5839 - val_SMAPE: 4.8793\n",
      "Epoch 5/200\n",
      "1369/1369 [==============================] - 2s 1ms/step - loss: 1.3174 - SMAPE: 2.5079 - val_loss: 1.5754 - val_SMAPE: 4.8076\n",
      "Epoch 6/200\n",
      "1369/1369 [==============================] - 2s 1ms/step - loss: 1.2824 - SMAPE: 2.4439 - val_loss: 1.5899 - val_SMAPE: 4.8689\n",
      "Epoch 7/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 1.2429 - SMAPE: 2.3634 - val_loss: 1.4458 - val_SMAPE: 4.4351\n",
      "Epoch 8/200\n",
      "1369/1369 [==============================] - 2s 1ms/step - loss: 1.2447 - SMAPE: 2.3650 - val_loss: 1.5837 - val_SMAPE: 4.8025\n",
      "Epoch 9/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 1.2320 - SMAPE: 2.3390 - val_loss: 1.7984 - val_SMAPE: 5.4190\n",
      "Epoch 10/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 1.1932 - SMAPE: 2.2699 - val_loss: 2.2038 - val_SMAPE: 6.4301\n",
      "Epoch 11/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 1.1674 - SMAPE: 2.2187 - val_loss: 1.8448 - val_SMAPE: 5.4149\n"
     ]
    }
   ],
   "source": [
    "nn1 = compile_fit(nn, (X_train,y_train), (X_val, y_val), patience=10,\n",
    "                  loss = tf.keras.metrics.mean_absolute_error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
