{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td><img src=\"../images/42450c5e679578b596be84e3df088ab1aac8b8ab.jpg\" style=\"width:320px;height:300px\"/></td>\n",
    "<td><img src= \"../images/spain_grid.gif\" style=\"width:320px;height:300px\"/></td>\n",
    "<td><img src= \"../images/wind_turbine.jpg\" style=\"width:320px;height:300px\"/></td> \n",
    "</tr></table>\n",
    "\n",
    "# Predicting Energy Markets in Spain\n",
    "**Author**: Evan Holder<br>\n",
    "**Flatiron Data Science**:  Capstone Project<br>\n",
    "[Github Link]()<br>\n",
    "[Presentation Link]()<br>\n",
    "\n",
    "### Table of Contents\n",
    "___\n",
    "\n",
    "1. [Background](#Background)<br>\n",
    "2. [Business Problem](#Business-Problem)<br>\n",
    "3. [Data Collection](#Data-Collection)<br>\n",
    "4. [Data Cleaning](#Data-Cleaning)<br>\n",
    "5. [Data Preparation](#Data-Preparation)<br>\n",
    "    5.1 [Encode Categorical Features](#Encode-Categorical-Features)<br>\n",
    "    5.2 [Scaling Continuous Features](#Scaling-Continuous-Features)<br>\n",
    "    5.3 [Multicolinearity](#Multicolinearity)<br>\n",
    "6. [Modeling the Actual Price](#Modeling-price_actual)<br>\n",
    "    6.1 [Lasso Regression](#Lasso-Regression)<br>\n",
    "    6.2 [XGBoost Regression](#XGBoost-Regression)<br>\n",
    "    6.3 [Neural Networks](#Neural-Networks)<br>\n",
    "    6.3.1 [Neural Network 1-to-1](#Neural-Network-1-to-1)<br>\n",
    "    6.3.2 [Neural Network 24-to-24](#Neural-Network-24-to-24)<br>\n",
    "    6.3.3 [LSTM Neural Network](#Neural-Network-LSTM)<br>\n",
    "    6.3.4 [DNN-LSTM Neural Network](#Neural-Network-DNN-LSTM)<br>\n",
    "7.0 [Modeling the Price Residual](#Modeling-Price_Residual)<br>\n",
    "8.0 [Impact of Weather Features on Price](#Weather)<br>\n",
    "### Background <a class=\"anchor\" id=\"Background\"></a>\n",
    "___\n",
    "Energy markets are especially volatile. At a high level, energy prices are the result of a supply and demand curve. Demand is mostly impacted by the weather outside (seasonal). Supply can be impacted by a multiude of factors from the availability of generation resources, to politics, to international trade and service outages.  Nominated Electricity Market Operator (NEMOs) are in charge of regulating this supply and demand curve and ensuring a fair market price for both generators and consumers.  It is their job balance the flow of electricity from generating sources with the demand of millions of consumers at every moment, of every day.  Maintaining this supply/demand balance is critical in efficient delivery of electricity.  If electricity generation is too high, generators have to reduce production or be completely disconnect from the grid resulting in wasted resources. If demand is higher than generation, transmission companies are forced to \"shed\" load resulting brownouts or blackouts for consumers.  Not only is fine-tuning this balance critical in consistent delivery of electricity, but also in keeping electricity prices low. The better NEMOs are able to balance supply and demand, the cheaper it is for generators to produces electricity, transmission companies to deliver it, and the cheaper it is for consumers to purchase it.  \n",
    "### Business Problem <a class=\"anchor\" id=\"Business-Problem\"></a>\n",
    "___\n",
    "With the rise renewable energies, which are significantly impacted by the weather, it has become harder to balance energy supply and demand and keep the grid stable.  Grid instability often results in price uncertainty. By more accurately modeling the price of electricity, we can minimize the effects of a rapidly changing supply and demand balance. Or in other words, the better NEMOs can model the price of electricity, the better they can regulate energy production, limit wasted resources, and more efficiently deliver electricity to the consumer.\n",
    "\n",
    "**Can we use information about energy generation, transmission, the weather, and the day ahead price to accurately predict the price of electricity tomorrow?**\n",
    "\n",
    "Some background on the target itself... In reality `price_actual` is an aggregate of about 15 price components.  The largest price components is day-ahead price (`price_day_ahead`).  At 12:00 CES everyday, energy buying and selling agents submit their bids to the day-ahead market.  Here, the day-ahead price is set to satisfy tomorrow's predicted supply and demand curve, by the hour.  In essence, it's the day-ahead price that best reflects tomorrow's predicted supply/demand balance.  From there, supply and demand information is submitted to the TSOs where adjustments may have to be made to accommodate any deviations from the plan. On the day of, the intraday market opens up, where market agents can buy and sell energy at prices adjusted for any deviations the TSO have to make in order to effectively operate the grid over the course of the day. These adjusted prices are reflected in the remaining intraday price components. Together, the day-ahead component combined with the intraday market components make up the final price.\n",
    "### Data Collection and Cleaning <a class=\"anchor\" id=\"Data-Collection\"></a>\n",
    "___\n",
    "The data for the project focuses on the electricity market in Spain. Spain was an obvious choice for this project as there is a multitude of data readily available and well documented. The full cleaning script is located [here](https://github.com/EvanHolder/capstone/blob/main/scripts/EDA_cleaning-components.ipynb).\n",
    "\n",
    "**Generation, Transmission, Load Data**<br>\n",
    "Downloaded from the [entso-e Transparency Platform](https://transparency.entsoe.eu/dashboard/show). The entso-e is a network of 39 indepentent Transmission Service Operators (TSOs) across Europe which make up the largest interconnected grid in the world. Cleaning steps included:\n",
    "* Created datetime index\n",
    "* Joined tables together\n",
    "* Imputed the immediate mean for missing data points\n",
    "* Removed duplicates\n",
    "* Lagged columns one day\n",
    "\n",
    "**Weather Data**<br>\n",
    "Data was scraped from [wunderground.com](wunderground.com).  See the weather scraper [here](https://github.com/EvanHolder/capstone/blob/main/scripts/weather_scraper.py) (Note: Thank you to Bojan stavrikj for your [blogpost](https://bojanstavrikj.github.io/content/page1/wunderground_scraper) and for the helper function `render_page` which I used in my script). Cleaning steps included:\n",
    "* Created datetime index\n",
    "* Joined data from 5 cities into a single table\n",
    "* Dropped rows not at the top of the hour\n",
    "* Shifted data to account for daylight savings time\n",
    "* Reformated strings to intergers\n",
    "* Removed unimportant columns\n",
    "* Imputed the immediate mean for days with 12 or missing data points\n",
    "* Interpolated/flagged missing data\n",
    "* Removed duplicates\n",
    "* Lagged columns one day\n",
    "\n",
    "**Price Data**<br>\n",
    "All pricing data was retrieved from the one and only Spanish TSO [Red Electric Espana](https://www.esios.ree.es/en/market-and-prices). Cleaning steps included:\n",
    "* Created datetime index\n",
    "* Dropped duplicates\n",
    "* Combined tables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and Functions  <a class=\"anchor\" id=\"Import-Libraries-and-Funtions\"></a>\n",
    "___\n",
    "Data manipulation, cleaning, massaging: pandas, numpy<br>\n",
    "Modeling: sklearn, keras<br>\n",
    "Plotting: matplotlib<br>\n",
    "Custom functions: function.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for data cleaning, massaging:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "# Modeling Libraries\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, models, regularizers\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Save Models\n",
    "import pickle\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Manipulate directories \n",
    "import os\n",
    "\n",
    "# Import custom functions\n",
    "os.chdir('../scripts')\n",
    "from functions import split_data, sMAPE, SMAPE, compute_metrics, r2,impute_immediate_mean\n",
    "from functions import resample, plot_metric_range, compile_fit, ensemble_nn\n",
    "os.chdir('../notebooks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data <a class=\"anchor\" id=\"Import-Data\"></a>\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "df_lag = pd.read_csv('../data/clean/df_clean_lag.csv', index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation <a class=\"anchor\" id=\"Data-Preparation\"></a>\n",
    "___\n",
    "In this project, we'll focus on three main algorithms types: Lasso Regression, XGBoost, and Neural Networks.  We'll need to prepare the data in slightly different ways for each of the these model types. Much of the preprocessing was already taken care of as part of the steps list above in [Data Cleaning](#Data-Cleaning). The remaining steps are model specific, and so are prepared below:<br><br>\n",
    "**Lasso Regression**: Encode the categorical features, remove mulitcolinearities<br>\n",
    "**Neural Networks**: Encode the categorical features\n",
    "\n",
    "### Encode Catergorical Features <a class=\"anchor\" id=\"Encode-Categorical-Features\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Categorical columns\n",
    "categorical = df_lag.select_dtypes(include='object')\n",
    "\n",
    "# Instationate wind_dir_coder LabelEncoder, fit\n",
    "wind_dir_coder = LabelEncoder()\n",
    "wind_dir_coder.fit(df_lag['wind_madrid_lag'])\n",
    "\n",
    "# Transform wind_direction cols\n",
    "for col in categorical.filter(regex='wind').columns:\n",
    "    df_lag[col] = wind_dir_coder.transform(df_lag[col])\n",
    "    \n",
    "\n",
    "# Stack condition columns into single col\n",
    "stacked_conditions = categorical.filter(regex='condition').stack()\n",
    "\n",
    "# Instantiate condition_coder LabelEncoder, fit on stacked conditions\n",
    "condition_coder = LabelEncoder()\n",
    "condition_coder.fit(stacked_conditions)\n",
    "\n",
    "# Transform condition cols\n",
    "for col in categorical.filter(regex='condition').columns:\n",
    "    df_lag[col] = condition_coder.transform(df_lag[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get price components not to be used in modeling\n",
    "price_cols = df_lag.filter(regex='price').columns.to_list()[1:]\n",
    "price_cols.remove('price_day_ahead')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Continuous Features <a class=\"anchor\" id=\"Scaling-Continuous-Features\"></a>\n",
    "For neural networks, continuous features do not necessarily need to be scaled. However according to this [article](https://www.sciencedirect.com/science/article/pii/S030626191830196X#s0235), which uses neural networks to predict electrical prices, scaling your continuous features generally increases accuracy of deep learning models on the validation set.  We'll give it a go here and scale the the continuos features between [-1,1] for the neural networks we'll train later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the dataframe for neural networks\n",
    "df_nn = df_lag.drop(columns=price_cols).copy()\n",
    "continuous = df_nn.select_dtypes(exclude='object').filter(regex='^(?!.*price).*').columns\n",
    "\n",
    "# Get rid of negatives\n",
    "time = dt.datetime(2021,3,24,22)\n",
    "df_nn.loc[time, 'dew_point_bilbao_lag'] = impute_immediate_mean(df_nn['dew_point_bilbao_lag'], time)\n",
    "\n",
    "# Rescale data [-1,1]\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "df_nn[continuous] = scaler.fit_transform(df_nn[continuous])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multicolinearity <a class=\"anchor\" id=\"Multicolinearity\"></a>\n",
    "One of the assumptions for regression is that featu\n",
    "res do not contain multicolinearities.  In this section, we'll investigate the predictors and eliminate any multicolinearities in preparation for a lasso regression. We'll need to find out which features are correlated with each other, and remove some of them to rid our dataset of multicolinearities. The steps are outlined below:\n",
    "1. Copy the dataframe, we'll modify this dataset for use in lasso regression\n",
    "2. Get the correlations between predictors, sort them in descending order\n",
    "3. Get the correlations between each individual predictor and the response variable\n",
    "4. Get the features which have a correlation greater than 0.8, add the feature which correlates less with price_actual to the drop list\n",
    "5. Drop the features in the drop list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy dataset for lasso regression specific preparation\n",
    "df_lr = df_lag.drop(columns=price_cols).copy()\n",
    "\n",
    "# Create correlation matrix predictors to predictors\n",
    "corr = df_lr.drop(columns='price_actual').corr().abs().stack().reset_index().sort_values(0, ascending=False)\n",
    "corr.rename(columns={0:'cor'}, inplace=True)  # Rename correlation column\n",
    "corr = corr.loc[corr['cor']!=1]  # remove correlations between same variables\n",
    "corr.drop_duplicates(subset='cor', inplace=True) # remove duplicate correlations\n",
    "corr.reset_index(drop=True, inplace=True) # Reset the index\n",
    "corr.cor =corr.cor.apply(lambda x: round(x,3))  # Round\n",
    "\n",
    "# Create correlation matrix predictors to response variable\n",
    "corr_price = df_lr.corr()['price_actual'].reset_index().sort_values('price_actual', ascending=False)\n",
    "corr_price = corr_price.loc[corr_price['price_actual']!=1] # remove correlations between same variables\n",
    "corr_price.reset_index(drop=True, inplace=True)  # Reset the index\n",
    "\n",
    "\n",
    "drop = []\n",
    "\n",
    "# For each feature pair where corr > 0.8, add feature with lower corr to price_actual to drop list\n",
    "for row in range(len(corr.loc[corr.cor>.8])):\n",
    "    var1 = corr.loc[row,'level_0'] # Get var1 name\n",
    "    var2 = corr.loc[row,'level_1'] # Get var2 name\n",
    "    var1_corr = float(corr_price.loc[corr_price['index'] == var1, 'price_actual'])  # Get var1 corr\n",
    "    var2_corr = float(corr_price.loc[corr_price['index'] == var2, 'price_actual'])  # Get var2 corr\n",
    "    \n",
    "    # Add the lower correlation to the drop list\n",
    "    if var1_corr > var2_corr:\n",
    "        drop.append(var2)\n",
    "    else:\n",
    "        drop.append(var1)\n",
    "        \n",
    "# Drop the features in the drop listi\n",
    "df_lr.drop(columns=drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xg = df_lag.drop(columns=price_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling `price_actual` <a class=\"anchor\" id=\"Modeling-price_actual\"></a>\n",
    "___\n",
    "**Performance Metrics**\n",
    "Our frame of reference for modeling the tomorrow's actual price will be the day-ahead price which is established at 12 CET (the day before), as this is the best guess for tomorrow's price.  Below, I'll make a table to hold our model results.  The table will include:\n",
    "\n",
    "**R-squared**: Chosen because this is a regression task.  R-squared represents the proportion of variance explained by the dependent variable.\n",
    "\n",
    "**Symmetrical Mean Absolute Percentage Error (SMAPE)**: Chosen because the starting point for r-squared is very very high (0.97).  The advantage to using SMAPE is it symmetry. MAPE has a lower bound of 100% over the actual but no upper bound.  In contrast, SMAPE is bound between 200% below and 200% above the actual. Again, because there is only modest room for improvement in r-squared, and so the primary measure of accuracy here will be SMAPE.\n",
    "\n",
    "**<u>NOTE</u>**: It should be documented that when I began this project, I had downloaded a version of this dataset from [Kaggle](https://www.kaggle.com/nicholasjhana/energy-consumption-generation-prices-and-weather).  When I imported the data and indexed it with datetime objects, I found that the first 12 days of each month often do not track well with the actual price.  At one point I decided to grab more data from more recent years and noticed the creator of the Kaggle dataset seemed have made an error. The data should have been read in from its original form in the [Transparency Platform](https://transparency.entsoe.eu/dashboard/show) in as DD-MM-YYYY-HH format but instead appears to have been misread in as MM-DD-YYYY-HH format. After fixing this mistake in the original Kaggle dataset, the r-squared increases from 0.54 to 0.96."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NEMO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Parameters</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMAPE_train</th>\n",
       "      <td>16.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMAPE_val</th>\n",
       "      <td>16.922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_train</th>\n",
       "      <td>0.954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_val</th>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               NEMO\n",
       "Parameters     None\n",
       "SMAPE_train   16.03\n",
       "SMAPE_val    16.922\n",
       "r2_train      0.954\n",
       "r2_val        0.971"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Benchmark results\n",
    "NEMO_train = df_lag.loc[:'2019', 'price_day_ahead']\n",
    "NEMO_val = df_lag.loc['2020', 'price_day_ahead']\n",
    "\n",
    "actual_train = df_lag.loc[:'2019', 'price_actual']\n",
    "actual_val = df_lag.loc['2020', 'price_actual']\n",
    "\n",
    "# Create dataframe\n",
    "results_actual = pd.DataFrame(index=['Parameters','SMAPE_train', 'SMAPE_val', 'r2_train', 'r2_val'])\n",
    "\n",
    "# Add the baseline NEMO predictions\n",
    "results_actual['NEMO'] = ['None',\n",
    "                                    round(sMAPE(actual_train, NEMO_train), 3),\n",
    "                                    round(sMAPE(actual_val, NEMO_val), 3),\n",
    "                                    round(r2(actual_train, NEMO_train), 3), \n",
    "                                    round(r2(actual_val, NEMO_val),3)]\n",
    "results_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val = split_data(df_lr, 2020, 'price_actual')\n",
    "with open('../models/Lasso.pickle', 'rb') as file:\n",
    "    lasso = pickle.load(file)\n",
    "with open('../models/Lasso1.pickle', 'rb') as file:\n",
    "    lasso1 = pickle.load(file)\n",
    "with open('../models/Lasso2.pickle', 'rb') as file:\n",
    "    lasso2 = pickle.load(file)\n",
    "with open('../models/XGBoost.pickle', 'rb') as file:\n",
    "    xg = pickle.load(file)\n",
    "with open('../models/XGBoost1.pickle', 'rb') as file:\n",
    "    xg1 = pickle.load(file)\n",
    "with open('../models/XGBoost2.pickle', 'rb') as file:\n",
    "    xg2 = pickle.load(file)\n",
    "with open('../models/XGBoost3.pickle', 'rb') as file:\n",
    "    xg3 = pickle.load(file)\n",
    "nn1 = keras.models.load_model('../models/nn1', custom_objects={'SMAPE':SMAPE})\n",
    "nn2 = keras.models.load_model('../models/nn2', custom_objects={'SMAPE':SMAPE})\n",
    "nn3 = keras.models.load_model('../models/nn3', custom_objects={'SMAPE':SMAPE})\n",
    "nn4 = keras.models.load_model('../models/nn4', custom_objects={'SMAPE':SMAPE})\n",
    "nn5 = keras.models.load_model('../models/nn5', custom_objects={'SMAPE':SMAPE})\n",
    "nn6 = keras.models.load_model('../models/nn6', custom_objects={'SMAPE':SMAPE})\n",
    "    \n",
    "\n",
    "results_actual['Lasso'] = compute_metrics(lasso, 'Vanilla', (X_train, y_train), (X_val, y_val))\n",
    "train_cols = ['humidities_bilbao_lag', 'oil_lag', 'renewable_lag', 'waste_lag', 'price_day_ahead']\n",
    "results_actual['Lasso1'] = compute_metrics(lasso1, {'num_features':5}, (X_train[train_cols], y_train), (X_val[train_cols], y_val))\n",
    "X_train1, X_val1 = X_train.drop(columns='price_day_ahead'), X_val.drop(columns='price_day_ahead')\n",
    "results_actual['Lasso2'] = compute_metrics(lasso2, {'price_day_ahead':False}, (X_train1, y_train), (X_val1, y_val))\n",
    "X_train, y_train, X_val, y_val = split_data(df_xg, 2020, 'price_actual')\n",
    "results_actual['XGBoost'] = compute_metrics(xg, 'Vanilla',(X_train, y_train), (X_val, y_val))\n",
    "results_actual['XGBoost1'] = compute_metrics(xg1, {'max_depth':2},(X_train, y_train), (X_val, y_val))\n",
    "X_train1, X_val1 = X_train.drop(columns='price_day_ahead'), X_val.drop(columns='price_day_ahead')\n",
    "results_actual['XGBoost2'] = compute_metrics(xg2, {'max_depth':2,\n",
    "                                                   'price_day_ahead':False},(X_train1, y_train), (X_val1, y_val))\n",
    "results_actual['XGBoost3'] = compute_metrics(xg3,\n",
    "                                             {'max_depth':16, 'price_day_ahead':False},\n",
    "                                             (X_train1, y_train), \n",
    "                                             (X_val1, y_val))\n",
    "\n",
    "\n",
    "X_train, y_train, X_val, y_val = split_data(df_nn, 2020, 'price_actual')\n",
    "results_actual['nn1'] = compute_metrics(nn1, '1-to-1', (X_train,y_train), (X_val, y_val))\n",
    "\n",
    "X_train, y_train, X_val, y_val = split_data(df_nn.drop(columns='price_day_ahead'), 2020, 'price_actual')\n",
    "results_actual['nn2'] = compute_metrics(nn2, '1-to-1, price_day_ahead:False', (X_train,y_train), (X_val, y_val))\n",
    "\n",
    "X_train, y_train, X_val, y_val = split_data(df_nn, 2020, 'price_actual')\n",
    "X_train, y_train = resample((X_train, y_train), 24, 24, 24)\n",
    "X_val, y_val = resample((X_val,y_val), 24, 24, 24)\n",
    "results_actual['nn3'] = compute_metrics(nn3, '24-to-24', (X_train,y_train), (X_val, y_val))\n",
    "\n",
    "\n",
    "X_train, y_train, X_val, y_val = split_data(df_nn, 2020, 'price_actual')\n",
    "X_train, y_train = resample((X_train, y_train), 24*7, 24, 24)\n",
    "X_val, y_val = resample((X_val,y_val), 24*7, 24, 24)\n",
    "results_actual['nn4'] = compute_metrics(nn4, 'LSTM, 7-day input', (X_train,y_train), (X_val,y_val))\n",
    "results_actual['nn5'] = compute_metrics(nn5, 'LSTM, 7-day input', (X_train,y_train), (X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val = split_data(df_nn, 2020, 'price_actual')\n",
    "X_train_lstm = X_train.filter(regex='lag')\n",
    "X_train_dnn = X_train.drop(columns=X_train_lstm.columns)\n",
    "X_val_lstm = X_val.filter(regex='lag')\n",
    "X_val_dnn = X_val.drop(columns=X_val_lstm.columns)\n",
    "X_train_dnn, y_train_dnn = resample((X_train_dnn, y_train), 24, 24, 24)\n",
    "X_val_dnn, y_val_dnn = resample((X_val_dnn, y_val), 24, 24, 24)\n",
    "X_train_lstm, y_train_lstm = resample((X_train_lstm, y_train), 24, 24, 24)\n",
    "X_val_lstm, y_val_lstm = resample((X_val_lstm, y_val), 24, 24, 24)\n",
    "results_actual['nn6'] = compute_metrics(nn6,\n",
    "                                        'dnn-lstm, 1-day input',\n",
    "                                        ([X_train_dnn, X_train_lstm],y_train),\n",
    "                                        ([X_val_dnn, X_val_lstm],y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>SMAPE_train</th>\n",
       "      <th>SMAPE_val</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NEMO</th>\n",
       "      <td>None</td>\n",
       "      <td>16.03</td>\n",
       "      <td>16.922</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>3.021</td>\n",
       "      <td>5.869</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso1</th>\n",
       "      <td>{'num_features': 5}</td>\n",
       "      <td>4.134</td>\n",
       "      <td>8.354</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso2</th>\n",
       "      <td>{'price_day_ahead': False}</td>\n",
       "      <td>11.811</td>\n",
       "      <td>32.664</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>1.248</td>\n",
       "      <td>6.668</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost1</th>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>2.465</td>\n",
       "      <td>5.85</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost2</th>\n",
       "      <td>{'max_depth': 2, 'price_day_ahead': False}</td>\n",
       "      <td>4.331</td>\n",
       "      <td>27.241</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost3</th>\n",
       "      <td>{'max_depth': 16, 'price_day_ahead': False}</td>\n",
       "      <td>0.026</td>\n",
       "      <td>24.84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn1</th>\n",
       "      <td>1-to-1</td>\n",
       "      <td>2.468</td>\n",
       "      <td>3.946</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn2</th>\n",
       "      <td>1-to-1, price_day_ahead:False</td>\n",
       "      <td>6.849</td>\n",
       "      <td>23.042</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn3</th>\n",
       "      <td>24-to-24</td>\n",
       "      <td>4.022</td>\n",
       "      <td>3.848</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn4</th>\n",
       "      <td>LSTM, 7-day input</td>\n",
       "      <td>5.202</td>\n",
       "      <td>8.699</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn5</th>\n",
       "      <td>LSTM, 7-day input</td>\n",
       "      <td>5.493</td>\n",
       "      <td>8.821</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn6</th>\n",
       "      <td>dnn-lstm, 1-day input</td>\n",
       "      <td>3.944</td>\n",
       "      <td>7.55</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Parameters SMAPE_train SMAPE_val  \\\n",
       "NEMO                                             None       16.03    16.922   \n",
       "Lasso                                         Vanilla       3.021     5.869   \n",
       "Lasso1                            {'num_features': 5}       4.134     8.354   \n",
       "Lasso2                     {'price_day_ahead': False}      11.811    32.664   \n",
       "XGBoost                                       Vanilla       1.248     6.668   \n",
       "XGBoost1                             {'max_depth': 2}       2.465      5.85   \n",
       "XGBoost2   {'max_depth': 2, 'price_day_ahead': False}       4.331    27.241   \n",
       "XGBoost3  {'max_depth': 16, 'price_day_ahead': False}       0.026     24.84   \n",
       "nn1                                            1-to-1       2.468     3.946   \n",
       "nn2                     1-to-1, price_day_ahead:False       6.849    23.042   \n",
       "nn3                                          24-to-24       4.022     3.848   \n",
       "nn4                                 LSTM, 7-day input       5.202     8.699   \n",
       "nn5                                 LSTM, 7-day input       5.493     8.821   \n",
       "nn6                             dnn-lstm, 1-day input       3.944      7.55   \n",
       "\n",
       "         r2_train r2_val  \n",
       "NEMO        0.954  0.971  \n",
       "Lasso       0.977  0.973  \n",
       "Lasso1      0.954  0.971  \n",
       "Lasso2      0.676  0.557  \n",
       "XGBoost     0.996  0.968  \n",
       "XGBoost1    0.984   0.97  \n",
       "XGBoost2    0.953  0.427  \n",
       "XGBoost3      1.0  0.403  \n",
       "nn1         0.983  0.979  \n",
       "nn2         0.907  0.428  \n",
       "nn3         0.983  0.979  \n",
       "nn4         0.923  0.879  \n",
       "nn5         0.904  0.862  \n",
       "nn6          0.96  0.972  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_actual.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression <a class=\"anchor\" id=\"Lasso-Regression\"></a>\n",
    "I'll start with a simple Lasso Regression.  Lasso Regression is really just a a linear regression that introduces a penalty infront of each coefficient in the model. Lasso is well-suited for datasets with high multicolinearities since it automatically selects for one of the features in a colinear pair. As part of the [preprocessing] for this model, I also remove features with high colinearity (>0.8). In fitting the below, I'll take the following steps:\n",
    "\n",
    "* Split the data into training (2015-2019) and validation (2020)\n",
    "* Fit a Vanilla lasso regression model with max_iter=10000 to make sure that the model converges.\n",
    "* Compute the output and add it to the results table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>SMAPE_train</th>\n",
       "      <th>SMAPE_val</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NEMO</th>\n",
       "      <td>None</td>\n",
       "      <td>16.03</td>\n",
       "      <td>16.922</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>3.021</td>\n",
       "      <td>5.869</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Parameters SMAPE_train SMAPE_val r2_train r2_val\n",
       "NEMO        None       16.03    16.922    0.954  0.971\n",
       "Lasso    Vanilla       3.021     5.869    0.977  0.973"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data\n",
    "X_train, y_train, X_val, y_val = split_data(df_lr, 2020, 'price_actual')\n",
    "\n",
    "# Instatiate and fit model on \n",
    "lasso = Lasso(max_iter=10000, random_state=17)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Add results of vanilla lasso to dataframe\n",
    "results_actual['Lasso'] = compute_metrics(lasso, 'Vanilla', (X_train, y_train), (X_val, y_val))\n",
    "\n",
    "# Save model\n",
    "with open('../models/Lasso.pickle', 'wb') as f:\n",
    "    pickle.dump(lasso, f)\n",
    "\n",
    "results_actual.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/lasso_vanilla.pickle', 'rb') as file:\n",
    "    lasso_test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vanilla model performed extremely well.  That's great, but it also isn't suprising given that we used the `price_day_ahead` as a predictor which has an r-squared value of 0.971 on the validation set.  The model outperformed the NEMO predictions in SMAPE and even increased r-squared by a small margin. Increased r-squared must mean that some of the other features were important in our prediction of `price_actual`.  I plotted the coefficients for this vanilla model on the below barchart.\n",
    "\n",
    "<img src=\"../images/lasso_feature_importance.png\" style=\"width:700px;height:272px\"/>\n",
    "\n",
    "As expected, `price_day_ahead` dominates this model, though renewable generation and waste generation have an impact, negatively affecting the price (renewable and waste increase, results in price decrease).  Other than that, the other features have very little influence on the final price.  \n",
    "\n",
    "**Recursive Feature Elimination**<br>\n",
    "As part of the [Lasso](https://github.com/EvanHolder/capstone/blob/main/notebooks/LassoRegression.ipynb) notebook, I ran a recursive feature elimination to see how the model performs with varying amounts of features in the model.  I started with a single feature (`price_day_ahead`), trained a model, and computed its metrics. Then I iteratively added in the next most important feature, trained the new model, and computed its metrics.  This process was repeated until all features were added back into the training set and the metrics were plotted as below.\n",
    "\n",
    "![RFE_LassoRegression](../images/RFE_LassoRegression.png)\n",
    "\n",
    "As shown above, when trained on top five features, the model minimizes r-squared.  Below, I'll train the model on these top five features (`price_day_ahead`, `renewable_lag`,`waste_lag`,`oil_lag`,`humidities_seville_lag`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>SMAPE_train</th>\n",
       "      <th>SMAPE_val</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NEMO</th>\n",
       "      <td>None</td>\n",
       "      <td>16.03</td>\n",
       "      <td>16.922</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>3.021</td>\n",
       "      <td>5.869</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso1</th>\n",
       "      <td>{'num_features': 5}</td>\n",
       "      <td>3.367</td>\n",
       "      <td>5.056</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Parameters SMAPE_train SMAPE_val r2_train r2_val\n",
       "NEMO                   None       16.03    16.922    0.954  0.971\n",
       "Lasso               Vanilla       3.021     5.869    0.977  0.973\n",
       "Lasso1  {'num_features': 5}       3.367     5.056    0.971  0.969"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Important Features\n",
    "train_cols = ['humidities_bilbao_lag', 'oil_lag', 'renewable_lag', 'waste_lag', 'price_day_ahead']\n",
    "\n",
    "# Instatiate and fit model on \n",
    "lasso1 = Lasso(max_iter=10000,random_state=17)\n",
    "lasso1.fit(X_train[train_cols], y_train)\n",
    "\n",
    "# Add results of vanilla lasso to dataframe\n",
    "results_actual['Lasso1'] = compute_metrics(lasso1, {'num_features':5}, (X_train[train_cols], y_train), (X_val[train_cols], y_val))\n",
    "\n",
    "# Save model\n",
    "with open('../models/Lasso1.pickle', 'wb') as f:\n",
    "    pickle.dump(lasso1, f)\n",
    "    \n",
    "# Preview\n",
    "results_actual.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Lasso1 includes only five predictors, it's not surprising that the model performance (SMAPE & r-squared) decreased from the vanilla model.  Performance decreased only marginally though.  Next, let's see just how well we can do without using `price_day_ahead`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>SMAPE_train</th>\n",
       "      <th>SMAPE_val</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NEMO</th>\n",
       "      <td>None</td>\n",
       "      <td>16.03</td>\n",
       "      <td>16.922</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>3.021</td>\n",
       "      <td>5.869</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso1</th>\n",
       "      <td>{'num_features': 5}</td>\n",
       "      <td>3.367</td>\n",
       "      <td>5.056</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso2</th>\n",
       "      <td>{'price_day_ahead': False}</td>\n",
       "      <td>11.811</td>\n",
       "      <td>32.664</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Parameters SMAPE_train SMAPE_val r2_train r2_val\n",
       "NEMO                          None       16.03    16.922    0.954  0.971\n",
       "Lasso                      Vanilla       3.021     5.869    0.977  0.973\n",
       "Lasso1         {'num_features': 5}       3.367     5.056    0.971  0.969\n",
       "Lasso2  {'price_day_ahead': False}      11.811    32.664    0.676  0.557"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop 'price_day_ahead'\n",
    "X_train1, X_val1 = X_train.drop(columns='price_day_ahead'), X_val.drop(columns='price_day_ahead')\n",
    "\n",
    "# Instatiate and fit model on \n",
    "lasso2 = Lasso(max_iter=10000, random_state=17)\n",
    "lasso2.fit(X_train1, y_train)\n",
    "\n",
    "# Add results of vanilla lasso to dataframe\n",
    "results_actual['Lasso2'] = compute_metrics(lasso2, {'price_day_ahead':False}, (X_train1, y_train), (X_val1, y_val))\n",
    "\n",
    "# Save Model\n",
    "with open('../models/Lasso2.pickle', 'wb') as f:\n",
    "    pickle.dump(lasso2, f)\n",
    "\n",
    "# Preview\n",
    "results_actual.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso2 performed approximately half as well as the other two Lasso models (SMAPE, r-squared).  The difference in performance between these models indicates that we really need `price_day_ahead` to match the NEMO's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Regression <a class=\"anchor\" id=\"XGBoost-Regression\"></a>\n",
    "XGBoost is the next choice in Machine Learning algorithms because of it's ability to learn non-linear decision boundaries.  So while we were unsuccessful in modeling without `price_day_ahead` with Lasso Regression, we'll give it another shot here with XGBoost.  XGBoost was chosen over Random Forest and other gradient boosted ensembles because it trains the fastest and generally performs better. The other great thing about XGBoost is it requires very little prepocessing. In fitting the below, I'll take the following steps:\n",
    "\n",
    "* Split the data into training (2015-2019) and validation (2020)\n",
    "* Fit a Vanilla XGBoostRegressor with random_state set to 17\n",
    "* Compute the output and add it to the results table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>SMAPE_train</th>\n",
       "      <th>SMAPE_val</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NEMO</th>\n",
       "      <td>None</td>\n",
       "      <td>16.03</td>\n",
       "      <td>16.922</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>3.021</td>\n",
       "      <td>5.869</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso1</th>\n",
       "      <td>{'num_features': 5}</td>\n",
       "      <td>3.367</td>\n",
       "      <td>5.056</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso2</th>\n",
       "      <td>{'price_day_ahead': False}</td>\n",
       "      <td>11.811</td>\n",
       "      <td>32.664</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>1.248</td>\n",
       "      <td>6.668</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Parameters SMAPE_train SMAPE_val r2_train r2_val\n",
       "NEMO                           None       16.03    16.922    0.954  0.971\n",
       "Lasso                       Vanilla       3.021     5.869    0.977  0.973\n",
       "Lasso1          {'num_features': 5}       3.367     5.056    0.971  0.969\n",
       "Lasso2   {'price_day_ahead': False}      11.811    32.664    0.676  0.557\n",
       "XGBoost                     Vanilla       1.248     6.668    0.996  0.968"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data\n",
    "X_train, y_train, X_val, y_val = split_data(df_xg, 2020, 'price_actual')\n",
    "\n",
    "# Instantiate and fit XGBRegressor\n",
    "xg = XGBRegressor(random_state=17)\n",
    "xg.fit(X_train, y_train)\n",
    "\n",
    "# Compute sMAPE, r2 and add to the table\n",
    "results_actual['XGBoost'] = compute_metrics(xg, 'Vanilla',(X_train, y_train), (X_val, y_val))\n",
    "\n",
    "# Save Model\n",
    "with open('../models/XGBoost.pickle', 'wb') as f:\n",
    "    pickle.dump(xg, f)\n",
    "\n",
    "# Preview\n",
    "results_actual.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vanilla model did beat the NEMO performance (SMAPE , r-squared) but surprisingly did not outperform the vanilla Lasso model. The model does not appear too overfit on r2_val, but partly on SMAPE_val.  As part of the [XGBoost notebook](https://github.com/EvanHolder/capstone/blob/main/notebooks/XGBoost.ipynb) I tried to reduce this overfitting on by iteratively training XGBoost models and tuning the below parameters.\n",
    "\n",
    "max_depth....................... [1,2,4,6,8,10,14,16,20],<br>\n",
    "gamma............................. [n/10 for n in range(11)]<br>\n",
    "min_child_weight.............. [1,2,4,8,16,32],<br>\n",
    "subsample........................ [n/10 for n in range(0, 12, 2)],<br>\n",
    "colsample_bytree............. [n/10 for n in range(0, 12, 2)],<br>\n",
    "reg_alpha......................... [.001, .01, .1, .5, 1],<br>\n",
    "reg_lambda...................... [.001, .01, .1, .5, 1]\n",
    "\n",
    "Adjusting all of these parameters in their respective ranges, there really wasn't much improvement in either of the metrics sMAPE or r2. The one exception may be `max_depth` which did see minor improvement in SMAPE when reduced set to 2.\n",
    "\n",
    "Below, I'll run another model ith `max_depth` set to 2 and add it to the results table.\n",
    "\n",
    "Tuning these parameters did not change the metrics in a substantial way.  `Max_depth`, the most influential, made only a marginal difference SMAPE.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>SMAPE_train</th>\n",
       "      <th>SMAPE_val</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NEMO</th>\n",
       "      <td>None</td>\n",
       "      <td>16.03</td>\n",
       "      <td>16.922</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>3.021</td>\n",
       "      <td>5.869</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso1</th>\n",
       "      <td>{'num_features': 5}</td>\n",
       "      <td>3.367</td>\n",
       "      <td>5.056</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso2</th>\n",
       "      <td>{'price_day_ahead': False}</td>\n",
       "      <td>11.811</td>\n",
       "      <td>32.664</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>1.248</td>\n",
       "      <td>6.668</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost1</th>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>2.465</td>\n",
       "      <td>5.85</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Parameters SMAPE_train SMAPE_val r2_train r2_val\n",
       "NEMO                            None       16.03    16.922    0.954  0.971\n",
       "Lasso                        Vanilla       3.021     5.869    0.977  0.973\n",
       "Lasso1           {'num_features': 5}       3.367     5.056    0.971  0.969\n",
       "Lasso2    {'price_day_ahead': False}      11.811    32.664    0.676  0.557\n",
       "XGBoost                      Vanilla       1.248     6.668    0.996  0.968\n",
       "XGBoost1            {'max_depth': 2}       2.465      5.85    0.984   0.97"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data\n",
    "X_train, y_train, X_val, y_val = split_data(df_xg, 2020, 'price_actual')\n",
    "\n",
    "# Instantiate and fit XGBRegressor\n",
    "xg1 = XGBRegressor(random_state=17, max_depth=2)\n",
    "xg1.fit(X_train, y_train)\n",
    "\n",
    "# Compute sMAPE, r2 and add to the table\n",
    "results_actual['XGBoost1'] = compute_metrics(xg1, {'max_depth':2},(X_train, y_train), (X_val, y_val))\n",
    "\n",
    "# Save Model\n",
    "with open('../models/XGBoost1.pickle', 'wb') as f:\n",
    "    pickle.dump(xg1, f)\n",
    "\n",
    "# Preview\n",
    "results_actual.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost1 does have a reduced SMAPE_val and increased r2_val, but does not outperform Lasso.  Let's next look at the feature importances from XGBoost1. I suspect that like Lasso, and given that a max tree depth of two is all we need for good performance, that `price_day_ahead` again dominates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>price_day_ahead</th>\n",
       "      <td>0.735356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>biomass_lag</th>\n",
       "      <td>0.046353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>renewable_lag</th>\n",
       "      <td>0.037915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>load_forecast</th>\n",
       "      <td>0.035208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coal_lag</th>\n",
       "      <td>0.034028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waste_lag</th>\n",
       "      <td>0.020222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transmission_fs_lag</th>\n",
       "      <td>0.008342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dew_point_seville_lag</th>\n",
       "      <td>0.007706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>solar_lag</th>\n",
       "      <td>0.006477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reservoir_lag</th>\n",
       "      <td>0.006204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       importance\n",
       "price_day_ahead          0.735356\n",
       "biomass_lag              0.046353\n",
       "renewable_lag            0.037915\n",
       "load_forecast            0.035208\n",
       "coal_lag                 0.034028\n",
       "waste_lag                0.020222\n",
       "transmission_fs_lag      0.008342\n",
       "dew_point_seville_lag    0.007706\n",
       "solar_lag                0.006477\n",
       "reservoir_lag            0.006204"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp = pd.DataFrame({'importance':xg1.feature_importances_},\n",
    "                   index=X_train.columns).sort_values(by='importance', ascending=False)\n",
    "imp.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the `price_day_ahead` has dominated.  Let's remove it and see how we do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>SMAPE_train</th>\n",
       "      <th>SMAPE_val</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NEMO</th>\n",
       "      <td>None</td>\n",
       "      <td>16.03</td>\n",
       "      <td>16.922</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>3.021</td>\n",
       "      <td>5.869</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso1</th>\n",
       "      <td>{'num_features': 5}</td>\n",
       "      <td>3.367</td>\n",
       "      <td>5.056</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso2</th>\n",
       "      <td>{'price_day_ahead': False}</td>\n",
       "      <td>11.811</td>\n",
       "      <td>32.664</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>1.248</td>\n",
       "      <td>6.668</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost1</th>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>2.465</td>\n",
       "      <td>5.85</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost2</th>\n",
       "      <td>{'max_depth': 2, 'price_day_ahead': False}</td>\n",
       "      <td>4.331</td>\n",
       "      <td>27.241</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Parameters SMAPE_train SMAPE_val  \\\n",
       "NEMO                                            None       16.03    16.922   \n",
       "Lasso                                        Vanilla       3.021     5.869   \n",
       "Lasso1                           {'num_features': 5}       3.367     5.056   \n",
       "Lasso2                    {'price_day_ahead': False}      11.811    32.664   \n",
       "XGBoost                                      Vanilla       1.248     6.668   \n",
       "XGBoost1                            {'max_depth': 2}       2.465      5.85   \n",
       "XGBoost2  {'max_depth': 2, 'price_day_ahead': False}       4.331    27.241   \n",
       "\n",
       "         r2_train r2_val  \n",
       "NEMO        0.954  0.971  \n",
       "Lasso       0.977  0.973  \n",
       "Lasso1      0.971  0.969  \n",
       "Lasso2      0.676  0.557  \n",
       "XGBoost     0.996  0.968  \n",
       "XGBoost1    0.984   0.97  \n",
       "XGBoost2    0.953  0.427  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop price_day_ahead\n",
    "X_train1, X_val1 = X_train.drop(columns='price_day_ahead'), X_val.drop(columns='price_day_ahead')\n",
    "\n",
    "\n",
    "# Instantiate and fit XGBRegressor\n",
    "xg2 = XGBRegressor(random_state=17)\n",
    "xg2.fit(X_train1, y_train)\n",
    "\n",
    "# Compute sMAPE, r2 and add to the table\n",
    "results_actual['XGBoost2'] = compute_metrics(xg2, {'max_depth':2,\n",
    "                                                   'price_day_ahead':False},(X_train1, y_train), (X_val1, y_val))\n",
    "# Save Model\n",
    "with open('../models/XGBoost2.pickle', 'wb') as f:\n",
    "    pickle.dump(xg2, f)\n",
    "\n",
    "# Preview\n",
    "results_actual.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again without our most important feature, the model performance has essentially halved (SMAPE and r2).  I further tuned XGBoost trained without `price_day_ahead` but the peformance did not improve substantially. Increasing tree depth was the only parameter that seemed to increase performance.  Below is another list of the tuned parameters, see the [notebook](https://github.com/EvanHolder/capstone/blob/main/notebooks/XGBoost.ipynb) for the plots displaying each model, and how it performed with the below list of tuned parameters.\n",
    "\n",
    "max_depth....................... [1,2,4,6,8,10,14,16,20],<br>\n",
    "gamma............................. [n/10 for n in range(11)]<br>\n",
    "min_child_weight.............. [1,2,4,8,16,32],<br>\n",
    "subsample........................ [n/10 for n in range(0, 12, 2)],<br>\n",
    "colsample_bytree............. [n/10 for n in range(0, 12, 2)],<br>\n",
    "reg_alpha......................... [.001, .01, .1, .5, 1],<br>\n",
    "reg_lambda...................... [.001, .01, .1, .5, 1]\n",
    "\n",
    "Lastly, I'll fit an XGBoost model with a max_depth of 16 and add it to the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>SMAPE_train</th>\n",
       "      <th>SMAPE_val</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NEMO</th>\n",
       "      <td>None</td>\n",
       "      <td>16.03</td>\n",
       "      <td>16.922</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>3.021</td>\n",
       "      <td>5.869</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso1</th>\n",
       "      <td>{'num_features': 5}</td>\n",
       "      <td>3.367</td>\n",
       "      <td>5.056</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso2</th>\n",
       "      <td>{'price_day_ahead': False}</td>\n",
       "      <td>11.811</td>\n",
       "      <td>32.664</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>1.248</td>\n",
       "      <td>6.668</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost1</th>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>2.465</td>\n",
       "      <td>5.85</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost2</th>\n",
       "      <td>{'max_depth': 2, 'price_day_ahead': False}</td>\n",
       "      <td>4.331</td>\n",
       "      <td>27.241</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost3</th>\n",
       "      <td>{'max_depth': 16, 'price_day_ahead': False}</td>\n",
       "      <td>0.026</td>\n",
       "      <td>24.84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Parameters SMAPE_train SMAPE_val  \\\n",
       "NEMO                                             None       16.03    16.922   \n",
       "Lasso                                         Vanilla       3.021     5.869   \n",
       "Lasso1                            {'num_features': 5}       3.367     5.056   \n",
       "Lasso2                     {'price_day_ahead': False}      11.811    32.664   \n",
       "XGBoost                                       Vanilla       1.248     6.668   \n",
       "XGBoost1                             {'max_depth': 2}       2.465      5.85   \n",
       "XGBoost2   {'max_depth': 2, 'price_day_ahead': False}       4.331    27.241   \n",
       "XGBoost3  {'max_depth': 16, 'price_day_ahead': False}       0.026     24.84   \n",
       "\n",
       "         r2_train r2_val  \n",
       "NEMO        0.954  0.971  \n",
       "Lasso       0.977  0.973  \n",
       "Lasso1      0.971  0.969  \n",
       "Lasso2      0.676  0.557  \n",
       "XGBoost     0.996  0.968  \n",
       "XGBoost1    0.984   0.97  \n",
       "XGBoost2    0.953  0.427  \n",
       "XGBoost3      1.0  0.403  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit XGBRegressor\n",
    "xg3 = XGBRegressor(random_state=17, max_depth=16)\n",
    "xg3.fit(X_train1, y_train)\n",
    "\n",
    "# Compute sMAPE, r2 and add to the table\n",
    "results_actual['XGBoost3'] = compute_metrics(xg3,\n",
    "                                             {'max_depth':16, 'price_day_ahead':False},\n",
    "                                             (X_train1, y_train), \n",
    "                                             (X_val1, y_val))\n",
    "# Save Model\n",
    "with open('../models/XGBoost3.pickle', 'wb') as f:\n",
    "    pickle.dump(xg3, f)\n",
    "\n",
    "#Preview\n",
    "results_actual.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks <a class=\"anchor\" id=\"Neural-Networks\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network (1-to-1) <a class=\"anchor\" id=\"Neural-Network-1-to-1\"></a>\n",
    "The last class of alorithms to try and fit is neural nets.  These may fit the model better since they have the ability to find non-linear patterns through the hidden layers of the network.  In addition, they more readily take in sequence data. The intuition is that while our features may not have a direct relationship with the actual price, they may nudge the price in a certain direction over the course of time. To start off, we'll set up a simple 1-to-1 (one input, one output) model and see how that performs. The steps to fit this model are:\n",
    "* Split the data into training (2015-2019) and validation (2020)\n",
    "* Set the input_shape\n",
    "* Establish network architecture\n",
    "* Compute the output and add it to the results table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1369/1369 [==============================] - 3s 2ms/step - loss: 2.2614 - SMAPE: 4.8637 - val_loss: 1.6311 - val_SMAPE: 4.8124\n",
      "Epoch 2/200\n",
      "1369/1369 [==============================] - 3s 2ms/step - loss: 1.4848 - SMAPE: 2.8463 - val_loss: 1.4403 - val_SMAPE: 4.2391\n",
      "Epoch 3/200\n",
      "1369/1369 [==============================] - 2s 1ms/step - loss: 1.4177 - SMAPE: 2.7121 - val_loss: 1.5529 - val_SMAPE: 4.6489\n",
      "Epoch 4/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 1.3579 - SMAPE: 2.5898 - val_loss: 1.5314 - val_SMAPE: 4.6528\n",
      "Epoch 5/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 1.3106 - SMAPE: 2.5045 - val_loss: 1.3141 - val_SMAPE: 3.8749\n",
      "Epoch 6/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 1.2887 - SMAPE: 2.4497 - val_loss: 1.3627 - val_SMAPE: 4.0324\n",
      "Epoch 7/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 1.2641 - SMAPE: 2.4029 - val_loss: 1.5824 - val_SMAPE: 4.7348\n",
      "Epoch 8/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 1.2498 - SMAPE: 2.3744 - val_loss: 1.7301 - val_SMAPE: 5.1422\n",
      "Epoch 9/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 1.2195 - SMAPE: 2.3155 - val_loss: 1.7222 - val_SMAPE: 5.2149\n",
      "Epoch 10/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 1.2050 - SMAPE: 2.2858 - val_loss: 1.4986 - val_SMAPE: 4.4577\n",
      "Epoch 11/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 1.1820 - SMAPE: 2.2440 - val_loss: 1.7295 - val_SMAPE: 5.2002\n",
      "Epoch 12/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 1.1668 - SMAPE: 2.2114 - val_loss: 1.7452 - val_SMAPE: 5.3256\n",
      "Epoch 13/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 1.1639 - SMAPE: 2.1998 - val_loss: 1.8116 - val_SMAPE: 5.3280\n",
      "Epoch 14/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 1.1448 - SMAPE: 2.1663 - val_loss: 1.8241 - val_SMAPE: 5.5003\n",
      "Epoch 15/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 1.1391 - SMAPE: 2.1471 - val_loss: 1.6447 - val_SMAPE: 4.8339\n",
      "INFO:tensorflow:Assets written to: ../models/nn1\\assets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>SMAPE_train</th>\n",
       "      <th>SMAPE_val</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NEMO</th>\n",
       "      <td>None</td>\n",
       "      <td>16.03</td>\n",
       "      <td>16.922</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>3.021</td>\n",
       "      <td>5.869</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso1</th>\n",
       "      <td>{'num_features': 5}</td>\n",
       "      <td>3.367</td>\n",
       "      <td>5.056</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso2</th>\n",
       "      <td>{'price_day_ahead': False}</td>\n",
       "      <td>11.811</td>\n",
       "      <td>32.664</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>1.248</td>\n",
       "      <td>6.668</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost1</th>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>2.465</td>\n",
       "      <td>5.85</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost2</th>\n",
       "      <td>{'max_depth': 2, 'price_day_ahead': False}</td>\n",
       "      <td>4.331</td>\n",
       "      <td>27.241</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost3</th>\n",
       "      <td>{'max_depth': 16, 'price_day_ahead': False}</td>\n",
       "      <td>0.026</td>\n",
       "      <td>24.84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn1</th>\n",
       "      <td>1-to-1</td>\n",
       "      <td>3.332</td>\n",
       "      <td>3.88</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Parameters SMAPE_train SMAPE_val  \\\n",
       "NEMO                                             None       16.03    16.922   \n",
       "Lasso                                         Vanilla       3.021     5.869   \n",
       "Lasso1                            {'num_features': 5}       3.367     5.056   \n",
       "Lasso2                     {'price_day_ahead': False}      11.811    32.664   \n",
       "XGBoost                                       Vanilla       1.248     6.668   \n",
       "XGBoost1                             {'max_depth': 2}       2.465      5.85   \n",
       "XGBoost2   {'max_depth': 2, 'price_day_ahead': False}       4.331    27.241   \n",
       "XGBoost3  {'max_depth': 16, 'price_day_ahead': False}       0.026     24.84   \n",
       "nn1                                            1-to-1       3.332      3.88   \n",
       "\n",
       "         r2_train r2_val  \n",
       "NEMO        0.954  0.971  \n",
       "Lasso       0.977  0.973  \n",
       "Lasso1      0.971  0.969  \n",
       "Lasso2      0.676  0.557  \n",
       "XGBoost     0.996  0.968  \n",
       "XGBoost1    0.984   0.97  \n",
       "XGBoost2    0.953  0.427  \n",
       "XGBoost3      1.0  0.403  \n",
       "nn1         0.985  0.979  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split Data\n",
    "X_train, y_train, X_val, y_val = split_data(df_nn, 2020, 'price_actual')\n",
    "\n",
    "# Define input_shape\n",
    "input_shape = (X_train.shape[1],)\n",
    "\n",
    "# Instantiate model and build layers\n",
    "nn = models.Sequential()\n",
    "nn.add(layers.Dense(59, activation='relu', input_shape=input_shape))\n",
    "nn.add(layers.Dense(239, activation='relu'))\n",
    "nn.add(layers.Dense(162, activation='relu'))\n",
    "nn.add(layers.Dense(1, activation='relu'))\n",
    "\n",
    "# Compile and Fit\n",
    "nn1 = compile_fit(nn, (X_train,y_train), (X_val, y_val), patience=10,\n",
    "                  loss = tf.keras.metrics.mean_absolute_error)\n",
    "\n",
    "# Compute metrics, add to table\n",
    "results_actual['nn1'] = compute_metrics(nn1, '1-to-1', (X_train,y_train), (X_val, y_val))\n",
    "\n",
    "# Save Model\n",
    "nn1.save('../models/nn1')\n",
    "\n",
    "# Preview\n",
    "results_actual.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first neural network is our best yet outperforming both Lasso and XGBoost (SMAPE and r2). This is good news, and bodes well for the more complicated neural networks we'll set up soon. Before that, let's run another model without `price_day_ahead`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 6.9826 - SMAPE: 14.1523 - val_loss: 12.4139 - val_SMAPE: 29.9619\n",
      "Epoch 2/200\n",
      "1369/1369 [==============================] - 2s 1ms/step - loss: 5.1166 - SMAPE: 9.6434 - val_loss: 12.0887 - val_SMAPE: 29.2425\n",
      "Epoch 3/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 4.6890 - SMAPE: 8.8301 - val_loss: 12.4094 - val_SMAPE: 29.8206\n",
      "Epoch 4/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 4.4079 - SMAPE: 8.3099 - val_loss: 10.6627 - val_SMAPE: 26.4241\n",
      "Epoch 5/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 4.1517 - SMAPE: 7.8564 - val_loss: 10.3005 - val_SMAPE: 25.5736\n",
      "Epoch 6/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 3.9867 - SMAPE: 7.5496 - val_loss: 11.8114 - val_SMAPE: 28.3833\n",
      "Epoch 7/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 3.8252 - SMAPE: 7.2534 - val_loss: 10.0208 - val_SMAPE: 25.0625\n",
      "Epoch 8/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 3.6896 - SMAPE: 7.0209 - val_loss: 11.5941 - val_SMAPE: 28.0079\n",
      "Epoch 9/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 3.5651 - SMAPE: 6.7849 - val_loss: 10.4777 - val_SMAPE: 26.0043\n",
      "Epoch 10/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 3.5074 - SMAPE: 6.6792 - val_loss: 9.9707 - val_SMAPE: 24.9742\n",
      "Epoch 11/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 3.3939 - SMAPE: 6.4776 - val_loss: 9.5526 - val_SMAPE: 24.1323\n",
      "Epoch 12/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 3.3455 - SMAPE: 6.3771 - val_loss: 11.7334 - val_SMAPE: 28.3638\n",
      "Epoch 13/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 3.2510 - SMAPE: 6.2016 - val_loss: 9.8933 - val_SMAPE: 24.7898\n",
      "Epoch 14/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 3.2166 - SMAPE: 6.1350 - val_loss: 8.2253 - val_SMAPE: 21.4169\n",
      "Epoch 15/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 3.1757 - SMAPE: 6.0533 - val_loss: 10.7096 - val_SMAPE: 26.3586\n",
      "Epoch 16/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 3.1313 - SMAPE: 5.9761 - val_loss: 9.6690 - val_SMAPE: 24.3898\n",
      "Epoch 17/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 3.0783 - SMAPE: 5.8727 - val_loss: 9.8485 - val_SMAPE: 24.6268\n",
      "Epoch 18/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 3.0263 - SMAPE: 5.7825 - val_loss: 9.8759 - val_SMAPE: 24.8234\n",
      "Epoch 19/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 2.9687 - SMAPE: 5.6556 - val_loss: 10.4556 - val_SMAPE: 25.7936\n",
      "Epoch 20/200\n",
      "1369/1369 [==============================] - 3s 2ms/step - loss: 2.9524 - SMAPE: 5.6333 - val_loss: 10.0071 - val_SMAPE: 24.8766\n",
      "Epoch 21/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 2.8988 - SMAPE: 5.5299 - val_loss: 10.9948 - val_SMAPE: 26.8879\n",
      "Epoch 22/200\n",
      "1369/1369 [==============================] - 3s 2ms/step - loss: 2.8752 - SMAPE: 5.4715 - val_loss: 10.2071 - val_SMAPE: 25.3623\n",
      "Epoch 23/200\n",
      "1369/1369 [==============================] - 3s 2ms/step - loss: 2.8211 - SMAPE: 5.3764 - val_loss: 10.7163 - val_SMAPE: 26.2280\n",
      "Epoch 24/200\n",
      "1369/1369 [==============================] - 3s 2ms/step - loss: 2.8069 - SMAPE: 5.3446 - val_loss: 10.1868 - val_SMAPE: 25.5026\n",
      "INFO:tensorflow:Assets written to: ../models/nn2\\assets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>SMAPE_train</th>\n",
       "      <th>SMAPE_val</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NEMO</th>\n",
       "      <td>None</td>\n",
       "      <td>16.03</td>\n",
       "      <td>16.922</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>3.021</td>\n",
       "      <td>5.869</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso1</th>\n",
       "      <td>{'num_features': 5}</td>\n",
       "      <td>3.367</td>\n",
       "      <td>5.056</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso2</th>\n",
       "      <td>{'price_day_ahead': False}</td>\n",
       "      <td>11.811</td>\n",
       "      <td>32.664</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>1.248</td>\n",
       "      <td>6.668</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost1</th>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>2.465</td>\n",
       "      <td>5.85</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost2</th>\n",
       "      <td>{'max_depth': 2, 'price_day_ahead': False}</td>\n",
       "      <td>4.331</td>\n",
       "      <td>27.241</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost3</th>\n",
       "      <td>{'max_depth': 16, 'price_day_ahead': False}</td>\n",
       "      <td>0.026</td>\n",
       "      <td>24.84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn1</th>\n",
       "      <td>1-to-1</td>\n",
       "      <td>3.332</td>\n",
       "      <td>3.88</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn2</th>\n",
       "      <td>1-to-1, price_day_ahead:False</td>\n",
       "      <td>7.139</td>\n",
       "      <td>21.382</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Parameters SMAPE_train SMAPE_val  \\\n",
       "NEMO                                             None       16.03    16.922   \n",
       "Lasso                                         Vanilla       3.021     5.869   \n",
       "Lasso1                            {'num_features': 5}       3.367     5.056   \n",
       "Lasso2                     {'price_day_ahead': False}      11.811    32.664   \n",
       "XGBoost                                       Vanilla       1.248     6.668   \n",
       "XGBoost1                             {'max_depth': 2}       2.465      5.85   \n",
       "XGBoost2   {'max_depth': 2, 'price_day_ahead': False}       4.331    27.241   \n",
       "XGBoost3  {'max_depth': 16, 'price_day_ahead': False}       0.026     24.84   \n",
       "nn1                                            1-to-1       3.332      3.88   \n",
       "nn2                     1-to-1, price_day_ahead:False       7.139    21.382   \n",
       "\n",
       "         r2_train r2_val  \n",
       "NEMO        0.954  0.971  \n",
       "Lasso       0.977  0.973  \n",
       "Lasso1      0.971  0.969  \n",
       "Lasso2      0.676  0.557  \n",
       "XGBoost     0.996  0.968  \n",
       "XGBoost1    0.984   0.97  \n",
       "XGBoost2    0.953  0.427  \n",
       "XGBoost3      1.0  0.403  \n",
       "nn1         0.985  0.979  \n",
       "nn2         0.906  0.467  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split Data\n",
    "X_train, y_train, X_val, y_val = split_data(df_nn.drop(columns='price_day_ahead'), 2020, 'price_actual')\n",
    "\n",
    "# Define input_shape\n",
    "input_shape = (X_train.shape[1],)\n",
    "\n",
    "# Instantiate model and build layers\n",
    "nn = models.Sequential()\n",
    "nn.add(layers.Dense(59, activation='relu', input_shape=input_shape))\n",
    "nn.add(layers.Dense(239, activation='relu'))\n",
    "nn.add(layers.Dense(162, activation='relu'))\n",
    "nn.add(layers.Dense(1, activation='relu'))\n",
    "\n",
    "# Compile and Fit\n",
    "nn2 = compile_fit(nn, (X_train,y_train), (X_val, y_val), patience=10,\n",
    "                  loss = tf.keras.metrics.mean_absolute_error)\n",
    "\n",
    "# Compute metrics, add to table\n",
    "results_actual['nn2'] = compute_metrics(nn2, '1-to-1, price_day_ahead:False', (X_train,y_train), (X_val, y_val))\n",
    "\n",
    "# Save Model\n",
    "nn2.save('../models/nn2')\n",
    "\n",
    "# Preview\n",
    "results_actual.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected performance decreased (SMAPE and r2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network (24 to 24) <a class=\"anchor\" id=\"Neural-Network-24-to-24\"></a>\n",
    "The next network will be a little more complicated by using sequences to predict another sequence. We'll reshape the input and output into 24 hour sequences, and 1825 batches. The network architecture change slightly too. I'll wrap the output Dense layer in a TimeDistributed wrapper.  This will transform my output into a vector of length 24, to match up with the output sequences of length 24. The steps to fit this model are the same as the 1-to-1 network with an extra step to process the input/output data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 11.6937 - SMAPE: 30.0617 - val_loss: 2.7429 - val_SMAPE: 7.3544\n",
      "Epoch 2/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 2.2464 - SMAPE: 4.3285 - val_loss: 2.2835 - val_SMAPE: 6.4569\n",
      "Epoch 3/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.9188 - SMAPE: 3.7321 - val_loss: 3.8568 - val_SMAPE: 10.0007\n",
      "Epoch 4/200\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.9527 - SMAPE: 3.7275 - val_loss: 2.0476 - val_SMAPE: 5.7761\n",
      "Epoch 5/200\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 1.7045 - SMAPE: 3.3793 - val_loss: 2.1667 - val_SMAPE: 6.1268\n",
      "Epoch 6/200\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 1.8006 - SMAPE: 3.4305 - val_loss: 2.3319 - val_SMAPE: 6.6150\n",
      "Epoch 7/200\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 1.6192 - SMAPE: 3.1372 - val_loss: 2.4482 - val_SMAPE: 6.9835\n",
      "Epoch 8/200\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.6070 - SMAPE: 3.1082 - val_loss: 1.4913 - val_SMAPE: 4.2686\n",
      "Epoch 9/200\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.6659 - SMAPE: 3.2473 - val_loss: 2.0735 - val_SMAPE: 5.9354\n",
      "Epoch 10/200\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 1.5556 - SMAPE: 2.9906 - val_loss: 1.8902 - val_SMAPE: 5.4273\n",
      "Epoch 11/200\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5453 - SMAPE: 2.9314 - val_loss: 2.3350 - val_SMAPE: 6.6417\n",
      "Epoch 12/200\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5073 - SMAPE: 2.8952 - val_loss: 1.4830 - val_SMAPE: 4.3090\n",
      "Epoch 13/200\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5986 - SMAPE: 3.0357 - val_loss: 1.5289 - val_SMAPE: 4.4878\n",
      "Epoch 14/200\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 1.6403 - SMAPE: 3.0881 - val_loss: 3.0464 - val_SMAPE: 8.3543\n",
      "Epoch 15/200\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5605 - SMAPE: 2.9947 - val_loss: 1.8435 - val_SMAPE: 5.3874\n",
      "Epoch 16/200\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4368 - SMAPE: 2.7961 - val_loss: 2.5743 - val_SMAPE: 7.1414\n",
      "Epoch 17/200\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.5795 - SMAPE: 2.9589 - val_loss: 2.5711 - val_SMAPE: 7.2421\n",
      "Epoch 18/200\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 1.4982 - SMAPE: 2.8424 - val_loss: 2.2728 - val_SMAPE: 6.4285\n",
      "INFO:tensorflow:Assets written to: ../models/nn3\\assets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>SMAPE_train</th>\n",
       "      <th>SMAPE_val</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NEMO</th>\n",
       "      <td>None</td>\n",
       "      <td>16.03</td>\n",
       "      <td>16.922</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>3.021</td>\n",
       "      <td>5.869</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso1</th>\n",
       "      <td>{'num_features': 5}</td>\n",
       "      <td>3.367</td>\n",
       "      <td>5.056</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso2</th>\n",
       "      <td>{'price_day_ahead': False}</td>\n",
       "      <td>11.811</td>\n",
       "      <td>32.664</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>1.248</td>\n",
       "      <td>6.668</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost1</th>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>2.465</td>\n",
       "      <td>5.85</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost2</th>\n",
       "      <td>{'max_depth': 2, 'price_day_ahead': False}</td>\n",
       "      <td>4.331</td>\n",
       "      <td>27.241</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost3</th>\n",
       "      <td>{'max_depth': 16, 'price_day_ahead': False}</td>\n",
       "      <td>0.026</td>\n",
       "      <td>24.84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn1</th>\n",
       "      <td>1-to-1</td>\n",
       "      <td>3.332</td>\n",
       "      <td>3.88</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn2</th>\n",
       "      <td>1-to-1, price_day_ahead:False</td>\n",
       "      <td>7.139</td>\n",
       "      <td>21.382</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn3</th>\n",
       "      <td>24-to-24</td>\n",
       "      <td>4.096</td>\n",
       "      <td>4.301</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Parameters SMAPE_train SMAPE_val  \\\n",
       "NEMO                                             None       16.03    16.922   \n",
       "Lasso                                         Vanilla       3.021     5.869   \n",
       "Lasso1                            {'num_features': 5}       3.367     5.056   \n",
       "Lasso2                     {'price_day_ahead': False}      11.811    32.664   \n",
       "XGBoost                                       Vanilla       1.248     6.668   \n",
       "XGBoost1                             {'max_depth': 2}       2.465      5.85   \n",
       "XGBoost2   {'max_depth': 2, 'price_day_ahead': False}       4.331    27.241   \n",
       "XGBoost3  {'max_depth': 16, 'price_day_ahead': False}       0.026     24.84   \n",
       "nn1                                            1-to-1       3.332      3.88   \n",
       "nn2                     1-to-1, price_day_ahead:False       7.139    21.382   \n",
       "nn3                                          24-to-24       4.096     4.301   \n",
       "\n",
       "         r2_train r2_val  \n",
       "NEMO        0.954  0.971  \n",
       "Lasso       0.977  0.973  \n",
       "Lasso1      0.971  0.969  \n",
       "Lasso2      0.676  0.557  \n",
       "XGBoost     0.996  0.968  \n",
       "XGBoost1    0.984   0.97  \n",
       "XGBoost2    0.953  0.427  \n",
       "XGBoost3      1.0  0.403  \n",
       "nn1         0.985  0.979  \n",
       "nn2         0.906  0.467  \n",
       "nn3         0.976  0.974  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split Data\n",
    "X_train, y_train, X_val, y_val = split_data(df_nn, 2020, 'price_actual')\n",
    "\n",
    "# Reorganize the training and testing data into batches\n",
    "X_train, y_train = resample((X_train, y_train), 24, 24, 24)\n",
    "X_val, y_val = resample((X_val,y_val), 24, 24, 24)\n",
    "\n",
    "# Define input_shape\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "# Instantiate model and build layers\n",
    "nn = models.Sequential()\n",
    "nn.add(layers.Dense(59, activation='relu', input_shape=input_shape))\n",
    "nn.add(layers.Dense(239, activation='relu'))\n",
    "nn.add(layers.Dense(162, activation='relu'))\n",
    "nn.add(TimeDistributed(layers.Dense(1)))\n",
    "\n",
    "# Compile and Fit\n",
    "nn3 = compile_fit(nn, (X_train, y_train), (X_val, y_val))\n",
    "\n",
    "# Compute metrics and add to table\n",
    "results_actual['nn3'] = compute_metrics(nn3, '24-to-24', (X_train,y_train), (X_val, y_val))\n",
    "\n",
    "# Save model\n",
    "nn3.save('../models/nn3')\n",
    "\n",
    "# Preview\n",
    "results_actual.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we have again improved (be it slightly) in SMAPE_val and r2_val."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Neural Network <a class=\"anchor\" id=\"LSTM-Neural-Network\"></a>\n",
    "Long-Short-Term-Memory neural networks are a type of recurrent neural network that have gates that allow the network to \"remember\" and \"forget\" information from a specified input window.  In this way, the model is able to better estimate time-dependent output sequences. Since much of the dataset are time-series sequences (including price_actual) it is possible that an LSTM will be able to pick up on time-dependent relationships that our other alogorithms and networks could not. The process for setting up this network is the same as the previous.  Architecture willl be change to include two LSTM layers, and a repeat vector layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "58/58 [==============================] - 7s 91ms/step - loss: 53.2571 - SMAPE: 174.9215 - val_loss: 33.0330 - val_SMAPE: 142.4845\n",
      "Epoch 2/200\n",
      "58/58 [==============================] - 5s 83ms/step - loss: 49.6235 - SMAPE: 152.4068 - val_loss: 30.9795 - val_SMAPE: 126.9025\n",
      "Epoch 3/200\n",
      "58/58 [==============================] - 5s 79ms/step - loss: 47.8563 - SMAPE: 142.2862 - val_loss: 29.3452 - val_SMAPE: 115.5986\n",
      "Epoch 4/200\n",
      "58/58 [==============================] - 4s 77ms/step - loss: 46.2619 - SMAPE: 134.0998 - val_loss: 27.7945 - val_SMAPE: 105.6441\n",
      "Epoch 5/200\n",
      "58/58 [==============================] - 4s 76ms/step - loss: 44.7245 - SMAPE: 126.5850 - val_loss: 26.2897 - val_SMAPE: 96.6151\n",
      "Epoch 6/200\n",
      "58/58 [==============================] - 4s 75ms/step - loss: 43.2207 - SMAPE: 117.9290 - val_loss: 24.8206 - val_SMAPE: 88.3475\n",
      "Epoch 7/200\n",
      "58/58 [==============================] - 4s 76ms/step - loss: 41.7432 - SMAPE: 112.6982 - val_loss: 23.3870 - val_SMAPE: 80.7568\n",
      "Epoch 8/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 40.2886 - SMAPE: 105.3173 - val_loss: 21.9862 - val_SMAPE: 73.7569\n",
      "Epoch 9/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 38.8517 - SMAPE: 100.5338 - val_loss: 20.6202 - val_SMAPE: 67.2956\n",
      "Epoch 10/200\n",
      "58/58 [==============================] - 4s 75ms/step - loss: 37.4349 - SMAPE: 94.7182 - val_loss: 19.2920 - val_SMAPE: 61.3389\n",
      "Epoch 11/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 36.0346 - SMAPE: 89.5652 - val_loss: 18.0138 - val_SMAPE: 55.8974\n",
      "Epoch 12/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 34.6500 - SMAPE: 84.3703 - val_loss: 16.7788 - val_SMAPE: 50.8967\n",
      "Epoch 13/200\n",
      "58/58 [==============================] - 4s 75ms/step - loss: 33.2776 - SMAPE: 78.9154 - val_loss: 15.6039 - val_SMAPE: 46.3558\n",
      "Epoch 14/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 31.9175 - SMAPE: 74.4574 - val_loss: 14.4632 - val_SMAPE: 42.1449\n",
      "Epoch 15/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 30.5695 - SMAPE: 70.5391 - val_loss: 13.4551 - val_SMAPE: 38.5793\n",
      "Epoch 16/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 29.2353 - SMAPE: 66.2262 - val_loss: 12.4966 - val_SMAPE: 35.3155\n",
      "Epoch 17/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 27.9397 - SMAPE: 61.8038 - val_loss: 11.6378 - val_SMAPE: 32.4956\n",
      "Epoch 18/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 26.6343 - SMAPE: 58.0149 - val_loss: 10.6553 - val_SMAPE: 29.3937\n",
      "Epoch 19/200\n",
      "58/58 [==============================] - 4s 76ms/step - loss: 25.3482 - SMAPE: 54.5311 - val_loss: 9.7725 - val_SMAPE: 26.8193\n",
      "Epoch 20/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 24.0611 - SMAPE: 50.4389 - val_loss: 9.4405 - val_SMAPE: 25.7149\n",
      "Epoch 21/200\n",
      "58/58 [==============================] - 4s 75ms/step - loss: 22.8032 - SMAPE: 47.3995 - val_loss: 8.5351 - val_SMAPE: 22.9186\n",
      "Epoch 22/200\n",
      "58/58 [==============================] - 4s 75ms/step - loss: 21.5656 - SMAPE: 44.3848 - val_loss: 7.8934 - val_SMAPE: 21.0484\n",
      "Epoch 23/200\n",
      "58/58 [==============================] - 4s 75ms/step - loss: 20.3818 - SMAPE: 40.9311 - val_loss: 7.3590 - val_SMAPE: 19.5837\n",
      "Epoch 24/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 19.1986 - SMAPE: 37.9789 - val_loss: 7.6094 - val_SMAPE: 20.5913\n",
      "Epoch 25/200\n",
      "58/58 [==============================] - 4s 75ms/step - loss: 18.0876 - SMAPE: 35.3084 - val_loss: 6.7170 - val_SMAPE: 17.9454\n",
      "Epoch 26/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 17.0086 - SMAPE: 32.8244 - val_loss: 7.2374 - val_SMAPE: 19.1696\n",
      "Epoch 27/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 16.0161 - SMAPE: 30.2716 - val_loss: 6.3302 - val_SMAPE: 16.8025\n",
      "Epoch 28/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 15.1181 - SMAPE: 28.5815 - val_loss: 6.7710 - val_SMAPE: 18.1977\n",
      "Epoch 29/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 14.2804 - SMAPE: 26.9062 - val_loss: 7.4134 - val_SMAPE: 19.5319\n",
      "Epoch 30/200\n",
      "58/58 [==============================] - 4s 75ms/step - loss: 13.4585 - SMAPE: 24.9491 - val_loss: 6.0972 - val_SMAPE: 16.3057\n",
      "Epoch 31/200\n",
      "58/58 [==============================] - 4s 76ms/step - loss: 12.7456 - SMAPE: 23.2509 - val_loss: 6.1535 - val_SMAPE: 16.5606\n",
      "Epoch 32/200\n",
      "58/58 [==============================] - 4s 75ms/step - loss: 12.2153 - SMAPE: 22.5974 - val_loss: 5.9579 - val_SMAPE: 15.8564\n",
      "Epoch 33/200\n",
      "58/58 [==============================] - 4s 75ms/step - loss: 11.5206 - SMAPE: 21.1521 - val_loss: 6.4648 - val_SMAPE: 16.9020\n",
      "Epoch 34/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 11.0522 - SMAPE: 19.9816 - val_loss: 5.8076 - val_SMAPE: 15.6476\n",
      "Epoch 35/200\n",
      "58/58 [==============================] - 4s 77ms/step - loss: 10.5087 - SMAPE: 18.9089 - val_loss: 5.1929 - val_SMAPE: 14.1274\n",
      "Epoch 36/200\n",
      "58/58 [==============================] - 4s 76ms/step - loss: 10.0533 - SMAPE: 18.0007 - val_loss: 5.4582 - val_SMAPE: 14.5842\n",
      "Epoch 37/200\n",
      "58/58 [==============================] - 4s 75ms/step - loss: 9.5822 - SMAPE: 17.3185 - val_loss: 5.5876 - val_SMAPE: 15.2569\n",
      "Epoch 38/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 9.2661 - SMAPE: 16.4813 - val_loss: 5.2074 - val_SMAPE: 14.2060\n",
      "Epoch 39/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 8.9550 - SMAPE: 15.9715 - val_loss: 4.9542 - val_SMAPE: 13.5416\n",
      "Epoch 40/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 8.6044 - SMAPE: 15.4018 - val_loss: 5.0548 - val_SMAPE: 14.0214\n",
      "Epoch 41/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 8.2649 - SMAPE: 14.8310 - val_loss: 4.6368 - val_SMAPE: 12.7469\n",
      "Epoch 42/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 8.0153 - SMAPE: 14.2436 - val_loss: 5.1697 - val_SMAPE: 13.8404\n",
      "Epoch 43/200\n",
      "58/58 [==============================] - 4s 75ms/step - loss: 7.7484 - SMAPE: 14.1374 - val_loss: 4.4989 - val_SMAPE: 12.5281\n",
      "Epoch 44/200\n",
      "58/58 [==============================] - 4s 75ms/step - loss: 7.5747 - SMAPE: 13.5531 - val_loss: 4.3521 - val_SMAPE: 12.0267\n",
      "Epoch 45/200\n",
      "58/58 [==============================] - 4s 76ms/step - loss: 7.3167 - SMAPE: 13.1387 - val_loss: 4.3006 - val_SMAPE: 11.8832\n",
      "Epoch 46/200\n",
      "58/58 [==============================] - 4s 76ms/step - loss: 7.1123 - SMAPE: 12.6927 - val_loss: 4.5365 - val_SMAPE: 12.4310\n",
      "Epoch 47/200\n",
      "58/58 [==============================] - 5s 78ms/step - loss: 6.8713 - SMAPE: 12.3105 - val_loss: 4.2603 - val_SMAPE: 11.7321\n",
      "Epoch 48/200\n",
      "58/58 [==============================] - 4s 77ms/step - loss: 6.8106 - SMAPE: 12.1351 - val_loss: 4.2989 - val_SMAPE: 11.8289\n",
      "Epoch 49/200\n",
      "58/58 [==============================] - 5s 78ms/step - loss: 6.5002 - SMAPE: 11.7611 - val_loss: 4.2011 - val_SMAPE: 11.6639\n",
      "Epoch 50/200\n",
      "58/58 [==============================] - 5s 79ms/step - loss: 6.3091 - SMAPE: 11.5932 - val_loss: 4.1108 - val_SMAPE: 11.4621\n",
      "Epoch 51/200\n",
      "58/58 [==============================] - 5s 79ms/step - loss: 6.0947 - SMAPE: 11.1059 - val_loss: 4.2370 - val_SMAPE: 11.7828\n",
      "Epoch 52/200\n",
      "58/58 [==============================] - 5s 82ms/step - loss: 5.8685 - SMAPE: 10.5905 - val_loss: 4.2316 - val_SMAPE: 11.9909\n",
      "Epoch 53/200\n",
      "58/58 [==============================] - 5s 82ms/step - loss: 5.6553 - SMAPE: 10.1666 - val_loss: 4.0468 - val_SMAPE: 11.2555\n",
      "Epoch 54/200\n",
      "58/58 [==============================] - 5s 80ms/step - loss: 5.4075 - SMAPE: 9.7422 - val_loss: 3.9276 - val_SMAPE: 10.9884\n",
      "Epoch 55/200\n",
      "58/58 [==============================] - 5s 78ms/step - loss: 5.2745 - SMAPE: 9.5501 - val_loss: 4.0660 - val_SMAPE: 11.3123\n",
      "Epoch 56/200\n",
      "58/58 [==============================] - 4s 77ms/step - loss: 5.2203 - SMAPE: 9.5110 - val_loss: 4.3726 - val_SMAPE: 11.9316\n",
      "Epoch 57/200\n",
      "58/58 [==============================] - 4s 75ms/step - loss: 5.0846 - SMAPE: 9.3031 - val_loss: 4.0858 - val_SMAPE: 11.3202\n",
      "Epoch 58/200\n",
      "58/58 [==============================] - 4s 77ms/step - loss: 4.8523 - SMAPE: 8.8469 - val_loss: 3.8464 - val_SMAPE: 10.7317\n",
      "Epoch 59/200\n",
      "58/58 [==============================] - 5s 78ms/step - loss: 4.6876 - SMAPE: 8.5542 - val_loss: 3.6664 - val_SMAPE: 10.2215\n",
      "Epoch 60/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 4.5738 - SMAPE: 8.4051 - val_loss: 3.6745 - val_SMAPE: 10.2661\n",
      "Epoch 61/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 4.4593 - SMAPE: 8.0819 - val_loss: 3.9415 - val_SMAPE: 10.9685\n",
      "Epoch 62/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 4.3663 - SMAPE: 7.8617 - val_loss: 3.7010 - val_SMAPE: 10.2814\n",
      "Epoch 63/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 4.3314 - SMAPE: 7.9019 - val_loss: 3.7502 - val_SMAPE: 10.4453\n",
      "Epoch 64/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 4.1870 - SMAPE: 7.5495 - val_loss: 3.5922 - val_SMAPE: 10.0652\n",
      "Epoch 65/200\n",
      "58/58 [==============================] - 4s 76ms/step - loss: 4.1312 - SMAPE: 7.4788 - val_loss: 3.6535 - val_SMAPE: 10.2280\n",
      "Epoch 66/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 4.1479 - SMAPE: 7.5362 - val_loss: 3.5585 - val_SMAPE: 9.9163\n",
      "Epoch 67/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 4.0362 - SMAPE: 7.3338 - val_loss: 3.6518 - val_SMAPE: 10.1641\n",
      "Epoch 68/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 3.9542 - SMAPE: 7.2113 - val_loss: 3.9564 - val_SMAPE: 11.1092\n",
      "Epoch 69/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 3.9143 - SMAPE: 7.1094 - val_loss: 3.7082 - val_SMAPE: 10.2959\n",
      "Epoch 70/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 3.8679 - SMAPE: 7.0515 - val_loss: 3.5341 - val_SMAPE: 9.8902\n",
      "Epoch 71/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 3.7999 - SMAPE: 6.9179 - val_loss: 3.5148 - val_SMAPE: 9.8404\n",
      "Epoch 72/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 3.8033 - SMAPE: 6.9191 - val_loss: 3.6100 - val_SMAPE: 10.0920\n",
      "Epoch 73/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 3.7826 - SMAPE: 6.8934 - val_loss: 3.5904 - val_SMAPE: 9.9507\n",
      "Epoch 74/200\n",
      "58/58 [==============================] - 4s 75ms/step - loss: 3.7831 - SMAPE: 6.9039 - val_loss: 3.6395 - val_SMAPE: 10.1916\n",
      "Epoch 75/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 3.7020 - SMAPE: 6.7811 - val_loss: 3.5742 - val_SMAPE: 10.0452\n",
      "Epoch 76/200\n",
      "58/58 [==============================] - 4s 76ms/step - loss: 3.6420 - SMAPE: 6.6767 - val_loss: 3.4412 - val_SMAPE: 9.6754\n",
      "Epoch 77/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 3.6333 - SMAPE: 6.6863 - val_loss: 3.5418 - val_SMAPE: 9.8946\n",
      "Epoch 78/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 3.6190 - SMAPE: 6.5852 - val_loss: 3.5427 - val_SMAPE: 9.9414\n",
      "Epoch 79/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 3.5429 - SMAPE: 6.4950 - val_loss: 3.3598 - val_SMAPE: 9.4023\n",
      "Epoch 80/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 3.5100 - SMAPE: 6.4358 - val_loss: 3.3980 - val_SMAPE: 9.5357\n",
      "Epoch 81/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 3.4630 - SMAPE: 6.4227 - val_loss: 3.3211 - val_SMAPE: 9.3552\n",
      "Epoch 82/200\n",
      "58/58 [==============================] - 4s 71ms/step - loss: 3.5324 - SMAPE: 6.7235 - val_loss: 3.4177 - val_SMAPE: 9.5731\n",
      "Epoch 83/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 3.4340 - SMAPE: 6.3462 - val_loss: 3.3166 - val_SMAPE: 9.2140\n",
      "Epoch 84/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 3.4079 - SMAPE: 6.3834 - val_loss: 3.4785 - val_SMAPE: 9.6017\n",
      "Epoch 85/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 3.6131 - SMAPE: 6.7513 - val_loss: 3.5848 - val_SMAPE: 10.1571\n",
      "Epoch 86/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 3.4476 - SMAPE: 6.3711 - val_loss: 3.5030 - val_SMAPE: 9.6863\n",
      "Epoch 87/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 3.3747 - SMAPE: 6.1789 - val_loss: 3.3748 - val_SMAPE: 9.3978\n",
      "Epoch 88/200\n",
      "58/58 [==============================] - 4s 76ms/step - loss: 3.2753 - SMAPE: 6.0546 - val_loss: 3.2754 - val_SMAPE: 9.1477\n",
      "Epoch 89/200\n",
      "58/58 [==============================] - 4s 75ms/step - loss: 3.2376 - SMAPE: 5.9558 - val_loss: 3.3608 - val_SMAPE: 9.3451\n",
      "Epoch 90/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 3.2191 - SMAPE: 5.9086 - val_loss: 3.4777 - val_SMAPE: 9.6677\n",
      "Epoch 91/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 3.1989 - SMAPE: 5.8901 - val_loss: 3.2142 - val_SMAPE: 8.9867\n",
      "Epoch 92/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 3.1710 - SMAPE: 5.7935 - val_loss: 3.2487 - val_SMAPE: 9.0537\n",
      "Epoch 93/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 3.1309 - SMAPE: 5.8876 - val_loss: 3.2315 - val_SMAPE: 9.0126\n",
      "Epoch 94/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 3.1691 - SMAPE: 5.8525 - val_loss: 3.2976 - val_SMAPE: 9.0909\n",
      "Epoch 95/200\n",
      "58/58 [==============================] - 4s 75ms/step - loss: 3.2307 - SMAPE: 6.0049 - val_loss: 3.2433 - val_SMAPE: 9.0901\n",
      "Epoch 96/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 3.0500 - SMAPE: 5.6029 - val_loss: 3.2869 - val_SMAPE: 9.1541\n",
      "Epoch 97/200\n",
      "58/58 [==============================] - 4s 75ms/step - loss: 3.0404 - SMAPE: 5.5640 - val_loss: 3.1842 - val_SMAPE: 8.9135\n",
      "Epoch 98/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 2.9611 - SMAPE: 5.4922 - val_loss: 3.1041 - val_SMAPE: 8.7467\n",
      "Epoch 99/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 2.9271 - SMAPE: 5.6519 - val_loss: 3.0810 - val_SMAPE: 8.7002\n",
      "Epoch 100/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 2.8796 - SMAPE: 5.3122 - val_loss: 3.0441 - val_SMAPE: 8.6301\n",
      "Epoch 101/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 2.8288 - SMAPE: 5.2048 - val_loss: 2.9406 - val_SMAPE: 8.3081\n",
      "Epoch 102/200\n",
      "58/58 [==============================] - 4s 78ms/step - loss: 2.7891 - SMAPE: 5.1554 - val_loss: 2.9217 - val_SMAPE: 8.3465\n",
      "Epoch 103/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 2.7175 - SMAPE: 5.0198 - val_loss: 2.8952 - val_SMAPE: 8.2841\n",
      "Epoch 104/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 2.6806 - SMAPE: 4.9530 - val_loss: 2.8643 - val_SMAPE: 8.1640\n",
      "Epoch 105/200\n",
      "58/58 [==============================] - 4s 75ms/step - loss: 2.6636 - SMAPE: 5.0688 - val_loss: 2.9539 - val_SMAPE: 8.4665\n",
      "Epoch 106/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 2.7616 - SMAPE: 5.3475 - val_loss: 3.0514 - val_SMAPE: 8.7620\n",
      "Epoch 107/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 2.6299 - SMAPE: 4.9357 - val_loss: 2.9825 - val_SMAPE: 8.5837\n",
      "Epoch 108/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 2.5839 - SMAPE: 4.8087 - val_loss: 2.7549 - val_SMAPE: 7.9767\n",
      "Epoch 109/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 2.5452 - SMAPE: 4.7381 - val_loss: 2.8374 - val_SMAPE: 8.1654\n",
      "Epoch 110/200\n",
      "58/58 [==============================] - 4s 75ms/step - loss: 2.5045 - SMAPE: 4.6420 - val_loss: 2.7992 - val_SMAPE: 8.0440\n",
      "Epoch 111/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 2.4495 - SMAPE: 4.6111 - val_loss: 2.7873 - val_SMAPE: 7.9754\n",
      "Epoch 112/200\n",
      "58/58 [==============================] - 4s 75ms/step - loss: 2.4289 - SMAPE: 4.5417 - val_loss: 2.8674 - val_SMAPE: 8.1427\n",
      "Epoch 113/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 2.4406 - SMAPE: 4.5576 - val_loss: 3.1057 - val_SMAPE: 8.7878\n",
      "Epoch 114/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 2.5459 - SMAPE: 4.7475 - val_loss: 2.7124 - val_SMAPE: 7.7919\n",
      "Epoch 115/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 2.3662 - SMAPE: 4.3866 - val_loss: 2.7536 - val_SMAPE: 7.9108\n",
      "Epoch 116/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 2.3908 - SMAPE: 4.4852 - val_loss: 2.7358 - val_SMAPE: 7.8422\n",
      "Epoch 117/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 2.3461 - SMAPE: 4.4465 - val_loss: 2.7952 - val_SMAPE: 8.0579\n",
      "Epoch 118/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 4s 77ms/step - loss: 2.3957 - SMAPE: 4.6019 - val_loss: 2.7558 - val_SMAPE: 7.9147\n",
      "Epoch 119/200\n",
      "58/58 [==============================] - 5s 92ms/step - loss: 2.3428 - SMAPE: 4.3575 - val_loss: 2.6914 - val_SMAPE: 7.7394\n",
      "Epoch 120/200\n",
      "58/58 [==============================] - 4s 71ms/step - loss: 2.2549 - SMAPE: 4.1969 - val_loss: 2.6886 - val_SMAPE: 7.7378\n",
      "Epoch 121/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 2.2441 - SMAPE: 4.1861 - val_loss: 2.6769 - val_SMAPE: 7.6537\n",
      "Epoch 122/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 2.2970 - SMAPE: 4.3037 - val_loss: 2.6693 - val_SMAPE: 7.7604\n",
      "Epoch 123/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 2.2204 - SMAPE: 4.1595 - val_loss: 2.6874 - val_SMAPE: 7.7110\n",
      "Epoch 124/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 2.1925 - SMAPE: 4.0821 - val_loss: 3.0693 - val_SMAPE: 8.5627\n",
      "Epoch 125/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 2.2998 - SMAPE: 4.2851 - val_loss: 2.5708 - val_SMAPE: 7.4673\n",
      "Epoch 126/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 2.1900 - SMAPE: 4.1182 - val_loss: 2.8530 - val_SMAPE: 8.0932\n",
      "Epoch 127/200\n",
      "58/58 [==============================] - 4s 70ms/step - loss: 2.4049 - SMAPE: 4.4322 - val_loss: 2.7087 - val_SMAPE: 7.7713\n",
      "Epoch 128/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 2.1744 - SMAPE: 4.0641 - val_loss: 2.5871 - val_SMAPE: 7.4943\n",
      "Epoch 129/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 2.1377 - SMAPE: 4.0615 - val_loss: 2.5530 - val_SMAPE: 7.4487\n",
      "Epoch 130/200\n",
      "58/58 [==============================] - 4s 76ms/step - loss: 2.1117 - SMAPE: 3.9635 - val_loss: 2.6494 - val_SMAPE: 7.5908\n",
      "Epoch 131/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 2.0883 - SMAPE: 3.8915 - val_loss: 2.6704 - val_SMAPE: 7.7268\n",
      "Epoch 132/200\n",
      "58/58 [==============================] - 4s 71ms/step - loss: 2.1066 - SMAPE: 3.9063 - val_loss: 2.5887 - val_SMAPE: 7.5373\n",
      "Epoch 133/200\n",
      "58/58 [==============================] - 4s 75ms/step - loss: 2.1237 - SMAPE: 3.9650 - val_loss: 2.5755 - val_SMAPE: 7.4727\n",
      "Epoch 134/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 2.0725 - SMAPE: 3.8715 - val_loss: 2.5754 - val_SMAPE: 7.4812\n",
      "Epoch 135/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 2.0753 - SMAPE: 3.8895 - val_loss: 2.5607 - val_SMAPE: 7.4453\n",
      "Epoch 136/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 2.0739 - SMAPE: 3.8907 - val_loss: 2.6808 - val_SMAPE: 7.6922\n",
      "Epoch 137/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 2.0939 - SMAPE: 3.9199 - val_loss: 2.5161 - val_SMAPE: 7.3138\n",
      "Epoch 138/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 2.0301 - SMAPE: 3.7731 - val_loss: 2.6631 - val_SMAPE: 7.6517\n",
      "Epoch 139/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 2.0476 - SMAPE: 3.8740 - val_loss: 2.6746 - val_SMAPE: 7.6330\n",
      "Epoch 140/200\n",
      "58/58 [==============================] - 4s 71ms/step - loss: 2.0945 - SMAPE: 3.8983 - val_loss: 2.5461 - val_SMAPE: 7.3533\n",
      "Epoch 141/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 2.0906 - SMAPE: 3.8785 - val_loss: 2.5193 - val_SMAPE: 7.3164\n",
      "Epoch 142/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 1.9993 - SMAPE: 3.7351 - val_loss: 2.5094 - val_SMAPE: 7.2708\n",
      "Epoch 143/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 2.0229 - SMAPE: 3.7881 - val_loss: 2.5439 - val_SMAPE: 7.3748\n",
      "Epoch 144/200\n",
      "58/58 [==============================] - 4s 70ms/step - loss: 1.9853 - SMAPE: 3.6996 - val_loss: 2.5831 - val_SMAPE: 7.5121\n",
      "Epoch 145/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 2.0237 - SMAPE: 3.8084 - val_loss: 2.7287 - val_SMAPE: 7.8408\n",
      "Epoch 146/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 1.9589 - SMAPE: 3.6426 - val_loss: 2.6561 - val_SMAPE: 7.6446\n",
      "Epoch 147/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 1.9779 - SMAPE: 3.6857 - val_loss: 2.5641 - val_SMAPE: 7.4131\n",
      "Epoch 148/200\n",
      "58/58 [==============================] - 4s 71ms/step - loss: 1.9583 - SMAPE: 3.6585 - val_loss: 2.6198 - val_SMAPE: 7.5707\n",
      "Epoch 149/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 1.9398 - SMAPE: 3.6597 - val_loss: 2.5317 - val_SMAPE: 7.3173\n",
      "Epoch 150/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 1.9344 - SMAPE: 3.5998 - val_loss: 2.4796 - val_SMAPE: 7.2040\n",
      "Epoch 151/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 1.8965 - SMAPE: 3.5281 - val_loss: 2.5398 - val_SMAPE: 7.3187\n",
      "Epoch 152/200\n",
      "58/58 [==============================] - 4s 71ms/step - loss: 1.8876 - SMAPE: 3.5015 - val_loss: 2.5687 - val_SMAPE: 7.4374\n",
      "Epoch 153/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 1.9189 - SMAPE: 3.5750 - val_loss: 2.4966 - val_SMAPE: 7.2176\n",
      "Epoch 154/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 1.8996 - SMAPE: 3.5131 - val_loss: 2.4643 - val_SMAPE: 7.1589\n",
      "Epoch 155/200\n",
      "58/58 [==============================] - 4s 70ms/step - loss: 1.8809 - SMAPE: 3.5032 - val_loss: 2.5954 - val_SMAPE: 7.5510\n",
      "Epoch 156/200\n",
      "58/58 [==============================] - 4s 71ms/step - loss: 1.8995 - SMAPE: 3.5285 - val_loss: 2.5277 - val_SMAPE: 7.2804\n",
      "Epoch 157/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 1.9041 - SMAPE: 3.5632 - val_loss: 2.6352 - val_SMAPE: 7.5942\n",
      "Epoch 158/200\n",
      "58/58 [==============================] - 4s 71ms/step - loss: 1.8573 - SMAPE: 3.4807 - val_loss: 2.4906 - val_SMAPE: 7.2573\n",
      "Epoch 159/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 1.8889 - SMAPE: 3.5318 - val_loss: 2.5496 - val_SMAPE: 7.3343\n",
      "Epoch 160/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 1.8659 - SMAPE: 3.4947 - val_loss: 2.5666 - val_SMAPE: 7.4773\n",
      "Epoch 161/200\n",
      "58/58 [==============================] - 4s 71ms/step - loss: 1.8614 - SMAPE: 3.5256 - val_loss: 2.4671 - val_SMAPE: 7.1974\n",
      "Epoch 162/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 1.8319 - SMAPE: 3.4076 - val_loss: 2.4957 - val_SMAPE: 7.2283\n",
      "Epoch 163/200\n",
      "58/58 [==============================] - 4s 71ms/step - loss: 1.8166 - SMAPE: 3.3735 - val_loss: 2.4936 - val_SMAPE: 7.2744\n",
      "Epoch 164/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 1.7989 - SMAPE: 3.3409 - val_loss: 2.4839 - val_SMAPE: 7.2089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/nn4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/nn4\\assets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>SMAPE_train</th>\n",
       "      <th>SMAPE_val</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NEMO</th>\n",
       "      <td>None</td>\n",
       "      <td>16.03</td>\n",
       "      <td>16.922</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>3.021</td>\n",
       "      <td>5.869</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso1</th>\n",
       "      <td>{'num_features': 5}</td>\n",
       "      <td>3.367</td>\n",
       "      <td>5.056</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso2</th>\n",
       "      <td>{'price_day_ahead': False}</td>\n",
       "      <td>11.811</td>\n",
       "      <td>32.664</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>1.248</td>\n",
       "      <td>6.668</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost1</th>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>2.465</td>\n",
       "      <td>5.85</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost2</th>\n",
       "      <td>{'max_depth': 2, 'price_day_ahead': False}</td>\n",
       "      <td>4.331</td>\n",
       "      <td>27.241</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost3</th>\n",
       "      <td>{'max_depth': 16, 'price_day_ahead': False}</td>\n",
       "      <td>0.026</td>\n",
       "      <td>24.84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn1</th>\n",
       "      <td>1-to-1</td>\n",
       "      <td>3.332</td>\n",
       "      <td>3.88</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn2</th>\n",
       "      <td>1-to-1, price_day_ahead:False</td>\n",
       "      <td>7.139</td>\n",
       "      <td>21.382</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn3</th>\n",
       "      <td>24-to-24</td>\n",
       "      <td>4.096</td>\n",
       "      <td>4.301</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn4</th>\n",
       "      <td>LSTM, 7-day input</td>\n",
       "      <td>3.439</td>\n",
       "      <td>7.123</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Parameters SMAPE_train SMAPE_val  \\\n",
       "NEMO                                             None       16.03    16.922   \n",
       "Lasso                                         Vanilla       3.021     5.869   \n",
       "Lasso1                            {'num_features': 5}       3.367     5.056   \n",
       "Lasso2                     {'price_day_ahead': False}      11.811    32.664   \n",
       "XGBoost                                       Vanilla       1.248     6.668   \n",
       "XGBoost1                             {'max_depth': 2}       2.465      5.85   \n",
       "XGBoost2   {'max_depth': 2, 'price_day_ahead': False}       4.331    27.241   \n",
       "XGBoost3  {'max_depth': 16, 'price_day_ahead': False}       0.026     24.84   \n",
       "nn1                                            1-to-1       3.332      3.88   \n",
       "nn2                     1-to-1, price_day_ahead:False       7.139    21.382   \n",
       "nn3                                          24-to-24       4.096     4.301   \n",
       "nn4                                 LSTM, 7-day input       3.439     7.123   \n",
       "\n",
       "         r2_train r2_val  \n",
       "NEMO        0.954  0.971  \n",
       "Lasso       0.977  0.973  \n",
       "Lasso1      0.971  0.969  \n",
       "Lasso2      0.676  0.557  \n",
       "XGBoost     0.996  0.968  \n",
       "XGBoost1    0.984   0.97  \n",
       "XGBoost2    0.953  0.427  \n",
       "XGBoost3      1.0  0.403  \n",
       "nn1         0.985  0.979  \n",
       "nn2         0.906  0.467  \n",
       "nn3         0.976  0.974  \n",
       "nn4         0.964  0.917  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into train and validation\n",
    "X_train, y_train, X_val, y_val = split_data(df_nn, 2020, 'price_actual')\n",
    "\n",
    "# Reorganize the training and testing data into batches\n",
    "X_train, y_train = resample((X_train, y_train), 24*7, 24, 24)\n",
    "X_val, y_val = resample((X_val,y_val), 24*7, 24, 24)\n",
    "\n",
    "# Input Shape\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "# Instantiate model and build layers\n",
    "nn = models.Sequential()\n",
    "nn.add(layers.LSTM(60, activation='tanh', input_shape=input_shape))\n",
    "nn.add(layers.RepeatVector(y_train.shape[1]))\n",
    "nn.add(layers.LSTM(24, activation='tanh', return_sequences=True))\n",
    "nn.add(TimeDistributed(layers.Dense(1)))\n",
    "\n",
    "# Compile Fit\n",
    "nn4 = compile_fit(nn, (X_train, y_train), (X_val, y_val))\n",
    "\n",
    "# Compute metrics, add to table\n",
    "results_actual['nn4'] = compute_metrics(nn4, 'LSTM, 7-day input', (X_train,y_train), (X_val,y_val))\n",
    "\n",
    "# Save Model\n",
    "nn4.save('../models/nn4')\n",
    "\n",
    "# Preview\n",
    "results_actual.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the model trained and did not overfit, it did not outpeform the previous models.  Just once, I'll try to the number of nodes in the first LSTM layer to see if that makes a difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "58/58 [==============================] - 27s 435ms/step - loss: 53.4645 - SMAPE: 176.4326 - val_loss: 33.3156 - val_SMAPE: 144.7479\n",
      "Epoch 2/200\n",
      "58/58 [==============================] - 6s 98ms/step - loss: 49.7252 - SMAPE: 153.0373 - val_loss: 30.9851 - val_SMAPE: 126.9423\n",
      "Epoch 3/200\n",
      "58/58 [==============================] - 5s 95ms/step - loss: 47.8595 - SMAPE: 142.7270 - val_loss: 29.3483 - val_SMAPE: 115.6185\n",
      "Epoch 4/200\n",
      "58/58 [==============================] - 6s 101ms/step - loss: 46.2662 - SMAPE: 134.0719 - val_loss: 27.7996 - val_SMAPE: 105.6752\n",
      "Epoch 5/200\n",
      "58/58 [==============================] - 6s 97ms/step - loss: 44.7291 - SMAPE: 126.0627 - val_loss: 26.2943 - val_SMAPE: 96.6412\n",
      "Epoch 6/200\n",
      "58/58 [==============================] - 6s 98ms/step - loss: 43.2262 - SMAPE: 119.1933 - val_loss: 24.8276 - val_SMAPE: 88.3856\n",
      "Epoch 7/200\n",
      "58/58 [==============================] - 5s 95ms/step - loss: 41.7509 - SMAPE: 112.5439 - val_loss: 23.3934 - val_SMAPE: 80.7895\n",
      "Epoch 8/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 40.2962 - SMAPE: 105.9723 - val_loss: 21.9950 - val_SMAPE: 73.7998\n",
      "Epoch 9/200\n",
      "58/58 [==============================] - 6s 95ms/step - loss: 38.8608 - SMAPE: 100.3260 - val_loss: 20.6293 - val_SMAPE: 67.3372\n",
      "Epoch 10/200\n",
      "58/58 [==============================] - 6s 95ms/step - loss: 37.4435 - SMAPE: 94.9257 - val_loss: 19.3027 - val_SMAPE: 61.3855\n",
      "Epoch 11/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 36.0437 - SMAPE: 88.9957 - val_loss: 18.0223 - val_SMAPE: 55.9327\n",
      "Epoch 12/200\n",
      "58/58 [==============================] - 12s 204ms/step - loss: 34.6588 - SMAPE: 83.4921 - val_loss: 16.7883 - val_SMAPE: 50.9343\n",
      "Epoch 13/200\n",
      "58/58 [==============================] - 17s 287ms/step - loss: 33.2877 - SMAPE: 79.2685 - val_loss: 15.6116 - val_SMAPE: 46.3847\n",
      "Epoch 14/200\n",
      "58/58 [==============================] - 7s 114ms/step - loss: 31.9288 - SMAPE: 74.6173 - val_loss: 14.5055 - val_SMAPE: 42.2962\n",
      "Epoch 15/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 30.5859 - SMAPE: 70.2378 - val_loss: 13.4642 - val_SMAPE: 38.6103\n",
      "Epoch 16/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 29.2590 - SMAPE: 66.2583 - val_loss: 12.5051 - val_SMAPE: 35.3435\n",
      "Epoch 17/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 27.9549 - SMAPE: 62.2642 - val_loss: 11.6470 - val_SMAPE: 32.5243\n",
      "Epoch 18/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 26.6714 - SMAPE: 57.8585 - val_loss: 10.9107 - val_SMAPE: 30.1801\n",
      "Epoch 19/200\n",
      "58/58 [==============================] - 5s 95ms/step - loss: 25.4131 - SMAPE: 54.4787 - val_loss: 10.2997 - val_SMAPE: 28.2854\n",
      "Epoch 20/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 24.1789 - SMAPE: 51.4361 - val_loss: 9.8271 - val_SMAPE: 26.8440\n",
      "Epoch 21/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 22.9768 - SMAPE: 47.4921 - val_loss: 9.4754 - val_SMAPE: 25.7738\n",
      "Epoch 22/200\n",
      "58/58 [==============================] - 5s 95ms/step - loss: 21.8163 - SMAPE: 45.5367 - val_loss: 9.2433 - val_SMAPE: 25.0517\n",
      "Epoch 23/200\n",
      "58/58 [==============================] - 5s 95ms/step - loss: 20.6841 - SMAPE: 42.1893 - val_loss: 8.4355 - val_SMAPE: 22.9379\n",
      "Epoch 24/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 19.4290 - SMAPE: 38.7949 - val_loss: 6.9958 - val_SMAPE: 19.3122\n",
      "Epoch 25/200\n",
      "58/58 [==============================] - 5s 92ms/step - loss: 18.2586 - SMAPE: 35.5087 - val_loss: 6.4173 - val_SMAPE: 17.2143\n",
      "Epoch 26/200\n",
      "58/58 [==============================] - 5s 95ms/step - loss: 17.1635 - SMAPE: 33.2128 - val_loss: 6.4816 - val_SMAPE: 17.4286\n",
      "Epoch 27/200\n",
      "58/58 [==============================] - 6s 98ms/step - loss: 16.1454 - SMAPE: 30.9147 - val_loss: 6.2679 - val_SMAPE: 16.9834\n",
      "Epoch 28/200\n",
      "58/58 [==============================] - 5s 95ms/step - loss: 15.1870 - SMAPE: 29.0770 - val_loss: 6.0247 - val_SMAPE: 16.1647\n",
      "Epoch 29/200\n",
      "58/58 [==============================] - 5s 95ms/step - loss: 14.4099 - SMAPE: 26.8844 - val_loss: 7.0211 - val_SMAPE: 19.0292\n",
      "Epoch 30/200\n",
      "58/58 [==============================] - 5s 95ms/step - loss: 13.5521 - SMAPE: 25.0974 - val_loss: 6.1570 - val_SMAPE: 16.6439\n",
      "Epoch 31/200\n",
      "58/58 [==============================] - 6s 95ms/step - loss: 12.8272 - SMAPE: 23.6957 - val_loss: 8.8407 - val_SMAPE: 22.7613\n",
      "Epoch 32/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 12.3967 - SMAPE: 22.9397 - val_loss: 7.8864 - val_SMAPE: 20.0581\n",
      "Epoch 33/200\n",
      "58/58 [==============================] - 6s 98ms/step - loss: 11.6787 - SMAPE: 21.3233 - val_loss: 6.9795 - val_SMAPE: 18.3206\n",
      "Epoch 34/200\n",
      "58/58 [==============================] - 6s 98ms/step - loss: 11.0874 - SMAPE: 20.2552 - val_loss: 8.1142 - val_SMAPE: 20.4495\n",
      "Epoch 35/200\n",
      "58/58 [==============================] - 6s 103ms/step - loss: 10.6351 - SMAPE: 19.6947 - val_loss: 8.3184 - val_SMAPE: 21.1937\n",
      "Epoch 36/200\n",
      "58/58 [==============================] - 6s 101ms/step - loss: 10.3597 - SMAPE: 18.9125 - val_loss: 8.1758 - val_SMAPE: 20.6208\n",
      "Epoch 37/200\n",
      "58/58 [==============================] - 6s 100ms/step - loss: 9.9099 - SMAPE: 18.0523 - val_loss: 5.6970 - val_SMAPE: 15.4402\n",
      "Epoch 38/200\n",
      "58/58 [==============================] - 6s 100ms/step - loss: 9.4097 - SMAPE: 16.9506 - val_loss: 5.5902 - val_SMAPE: 15.0968\n",
      "Epoch 39/200\n",
      "58/58 [==============================] - 6s 95ms/step - loss: 9.3168 - SMAPE: 16.8479 - val_loss: 5.3188 - val_SMAPE: 14.1260\n",
      "Epoch 40/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 8.9161 - SMAPE: 16.0727 - val_loss: 5.5985 - val_SMAPE: 15.0409\n",
      "Epoch 41/200\n",
      "58/58 [==============================] - 5s 91ms/step - loss: 8.6756 - SMAPE: 15.4971 - val_loss: 5.7553 - val_SMAPE: 15.6546\n",
      "Epoch 42/200\n",
      "58/58 [==============================] - 5s 92ms/step - loss: 8.4784 - SMAPE: 15.3155 - val_loss: 5.3225 - val_SMAPE: 14.4307\n",
      "Epoch 43/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 8.1539 - SMAPE: 14.9987 - val_loss: 5.2682 - val_SMAPE: 14.2577\n",
      "Epoch 44/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 7.9107 - SMAPE: 14.2671 - val_loss: 4.8481 - val_SMAPE: 13.1478\n",
      "Epoch 45/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 7.6376 - SMAPE: 13.6602 - val_loss: 5.0720 - val_SMAPE: 13.8544\n",
      "Epoch 46/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 7.4220 - SMAPE: 13.3709 - val_loss: 4.6678 - val_SMAPE: 12.7213\n",
      "Epoch 47/200\n",
      "58/58 [==============================] - 5s 92ms/step - loss: 7.4787 - SMAPE: 13.3896 - val_loss: 5.1202 - val_SMAPE: 14.0025\n",
      "Epoch 48/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 7.1335 - SMAPE: 12.9313 - val_loss: 4.5196 - val_SMAPE: 12.5284\n",
      "Epoch 49/200\n",
      "58/58 [==============================] - 5s 95ms/step - loss: 6.8927 - SMAPE: 12.4163 - val_loss: 5.1219 - val_SMAPE: 14.2096\n",
      "Epoch 50/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 6.6929 - SMAPE: 12.1309 - val_loss: 4.4149 - val_SMAPE: 12.3219\n",
      "Epoch 51/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 6.4849 - SMAPE: 11.6345 - val_loss: 4.2988 - val_SMAPE: 11.9317\n",
      "Epoch 52/200\n",
      "58/58 [==============================] - 5s 95ms/step - loss: 6.3017 - SMAPE: 11.3513 - val_loss: 4.2649 - val_SMAPE: 11.8413\n",
      "Epoch 53/200\n",
      "58/58 [==============================] - 5s 93ms/step - loss: 6.1840 - SMAPE: 11.0461 - val_loss: 4.5888 - val_SMAPE: 12.7290\n",
      "Epoch 54/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 5.9562 - SMAPE: 10.7564 - val_loss: 5.3112 - val_SMAPE: 14.5085\n",
      "Epoch 55/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 5.7902 - SMAPE: 10.5329 - val_loss: 4.1521 - val_SMAPE: 11.5358\n",
      "Epoch 56/200\n",
      "58/58 [==============================] - 5s 95ms/step - loss: 5.6207 - SMAPE: 10.6229 - val_loss: 4.7315 - val_SMAPE: 13.1238\n",
      "Epoch 57/200\n",
      "58/58 [==============================] - 6s 95ms/step - loss: 5.4669 - SMAPE: 9.8397 - val_loss: 4.3292 - val_SMAPE: 11.9940\n",
      "Epoch 58/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 5.3421 - SMAPE: 9.6903 - val_loss: 4.1414 - val_SMAPE: 11.5891\n",
      "Epoch 59/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 5.1417 - SMAPE: 9.3075 - val_loss: 3.9258 - val_SMAPE: 10.9430\n",
      "Epoch 60/200\n",
      "58/58 [==============================] - 6s 95ms/step - loss: 5.0091 - SMAPE: 9.1038 - val_loss: 4.0006 - val_SMAPE: 11.1651\n",
      "Epoch 61/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 5.0164 - SMAPE: 9.1456 - val_loss: 4.2807 - val_SMAPE: 11.8541\n",
      "Epoch 62/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 4.8754 - SMAPE: 8.9481 - val_loss: 4.1226 - val_SMAPE: 11.4420\n",
      "Epoch 63/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 4.6844 - SMAPE: 8.6570 - val_loss: 3.9196 - val_SMAPE: 10.9704\n",
      "Epoch 64/200\n",
      "58/58 [==============================] - 5s 92ms/step - loss: 4.6029 - SMAPE: 8.4669 - val_loss: 3.8992 - val_SMAPE: 10.8823\n",
      "Epoch 65/200\n",
      "58/58 [==============================] - 5s 95ms/step - loss: 4.5320 - SMAPE: 8.3685 - val_loss: 4.0844 - val_SMAPE: 11.3018\n",
      "Epoch 66/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 4.4069 - SMAPE: 8.1196 - val_loss: 3.8362 - val_SMAPE: 10.6839\n",
      "Epoch 67/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 4.3706 - SMAPE: 8.0268 - val_loss: 3.8882 - val_SMAPE: 10.8556\n",
      "Epoch 68/200\n",
      "58/58 [==============================] - 5s 95ms/step - loss: 4.2526 - SMAPE: 7.8553 - val_loss: 3.7742 - val_SMAPE: 10.5229\n",
      "Epoch 69/200\n",
      "58/58 [==============================] - 5s 92ms/step - loss: 4.1936 - SMAPE: 7.7849 - val_loss: 3.7914 - val_SMAPE: 10.5575\n",
      "Epoch 70/200\n",
      "58/58 [==============================] - 6s 95ms/step - loss: 4.1094 - SMAPE: 7.5326 - val_loss: 3.8160 - val_SMAPE: 10.6598\n",
      "Epoch 71/200\n",
      "58/58 [==============================] - 6s 95ms/step - loss: 4.0776 - SMAPE: 7.5302 - val_loss: 3.6739 - val_SMAPE: 10.2951\n",
      "Epoch 72/200\n",
      "58/58 [==============================] - 5s 95ms/step - loss: 4.0259 - SMAPE: 7.3833 - val_loss: 3.9052 - val_SMAPE: 10.8446\n",
      "Epoch 73/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 3.9622 - SMAPE: 7.3640 - val_loss: 3.8800 - val_SMAPE: 10.8818\n",
      "Epoch 74/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 3.8849 - SMAPE: 7.1483 - val_loss: 3.7410 - val_SMAPE: 10.4280\n",
      "Epoch 75/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 3.8051 - SMAPE: 6.9781 - val_loss: 3.6308 - val_SMAPE: 10.1815\n",
      "Epoch 76/200\n",
      "58/58 [==============================] - 5s 95ms/step - loss: 3.7444 - SMAPE: 6.8892 - val_loss: 3.6317 - val_SMAPE: 10.1615\n",
      "Epoch 77/200\n",
      "58/58 [==============================] - 5s 95ms/step - loss: 3.9890 - SMAPE: 7.3806 - val_loss: 3.9867 - val_SMAPE: 11.0201\n",
      "Epoch 78/200\n",
      "58/58 [==============================] - 5s 95ms/step - loss: 3.7740 - SMAPE: 6.9704 - val_loss: 3.6379 - val_SMAPE: 10.2350\n",
      "Epoch 79/200\n",
      "58/58 [==============================] - 5s 95ms/step - loss: 3.6894 - SMAPE: 6.8071 - val_loss: 3.8769 - val_SMAPE: 10.7370\n",
      "Epoch 80/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 3.6633 - SMAPE: 6.7716 - val_loss: 3.4718 - val_SMAPE: 9.7120\n",
      "Epoch 81/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 3.6583 - SMAPE: 6.7391 - val_loss: 3.5731 - val_SMAPE: 10.0798\n",
      "Epoch 82/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 3.5532 - SMAPE: 6.6038 - val_loss: 3.5399 - val_SMAPE: 9.9534\n",
      "Epoch 83/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 3.5035 - SMAPE: 6.4457 - val_loss: 3.6060 - val_SMAPE: 9.9796\n",
      "Epoch 84/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 3.4762 - SMAPE: 6.4331 - val_loss: 3.4305 - val_SMAPE: 9.6318\n",
      "Epoch 85/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 3.4231 - SMAPE: 6.3112 - val_loss: 3.5827 - val_SMAPE: 9.9295\n",
      "Epoch 86/200\n",
      "58/58 [==============================] - 5s 93ms/step - loss: 3.4492 - SMAPE: 6.3881 - val_loss: 3.4761 - val_SMAPE: 9.8462\n",
      "Epoch 87/200\n",
      "58/58 [==============================] - 5s 95ms/step - loss: 3.5533 - SMAPE: 6.5281 - val_loss: 3.5633 - val_SMAPE: 9.9852\n",
      "Epoch 88/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 3.3435 - SMAPE: 6.1565 - val_loss: 3.7100 - val_SMAPE: 10.2625\n",
      "Epoch 89/200\n",
      "58/58 [==============================] - 5s 95ms/step - loss: 3.3121 - SMAPE: 6.1298 - val_loss: 3.4334 - val_SMAPE: 9.5776\n",
      "Epoch 90/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 3.3105 - SMAPE: 6.1649 - val_loss: 3.4377 - val_SMAPE: 9.6740\n",
      "Epoch 91/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 3.2247 - SMAPE: 5.9504 - val_loss: 3.3737 - val_SMAPE: 9.4517\n",
      "Epoch 92/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 3.2040 - SMAPE: 5.9181 - val_loss: 3.2971 - val_SMAPE: 9.2772\n",
      "Epoch 93/200\n",
      "58/58 [==============================] - 6s 97ms/step - loss: 3.1895 - SMAPE: 5.8863 - val_loss: 3.3224 - val_SMAPE: 9.4107\n",
      "Epoch 94/200\n",
      "58/58 [==============================] - 5s 95ms/step - loss: 3.1736 - SMAPE: 5.9342 - val_loss: 3.4687 - val_SMAPE: 9.6546\n",
      "Epoch 95/200\n",
      "58/58 [==============================] - 5s 95ms/step - loss: 3.2454 - SMAPE: 6.0405 - val_loss: 3.3612 - val_SMAPE: 9.4256\n",
      "Epoch 96/200\n",
      "58/58 [==============================] - 5s 95ms/step - loss: 3.1285 - SMAPE: 5.8191 - val_loss: 3.5574 - val_SMAPE: 9.9523\n",
      "Epoch 97/200\n",
      "58/58 [==============================] - 5s 93ms/step - loss: 3.2064 - SMAPE: 5.9607 - val_loss: 3.3777 - val_SMAPE: 9.4279\n",
      "Epoch 98/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 3.0471 - SMAPE: 5.6047 - val_loss: 3.2917 - val_SMAPE: 9.3224\n",
      "Epoch 99/200\n",
      "58/58 [==============================] - 6s 95ms/step - loss: 3.1316 - SMAPE: 5.8144 - val_loss: 3.4816 - val_SMAPE: 9.9458\n",
      "Epoch 100/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 3.0970 - SMAPE: 5.7442 - val_loss: 3.4998 - val_SMAPE: 9.7782\n",
      "Epoch 101/200\n",
      "58/58 [==============================] - 6s 99ms/step - loss: 3.0278 - SMAPE: 5.6120 - val_loss: 3.1689 - val_SMAPE: 8.9432\n",
      "Epoch 102/200\n",
      "58/58 [==============================] - 6s 99ms/step - loss: 2.9350 - SMAPE: 5.4453 - val_loss: 3.1586 - val_SMAPE: 8.9322\n",
      "Epoch 103/200\n",
      "58/58 [==============================] - 6s 102ms/step - loss: 2.8908 - SMAPE: 5.3633 - val_loss: 3.1689 - val_SMAPE: 8.9428\n",
      "Epoch 104/200\n",
      "58/58 [==============================] - 6s 101ms/step - loss: 2.9117 - SMAPE: 5.4303 - val_loss: 3.2211 - val_SMAPE: 9.1798\n",
      "Epoch 105/200\n",
      "58/58 [==============================] - 6s 103ms/step - loss: 2.8289 - SMAPE: 5.2419 - val_loss: 3.2820 - val_SMAPE: 9.2354\n",
      "Epoch 106/200\n",
      "58/58 [==============================] - 6s 100ms/step - loss: 2.8413 - SMAPE: 5.2887 - val_loss: 3.0895 - val_SMAPE: 8.7507\n",
      "Epoch 107/200\n",
      "58/58 [==============================] - 6s 97ms/step - loss: 2.8284 - SMAPE: 5.2719 - val_loss: 3.1126 - val_SMAPE: 8.9019\n",
      "Epoch 108/200\n",
      "58/58 [==============================] - 5s 95ms/step - loss: 2.7938 - SMAPE: 5.2012 - val_loss: 3.3556 - val_SMAPE: 9.4149\n",
      "Epoch 109/200\n",
      "58/58 [==============================] - 5s 93ms/step - loss: 2.8107 - SMAPE: 5.1803 - val_loss: 3.1847 - val_SMAPE: 9.0309\n",
      "Epoch 110/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 2.7073 - SMAPE: 5.0144 - val_loss: 3.0849 - val_SMAPE: 8.7988\n",
      "Epoch 111/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 2.8353 - SMAPE: 5.2621 - val_loss: 3.1091 - val_SMAPE: 8.9381\n",
      "Epoch 112/200\n",
      "58/58 [==============================] - 5s 93ms/step - loss: 2.6727 - SMAPE: 4.9849 - val_loss: 3.1251 - val_SMAPE: 8.8996\n",
      "Epoch 113/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 2.7075 - SMAPE: 5.0580 - val_loss: 3.1376 - val_SMAPE: 9.0488\n",
      "Epoch 114/200\n",
      "58/58 [==============================] - 6s 95ms/step - loss: 2.6530 - SMAPE: 4.9246 - val_loss: 3.0205 - val_SMAPE: 8.6458\n",
      "Epoch 115/200\n",
      "58/58 [==============================] - 6s 95ms/step - loss: 2.6630 - SMAPE: 4.9660 - val_loss: 3.0372 - val_SMAPE: 8.6352\n",
      "Epoch 116/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 2.6209 - SMAPE: 4.8838 - val_loss: 3.1062 - val_SMAPE: 8.9336\n",
      "Epoch 117/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 2.5945 - SMAPE: 4.8411 - val_loss: 3.0278 - val_SMAPE: 8.6208\n",
      "Epoch 118/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 5s 94ms/step - loss: 2.6903 - SMAPE: 5.0118 - val_loss: 3.0098 - val_SMAPE: 8.5771\n",
      "Epoch 119/200\n",
      "58/58 [==============================] - 5s 93ms/step - loss: 2.5530 - SMAPE: 4.7390 - val_loss: 3.0157 - val_SMAPE: 8.7114\n",
      "Epoch 120/200\n",
      "58/58 [==============================] - 5s 95ms/step - loss: 2.5215 - SMAPE: 4.6922 - val_loss: 2.9171 - val_SMAPE: 8.3552\n",
      "Epoch 121/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 2.6017 - SMAPE: 4.8102 - val_loss: 3.2080 - val_SMAPE: 9.0817\n",
      "Epoch 122/200\n",
      "58/58 [==============================] - 6s 95ms/step - loss: 2.5625 - SMAPE: 4.8293 - val_loss: 3.2714 - val_SMAPE: 9.1671\n",
      "Epoch 123/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 2.4673 - SMAPE: 4.5920 - val_loss: 2.8628 - val_SMAPE: 8.2607\n",
      "Epoch 124/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 2.4269 - SMAPE: 4.5560 - val_loss: 3.2205 - val_SMAPE: 9.1082\n",
      "Epoch 125/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 2.4124 - SMAPE: 4.5237 - val_loss: 2.9534 - val_SMAPE: 8.4414\n",
      "Epoch 126/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 2.3980 - SMAPE: 4.4993 - val_loss: 3.3218 - val_SMAPE: 9.3232\n",
      "Epoch 127/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 2.4768 - SMAPE: 4.6105 - val_loss: 2.8273 - val_SMAPE: 8.2341\n",
      "Epoch 128/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 2.3413 - SMAPE: 4.3358 - val_loss: 3.0803 - val_SMAPE: 8.6990\n",
      "Epoch 129/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 2.3360 - SMAPE: 4.3385 - val_loss: 2.8004 - val_SMAPE: 8.0875\n",
      "Epoch 130/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 2.2920 - SMAPE: 4.2548 - val_loss: 2.9000 - val_SMAPE: 8.2421\n",
      "Epoch 131/200\n",
      "58/58 [==============================] - 6s 99ms/step - loss: 2.3874 - SMAPE: 4.4401 - val_loss: 2.7677 - val_SMAPE: 8.0687\n",
      "Epoch 132/200\n",
      "58/58 [==============================] - 6s 99ms/step - loss: 2.2893 - SMAPE: 4.2580 - val_loss: 2.7684 - val_SMAPE: 7.9799\n",
      "Epoch 133/200\n",
      "58/58 [==============================] - 6s 102ms/step - loss: 2.2365 - SMAPE: 4.1890 - val_loss: 2.9760 - val_SMAPE: 8.4643\n",
      "Epoch 134/200\n",
      "58/58 [==============================] - 6s 95ms/step - loss: 2.3535 - SMAPE: 4.3998 - val_loss: 2.8370 - val_SMAPE: 8.2039\n",
      "Epoch 135/200\n",
      "58/58 [==============================] - 6s 95ms/step - loss: 2.2101 - SMAPE: 4.1235 - val_loss: 2.8410 - val_SMAPE: 8.1892\n",
      "Epoch 136/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 2.2329 - SMAPE: 4.1828 - val_loss: 2.7476 - val_SMAPE: 7.9326\n",
      "Epoch 137/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 2.2085 - SMAPE: 4.1100 - val_loss: 2.8143 - val_SMAPE: 8.0787\n",
      "Epoch 138/200\n",
      "58/58 [==============================] - 6s 95ms/step - loss: 2.1663 - SMAPE: 4.0414 - val_loss: 2.6917 - val_SMAPE: 7.7972\n",
      "Epoch 139/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 2.2384 - SMAPE: 4.1586 - val_loss: 2.6421 - val_SMAPE: 7.5836\n",
      "Epoch 140/200\n",
      "58/58 [==============================] - 5s 93ms/step - loss: 2.2569 - SMAPE: 4.1936 - val_loss: 2.7103 - val_SMAPE: 7.7676\n",
      "Epoch 141/200\n",
      "58/58 [==============================] - 5s 93ms/step - loss: 2.1602 - SMAPE: 4.0360 - val_loss: 2.8506 - val_SMAPE: 8.1910\n",
      "Epoch 142/200\n",
      "58/58 [==============================] - 5s 95ms/step - loss: 2.1836 - SMAPE: 4.1355 - val_loss: 2.7700 - val_SMAPE: 7.9553\n",
      "Epoch 143/200\n",
      "58/58 [==============================] - 5s 95ms/step - loss: 2.1350 - SMAPE: 4.0148 - val_loss: 2.7347 - val_SMAPE: 7.9293\n",
      "Epoch 144/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 2.1684 - SMAPE: 4.1536 - val_loss: 2.7788 - val_SMAPE: 7.9344\n",
      "Epoch 145/200\n",
      "58/58 [==============================] - 5s 95ms/step - loss: 2.3020 - SMAPE: 4.3553 - val_loss: 2.6995 - val_SMAPE: 7.9144\n",
      "Epoch 146/200\n",
      "58/58 [==============================] - 6s 95ms/step - loss: 2.1163 - SMAPE: 3.9885 - val_loss: 2.6054 - val_SMAPE: 7.4988\n",
      "Epoch 147/200\n",
      "58/58 [==============================] - 6s 97ms/step - loss: 2.0903 - SMAPE: 3.9085 - val_loss: 2.6267 - val_SMAPE: 7.5985\n",
      "Epoch 148/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 2.0206 - SMAPE: 3.7685 - val_loss: 2.7520 - val_SMAPE: 7.8313\n",
      "Epoch 149/200\n",
      "58/58 [==============================] - 6s 94ms/step - loss: 2.0547 - SMAPE: 3.8997 - val_loss: 2.7565 - val_SMAPE: 8.0053\n",
      "Epoch 150/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 2.1713 - SMAPE: 4.1031 - val_loss: 2.7272 - val_SMAPE: 7.8014\n",
      "Epoch 151/200\n",
      "58/58 [==============================] - 5s 93ms/step - loss: 2.0583 - SMAPE: 3.8271 - val_loss: 2.6727 - val_SMAPE: 7.6764\n",
      "Epoch 152/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 2.0156 - SMAPE: 3.7738 - val_loss: 2.6591 - val_SMAPE: 7.6231\n",
      "Epoch 153/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 2.0418 - SMAPE: 3.8119 - val_loss: 2.6426 - val_SMAPE: 7.6355\n",
      "Epoch 154/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 2.0445 - SMAPE: 3.9439 - val_loss: 2.9135 - val_SMAPE: 8.3402\n",
      "Epoch 155/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 2.0683 - SMAPE: 3.8826 - val_loss: 3.0911 - val_SMAPE: 8.6768\n",
      "Epoch 156/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 2.0302 - SMAPE: 3.8184 - val_loss: 2.6182 - val_SMAPE: 7.5517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/nn5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/nn5\\assets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>SMAPE_train</th>\n",
       "      <th>SMAPE_val</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NEMO</th>\n",
       "      <td>None</td>\n",
       "      <td>16.03</td>\n",
       "      <td>16.922</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>3.021</td>\n",
       "      <td>5.869</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso1</th>\n",
       "      <td>{'num_features': 5}</td>\n",
       "      <td>3.367</td>\n",
       "      <td>5.056</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso2</th>\n",
       "      <td>{'price_day_ahead': False}</td>\n",
       "      <td>11.811</td>\n",
       "      <td>32.664</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>1.248</td>\n",
       "      <td>6.668</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost1</th>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>2.465</td>\n",
       "      <td>5.85</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost2</th>\n",
       "      <td>{'max_depth': 2, 'price_day_ahead': False}</td>\n",
       "      <td>4.331</td>\n",
       "      <td>27.241</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost3</th>\n",
       "      <td>{'max_depth': 16, 'price_day_ahead': False}</td>\n",
       "      <td>0.026</td>\n",
       "      <td>24.84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn1</th>\n",
       "      <td>1-to-1</td>\n",
       "      <td>3.332</td>\n",
       "      <td>3.88</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn2</th>\n",
       "      <td>1-to-1, price_day_ahead:False</td>\n",
       "      <td>7.139</td>\n",
       "      <td>21.382</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn3</th>\n",
       "      <td>24-to-24</td>\n",
       "      <td>4.096</td>\n",
       "      <td>4.301</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn4</th>\n",
       "      <td>LSTM, 7-day input</td>\n",
       "      <td>3.439</td>\n",
       "      <td>7.123</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn5</th>\n",
       "      <td>LSTM, 7-day input</td>\n",
       "      <td>3.873</td>\n",
       "      <td>7.499</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Parameters SMAPE_train SMAPE_val  \\\n",
       "NEMO                                             None       16.03    16.922   \n",
       "Lasso                                         Vanilla       3.021     5.869   \n",
       "Lasso1                            {'num_features': 5}       3.367     5.056   \n",
       "Lasso2                     {'price_day_ahead': False}      11.811    32.664   \n",
       "XGBoost                                       Vanilla       1.248     6.668   \n",
       "XGBoost1                             {'max_depth': 2}       2.465      5.85   \n",
       "XGBoost2   {'max_depth': 2, 'price_day_ahead': False}       4.331    27.241   \n",
       "XGBoost3  {'max_depth': 16, 'price_day_ahead': False}       0.026     24.84   \n",
       "nn1                                            1-to-1       3.332      3.88   \n",
       "nn2                     1-to-1, price_day_ahead:False       7.139    21.382   \n",
       "nn3                                          24-to-24       4.096     4.301   \n",
       "nn4                                 LSTM, 7-day input       3.439     7.123   \n",
       "nn5                                 LSTM, 7-day input       3.873     7.499   \n",
       "\n",
       "         r2_train r2_val  \n",
       "NEMO        0.954  0.971  \n",
       "Lasso       0.977  0.973  \n",
       "Lasso1      0.971  0.969  \n",
       "Lasso2      0.676  0.557  \n",
       "XGBoost     0.996  0.968  \n",
       "XGBoost1    0.984   0.97  \n",
       "XGBoost2    0.953  0.427  \n",
       "XGBoost3      1.0  0.403  \n",
       "nn1         0.985  0.979  \n",
       "nn2         0.906  0.467  \n",
       "nn3         0.976  0.974  \n",
       "nn4         0.964  0.917  \n",
       "nn5         0.954  0.914  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input Shape\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "# Instantiate model and build layers\n",
    "nn = models.Sequential()\n",
    "nn.add(layers.LSTM(83, activation='tanh', input_shape=input_shape))\n",
    "nn.add(layers.RepeatVector(y_train.shape[1]))\n",
    "nn.add(layers.LSTM(24, activation='tanh', return_sequences=True))\n",
    "nn.add(TimeDistributed(layers.Dense(1)))\n",
    "\n",
    "# Compile Fit\n",
    "nn5 = compile_fit(nn, (X_train, y_train), (X_val, y_val))\n",
    "\n",
    "# Compute metrics, add to table\n",
    "results_actual['nn5'] = compute_metrics(nn5, 'LSTM, 7-day input', (X_train,y_train), (X_val,y_val))\n",
    "\n",
    "# Save Model\n",
    "nn5.save('../models/nn5')\n",
    "\n",
    "# Preview\n",
    "results_actual.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, the addition of a few extra nodes in the first layer did not change the performance of the LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN-LSTM Neural Network <a class=\"anchor\" id=\"DNN-LSTM Neural Network\"></a>\n",
    "The motivation for this model comes from this [article](https://www.sciencedirect.com/science/article/pii/S030626191830196X#s0220). The idea is that time-dependent features (values from the past) can be modeled by an LSTM, but if the data represetns a specific property associated with the day ahead (forecast data) then it cannot be modeled as a time sequence.  In this case, all the columns in the dataset with `_lag` suffix are past values, while all other columns represent future predictions.  With this distinction, I'll set up a combined DNN-LSTM model:\n",
    "\n",
    "**DNN**\n",
    "* Single best non-lstm neural network\n",
    "* Trained on forecast columns only\n",
    "\n",
    "**LSTM**\n",
    "* Single best lstm neural network\n",
    "* Trained on the `_lag` columns\n",
    "\n",
    "**Ensemble**<br>\n",
    "In order to combine these network, I created the function [`ensemble_nn`](https://github.com/EvanHolder/capstone/blob/main/scripts/functions.py) which takes in a list of models. For each model in the list, the function changes the model's layers untrainable.  Once complete, the function sets up another mini neural network.  The architecture is the concatenated output of each model, then hidden dense layer with 24 nodes, and finally a TimeDistributed dense layer as the final output.  Once the dnn and lstm are trained on their respective columns, we can call the `ensemble_nn` function to instantiate it.  All that's left to do is fit the resulting ensemble on the data and compute the results.\n",
    "\n",
    "In the Neural Networks [notebook](https://github.com/EvanHolder/capstone/blob/main/notebooks/NeuralNets.ipynb), I played around with both the dnn and lstm architecture input windows. In the end, this tuning did not prove to impact either the dnn or lstm significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "58/58 [==============================] - 1s 7ms/step - loss: 12.7041 - SMAPE: 33.4569 - val_loss: 1.8978 - val_SMAPE: 6.8829\n",
      "Epoch 2/200\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 2.8541 - SMAPE: 6.4467 - val_loss: 1.7937 - val_SMAPE: 5.6683\n",
      "Epoch 3/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 2.5618 - SMAPE: 5.2333 - val_loss: 1.8608 - val_SMAPE: 5.6845\n",
      "Epoch 4/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 2.4285 - SMAPE: 4.8457 - val_loss: 3.2789 - val_SMAPE: 8.8133\n",
      "Epoch 5/200\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 2.4227 - SMAPE: 4.7123 - val_loss: 1.8091 - val_SMAPE: 5.5043\n",
      "Epoch 6/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 2.3088 - SMAPE: 4.4613 - val_loss: 2.6440 - val_SMAPE: 7.4034\n",
      "Epoch 7/200\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 2.3094 - SMAPE: 4.4513 - val_loss: 3.2168 - val_SMAPE: 8.6800\n",
      "Epoch 8/200\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 2.2361 - SMAPE: 4.3466 - val_loss: 4.4220 - val_SMAPE: 11.4018\n",
      "Epoch 9/200\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 2.6892 - SMAPE: 5.0185 - val_loss: 1.7478 - val_SMAPE: 5.2457\n",
      "Epoch 10/200\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 2.1671 - SMAPE: 4.1538 - val_loss: 2.3286 - val_SMAPE: 6.7221\n",
      "Epoch 11/200\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 2.1428 - SMAPE: 4.0982 - val_loss: 3.8811 - val_SMAPE: 10.2027\n",
      "Epoch 12/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 2.2287 - SMAPE: 4.2400 - val_loss: 1.7621 - val_SMAPE: 5.2459\n",
      "Epoch 13/200\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 2.2440 - SMAPE: 4.5584 - val_loss: 3.2971 - val_SMAPE: 8.9850\n",
      "Epoch 14/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 2.2517 - SMAPE: 4.3005 - val_loss: 1.9986 - val_SMAPE: 5.8826\n",
      "Epoch 15/200\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 2.1793 - SMAPE: 4.1501 - val_loss: 3.9188 - val_SMAPE: 10.3339\n",
      "Epoch 16/200\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 2.2187 - SMAPE: 4.2379 - val_loss: 2.3342 - val_SMAPE: 6.6747\n",
      "Epoch 17/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 2.0339 - SMAPE: 3.8637 - val_loss: 3.0279 - val_SMAPE: 8.4026\n",
      "Epoch 18/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 2.0915 - SMAPE: 3.9464 - val_loss: 1.7638 - val_SMAPE: 5.2199\n",
      "Epoch 19/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 2.2936 - SMAPE: 4.3012 - val_loss: 1.9852 - val_SMAPE: 5.8416\n",
      "Epoch 20/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 2.4849 - SMAPE: 4.6221 - val_loss: 1.7395 - val_SMAPE: 5.1663\n",
      "Epoch 21/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 2.3297 - SMAPE: 4.3421 - val_loss: 2.4498 - val_SMAPE: 6.9663\n",
      "Epoch 22/200\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 2.0339 - SMAPE: 3.8917 - val_loss: 2.1022 - val_SMAPE: 6.1664\n",
      "Epoch 23/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 2.0630 - SMAPE: 3.9021 - val_loss: 2.2395 - val_SMAPE: 6.4194\n",
      "Epoch 24/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 2.0423 - SMAPE: 3.9074 - val_loss: 1.6250 - val_SMAPE: 4.8124\n",
      "Epoch 25/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 2.3046 - SMAPE: 4.3227 - val_loss: 3.0805 - val_SMAPE: 8.4811\n",
      "Epoch 26/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 2.0285 - SMAPE: 3.8533 - val_loss: 2.9160 - val_SMAPE: 8.1297\n",
      "Epoch 27/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 2.0832 - SMAPE: 3.9054 - val_loss: 1.6988 - val_SMAPE: 4.9952\n",
      "Epoch 28/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 2.1032 - SMAPE: 4.0661 - val_loss: 2.8549 - val_SMAPE: 7.9870\n",
      "Epoch 29/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 2.0780 - SMAPE: 4.0329 - val_loss: 4.0384 - val_SMAPE: 10.8013\n",
      "Epoch 30/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 2.0574 - SMAPE: 3.9545 - val_loss: 2.7348 - val_SMAPE: 7.7676\n",
      "Epoch 31/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 2.0780 - SMAPE: 3.9029 - val_loss: 2.6792 - val_SMAPE: 7.5401\n",
      "Epoch 32/200\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 2.0372 - SMAPE: 3.8445 - val_loss: 2.0414 - val_SMAPE: 6.0383\n",
      "Epoch 33/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 2.1552 - SMAPE: 4.0416 - val_loss: 3.0882 - val_SMAPE: 8.5556\n",
      "Epoch 34/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 2.0686 - SMAPE: 3.9058 - val_loss: 3.0292 - val_SMAPE: 8.3526\n",
      "Epoch 1/200\n",
      "58/58 [==============================] - 4s 32ms/step - loss: 51.8446 - SMAPE: 166.2114 - val_loss: 31.8950 - val_SMAPE: 133.6569\n",
      "Epoch 2/200\n",
      "58/58 [==============================] - 1s 22ms/step - loss: 48.6867 - SMAPE: 145.6342 - val_loss: 30.1544 - val_SMAPE: 121.0852\n",
      "Epoch 3/200\n",
      "58/58 [==============================] - 1s 22ms/step - loss: 47.0918 - SMAPE: 138.5869 - val_loss: 28.6436 - val_SMAPE: 111.0112\n",
      "Epoch 4/200\n",
      "58/58 [==============================] - 1s 22ms/step - loss: 45.6051 - SMAPE: 130.6944 - val_loss: 27.1909 - val_SMAPE: 101.9520\n",
      "Epoch 5/200\n",
      "58/58 [==============================] - 1s 23ms/step - loss: 44.1582 - SMAPE: 123.5828 - val_loss: 25.7732 - val_SMAPE: 93.6508\n",
      "Epoch 6/200\n",
      "58/58 [==============================] - 1s 22ms/step - loss: 42.7377 - SMAPE: 117.1357 - val_loss: 24.3858 - val_SMAPE: 85.9987\n",
      "Epoch 7/200\n",
      "58/58 [==============================] - 1s 22ms/step - loss: 41.3380 - SMAPE: 110.8888 - val_loss: 23.0291 - val_SMAPE: 78.9320\n",
      "Epoch 8/200\n",
      "58/58 [==============================] - 1s 22ms/step - loss: 39.9560 - SMAPE: 104.6616 - val_loss: 21.7014 - val_SMAPE: 72.3820\n",
      "Epoch 9/200\n",
      "58/58 [==============================] - 1s 23ms/step - loss: 38.5894 - SMAPE: 98.8535 - val_loss: 20.4041 - val_SMAPE: 66.3057\n",
      "Epoch 10/200\n",
      "58/58 [==============================] - 1s 22ms/step - loss: 37.2396 - SMAPE: 93.1990 - val_loss: 19.1428 - val_SMAPE: 60.6893\n",
      "Epoch 11/200\n",
      "58/58 [==============================] - 1s 22ms/step - loss: 35.9122 - SMAPE: 88.9907 - val_loss: 17.9326 - val_SMAPE: 55.5617\n",
      "Epoch 12/200\n",
      "58/58 [==============================] - 1s 22ms/step - loss: 34.5900 - SMAPE: 84.1801 - val_loss: 16.7525 - val_SMAPE: 50.7932\n",
      "Epoch 13/200\n",
      "58/58 [==============================] - 1s 22ms/step - loss: 33.2768 - SMAPE: 79.4778 - val_loss: 15.6296 - val_SMAPE: 46.4532\n",
      "Epoch 14/200\n",
      "58/58 [==============================] - 1s 22ms/step - loss: 31.9763 - SMAPE: 74.9984 - val_loss: 14.5659 - val_SMAPE: 42.5148\n",
      "Epoch 15/200\n",
      "58/58 [==============================] - 1s 23ms/step - loss: 30.6885 - SMAPE: 70.5571 - val_loss: 13.5632 - val_SMAPE: 38.9545\n",
      "Epoch 16/200\n",
      "58/58 [==============================] - 1s 22ms/step - loss: 29.4156 - SMAPE: 66.4843 - val_loss: 12.6332 - val_SMAPE: 35.7727\n",
      "Epoch 17/200\n",
      "58/58 [==============================] - 1s 22ms/step - loss: 28.1618 - SMAPE: 62.4683 - val_loss: 11.7934 - val_SMAPE: 32.9985\n",
      "Epoch 18/200\n",
      "58/58 [==============================] - 1s 22ms/step - loss: 26.9259 - SMAPE: 59.1582 - val_loss: 11.0641 - val_SMAPE: 30.6625\n",
      "Epoch 19/200\n",
      "58/58 [==============================] - 1s 22ms/step - loss: 25.7132 - SMAPE: 55.6201 - val_loss: 10.4480 - val_SMAPE: 28.7414\n",
      "Epoch 20/200\n",
      "58/58 [==============================] - 1s 22ms/step - loss: 24.5235 - SMAPE: 52.4403 - val_loss: 9.9562 - val_SMAPE: 27.2362\n",
      "Epoch 21/200\n",
      "58/58 [==============================] - 1s 22ms/step - loss: 23.3618 - SMAPE: 49.0968 - val_loss: 9.5826 - val_SMAPE: 26.1006\n",
      "Epoch 22/200\n",
      "58/58 [==============================] - 1s 22ms/step - loss: 22.2262 - SMAPE: 45.7378 - val_loss: 9.3180 - val_SMAPE: 25.2881\n",
      "Epoch 23/200\n",
      "58/58 [==============================] - 1s 22ms/step - loss: 21.1245 - SMAPE: 42.6903 - val_loss: 9.1573 - val_SMAPE: 24.7635\n",
      "Epoch 24/200\n",
      "58/58 [==============================] - 1s 22ms/step - loss: 20.0804 - SMAPE: 40.0635 - val_loss: 9.0879 - val_SMAPE: 24.4873\n",
      "Epoch 25/200\n",
      "58/58 [==============================] - 1s 22ms/step - loss: 19.0663 - SMAPE: 37.9603 - val_loss: 9.1085 - val_SMAPE: 24.4459\n",
      "Epoch 26/200\n",
      "58/58 [==============================] - 1s 22ms/step - loss: 18.0953 - SMAPE: 35.6075 - val_loss: 9.2229 - val_SMAPE: 24.6289\n",
      "Epoch 27/200\n",
      "58/58 [==============================] - 1s 22ms/step - loss: 17.1809 - SMAPE: 33.4444 - val_loss: 9.4313 - val_SMAPE: 25.0200\n",
      "Epoch 28/200\n",
      "58/58 [==============================] - 1s 22ms/step - loss: 16.3411 - SMAPE: 31.4077 - val_loss: 9.7216 - val_SMAPE: 25.5793\n",
      "Epoch 29/200\n",
      "58/58 [==============================] - 1s 22ms/step - loss: 15.5604 - SMAPE: 29.9435 - val_loss: 10.0781 - val_SMAPE: 26.2659\n",
      "Epoch 30/200\n",
      "58/58 [==============================] - 1s 23ms/step - loss: 14.8530 - SMAPE: 28.6162 - val_loss: 10.4967 - val_SMAPE: 27.0653\n",
      "Epoch 31/200\n",
      "58/58 [==============================] - 1s 24ms/step - loss: 14.2117 - SMAPE: 26.5898 - val_loss: 10.9468 - val_SMAPE: 27.9176\n",
      "Epoch 32/200\n",
      "58/58 [==============================] - 1s 23ms/step - loss: 13.6482 - SMAPE: 25.4328 - val_loss: 11.4313 - val_SMAPE: 28.8221\n",
      "Epoch 33/200\n",
      "58/58 [==============================] - 1s 23ms/step - loss: 13.1514 - SMAPE: 24.7985 - val_loss: 11.9337 - val_SMAPE: 29.7509\n",
      "Epoch 34/200\n",
      "58/58 [==============================] - 1s 22ms/step - loss: 12.7219 - SMAPE: 23.7456 - val_loss: 12.4447 - val_SMAPE: 30.6826\n",
      "Epoch 35/200\n",
      "58/58 [==============================] - 1s 22ms/step - loss: 12.3568 - SMAPE: 22.8596 - val_loss: 12.9520 - val_SMAPE: 31.5974\n",
      "Epoch 1/200\n",
      "58/58 [==============================] - 3s 25ms/step - loss: 35.0999 - SMAPE: 89.5914 - val_loss: 8.1057 - val_SMAPE: 21.7547\n",
      "Epoch 2/200\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 9.4168 - SMAPE: 17.9639 - val_loss: 11.5010 - val_SMAPE: 28.7532\n",
      "Epoch 3/200\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 5.0119 - SMAPE: 9.8302 - val_loss: 7.9606 - val_SMAPE: 21.3627\n",
      "Epoch 4/200\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 3.6056 - SMAPE: 7.2141 - val_loss: 6.6203 - val_SMAPE: 18.1335\n",
      "Epoch 5/200\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 2.7448 - SMAPE: 5.5042 - val_loss: 5.3023 - val_SMAPE: 14.7420\n",
      "Epoch 6/200\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 2.2410 - SMAPE: 4.4092 - val_loss: 3.7394 - val_SMAPE: 10.6404\n",
      "Epoch 7/200\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 2.0404 - SMAPE: 3.9697 - val_loss: 3.4838 - val_SMAPE: 9.7806\n",
      "Epoch 8/200\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 2.0073 - SMAPE: 3.8317 - val_loss: 2.9104 - val_SMAPE: 8.2790\n",
      "Epoch 9/200\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 1.9940 - SMAPE: 3.8476 - val_loss: 2.9820 - val_SMAPE: 8.4141\n",
      "Epoch 10/200\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 2.0004 - SMAPE: 3.8113 - val_loss: 3.4609 - val_SMAPE: 9.5895\n",
      "Epoch 11/200\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 1.9893 - SMAPE: 4.0569 - val_loss: 3.2093 - val_SMAPE: 8.9768\n",
      "Epoch 12/200\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 1.9858 - SMAPE: 3.8064 - val_loss: 2.6430 - val_SMAPE: 7.5770\n",
      "Epoch 13/200\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 2.0026 - SMAPE: 3.8205 - val_loss: 3.3372 - val_SMAPE: 9.2975\n",
      "Epoch 14/200\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 1.9873 - SMAPE: 3.8428 - val_loss: 2.8915 - val_SMAPE: 8.1760\n",
      "Epoch 15/200\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 1.9992 - SMAPE: 3.8091 - val_loss: 2.9448 - val_SMAPE: 8.3072\n",
      "Epoch 16/200\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 1.9923 - SMAPE: 3.7894 - val_loss: 3.0760 - val_SMAPE: 8.6247\n",
      "Epoch 17/200\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 2.0043 - SMAPE: 3.8750 - val_loss: 3.1305 - val_SMAPE: 8.7691\n",
      "Epoch 18/200\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 1.9843 - SMAPE: 3.9074 - val_loss: 2.9227 - val_SMAPE: 8.2522\n",
      "Epoch 19/200\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 1.9922 - SMAPE: 3.8028 - val_loss: 3.0615 - val_SMAPE: 8.6083\n",
      "Epoch 20/200\n",
      "58/58 [==============================] - 1987s 35s/step - loss: 1.9862 - SMAPE: 3.9173 - val_loss: 3.2651 - val_SMAPE: 9.0959\n",
      "Epoch 21/200\n",
      "58/58 [==============================] - 1s 14ms/step - loss: 1.9800 - SMAPE: 3.7908 - val_loss: 2.9053 - val_SMAPE: 8.2004\n",
      "Epoch 22/200\n",
      "58/58 [==============================] - 1s 18ms/step - loss: 1.9717 - SMAPE: 3.8364 - val_loss: 3.5908 - val_SMAPE: 9.9047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/nn6\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/nn6\\assets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>SMAPE_train</th>\n",
       "      <th>SMAPE_val</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NEMO</th>\n",
       "      <td>None</td>\n",
       "      <td>16.03</td>\n",
       "      <td>16.922</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>3.021</td>\n",
       "      <td>5.869</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso1</th>\n",
       "      <td>{'num_features': 5}</td>\n",
       "      <td>3.367</td>\n",
       "      <td>5.056</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso2</th>\n",
       "      <td>{'price_day_ahead': False}</td>\n",
       "      <td>11.811</td>\n",
       "      <td>32.664</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>1.248</td>\n",
       "      <td>6.668</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost1</th>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>2.465</td>\n",
       "      <td>5.85</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost2</th>\n",
       "      <td>{'max_depth': 2, 'price_day_ahead': False}</td>\n",
       "      <td>4.331</td>\n",
       "      <td>27.241</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost3</th>\n",
       "      <td>{'max_depth': 16, 'price_day_ahead': False}</td>\n",
       "      <td>0.026</td>\n",
       "      <td>24.84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn1</th>\n",
       "      <td>1-to-1</td>\n",
       "      <td>3.332</td>\n",
       "      <td>3.88</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn2</th>\n",
       "      <td>1-to-1, price_day_ahead:False</td>\n",
       "      <td>7.139</td>\n",
       "      <td>21.382</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn3</th>\n",
       "      <td>24-to-24</td>\n",
       "      <td>4.096</td>\n",
       "      <td>4.301</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn4</th>\n",
       "      <td>LSTM, 7-day input</td>\n",
       "      <td>3.439</td>\n",
       "      <td>7.123</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn5</th>\n",
       "      <td>LSTM, 7-day input</td>\n",
       "      <td>3.873</td>\n",
       "      <td>7.499</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn6</th>\n",
       "      <td>dnn-lstm, 1-day input</td>\n",
       "      <td>3.931</td>\n",
       "      <td>7.67</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Parameters SMAPE_train SMAPE_val  \\\n",
       "NEMO                                             None       16.03    16.922   \n",
       "Lasso                                         Vanilla       3.021     5.869   \n",
       "Lasso1                            {'num_features': 5}       3.367     5.056   \n",
       "Lasso2                     {'price_day_ahead': False}      11.811    32.664   \n",
       "XGBoost                                       Vanilla       1.248     6.668   \n",
       "XGBoost1                             {'max_depth': 2}       2.465      5.85   \n",
       "XGBoost2   {'max_depth': 2, 'price_day_ahead': False}       4.331    27.241   \n",
       "XGBoost3  {'max_depth': 16, 'price_day_ahead': False}       0.026     24.84   \n",
       "nn1                                            1-to-1       3.332      3.88   \n",
       "nn2                     1-to-1, price_day_ahead:False       7.139    21.382   \n",
       "nn3                                          24-to-24       4.096     4.301   \n",
       "nn4                                 LSTM, 7-day input       3.439     7.123   \n",
       "nn5                                 LSTM, 7-day input       3.873     7.499   \n",
       "nn6                             dnn-lstm, 1-day input       3.931      7.67   \n",
       "\n",
       "         r2_train r2_val  \n",
       "NEMO        0.954  0.971  \n",
       "Lasso       0.977  0.973  \n",
       "Lasso1      0.971  0.969  \n",
       "Lasso2      0.676  0.557  \n",
       "XGBoost     0.996  0.968  \n",
       "XGBoost1    0.984   0.97  \n",
       "XGBoost2    0.953  0.427  \n",
       "XGBoost3      1.0  0.403  \n",
       "nn1         0.985  0.979  \n",
       "nn2         0.906  0.467  \n",
       "nn3         0.976  0.974  \n",
       "nn4         0.964  0.917  \n",
       "nn5         0.954  0.914  \n",
       "nn6         0.961  0.975  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into train and validation\n",
    "X_train, y_train, X_val, y_val = split_data(df_nn, 2020, 'price_actual')\n",
    "\n",
    "# Get the x cols for lstm network, lagged cols\n",
    "X_train_lstm = X_train.filter(regex='lag')\n",
    "X_train_dnn = X_train.drop(columns=X_train_lstm.columns)\n",
    "\n",
    "# Get the x cols for dnn network, forecast cols\n",
    "X_val_lstm = X_val.filter(regex='lag')\n",
    "X_val_dnn = X_val.drop(columns=X_val_lstm.columns)\n",
    "\n",
    "# Reorganize the training and testing data into batches\n",
    "X_train_dnn, y_train_dnn = resample((X_train_dnn, y_train), 24, 24, 24)\n",
    "X_val_dnn, y_val_dnn = resample((X_val_dnn, y_val), 24, 24, 24)\n",
    "\n",
    "# LSTM\n",
    "X_train_lstm, y_train_lstm = resample((X_train_lstm, y_train), 24, 24, 24)\n",
    "X_val_lstm, y_val_lstm = resample((X_val_lstm, y_val), 24, 24, 24)\n",
    "\n",
    "# Instantiate, compiled and fit dnn\n",
    "input_shape = (X_train_dnn.shape[1], X_train_dnn.shape[2])\n",
    "nn = models.Sequential()\n",
    "nn.add(layers.Dense(59, activation='relu', input_shape=input_shape))\n",
    "nn.add(layers.Dense(239, activation='relu'))\n",
    "nn.add(layers.Dense(162, activation='relu'))\n",
    "nn.add(TimeDistributed(layers.Dense(1)))\n",
    "dnn = compile_fit(nn, (X_train_dnn, y_train_dnn), (X_val_dnn, y_val_dnn))\n",
    "\n",
    "\n",
    "# Instantiate, compiled and fit lstm\n",
    "input_shape = (X_train_lstm.shape[1], X_train_lstm.shape[2])\n",
    "nn = models.Sequential()\n",
    "nn.add(layers.LSTM(83, activation='tanh', input_shape=input_shape))\n",
    "nn.add(layers.RepeatVector(y_train_lstm.shape[1]))\n",
    "nn.add(layers.LSTM(24, activation='tanh', return_sequences=True))\n",
    "nn.add(TimeDistributed(layers.Dense(1)))\n",
    "lstm = compile_fit(nn, (X_train_lstm, y_train_lstm), (X_val_lstm, y_val_lstm))\n",
    "\n",
    "# Create ensemble to combine dnn and lstm, compile and fit\n",
    "LSTM_DNN = ensemble_nn([dnn, lstm])\n",
    "nn6 = compile_fit(LSTM_DNN, ([X_train_dnn, X_train_lstm], y_train_dnn), ([X_val_dnn, X_val_lstm], y_val_dnn))\n",
    "\n",
    "# Compute metrics, add to table\n",
    "results_actual['nn6'] = compute_metrics(nn6,\n",
    "                                        'dnn-lstm, 1-day input',\n",
    "                                        ([X_train_dnn, X_train_lstm],y_train),\n",
    "                                        ([X_val_dnn, X_val_lstm],y_val))\n",
    "\n",
    "# Save Model\n",
    "nn6.save('../models/nn6')\n",
    "\n",
    "results_actual.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the table above, the combined dnn-lstm model did not improve upon the best neural network. In my [notebook](https://github.com/EvanHolder/capstone/blob/main/notebooks/NeuralNets.ipynb), I found out why the metric were degraded.  The LSTM network when trained on the `_lag` data, did not pick up on the any significant trends.  Instead, it found a few solid predictions and most of the time predicted one of four number instead of a nice continuous range.  See the plot below.\n",
    "\n",
    "<img src='../images/LSTM_hist.png' style='width:500px;height=326px'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>SMAPE_train</th>\n",
       "      <th>SMAPE_val</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nn1</th>\n",
       "      <td>1-to-1</td>\n",
       "      <td>3.332</td>\n",
       "      <td>3.88</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn3</th>\n",
       "      <td>24-to-24</td>\n",
       "      <td>4.096</td>\n",
       "      <td>4.301</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso1</th>\n",
       "      <td>{'num_features': 5}</td>\n",
       "      <td>3.367</td>\n",
       "      <td>5.056</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost1</th>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>2.465</td>\n",
       "      <td>5.85</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>3.021</td>\n",
       "      <td>5.869</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>1.248</td>\n",
       "      <td>6.668</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn4</th>\n",
       "      <td>LSTM, 7-day input</td>\n",
       "      <td>3.439</td>\n",
       "      <td>7.123</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn5</th>\n",
       "      <td>LSTM, 7-day input</td>\n",
       "      <td>3.873</td>\n",
       "      <td>7.499</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn6</th>\n",
       "      <td>dnn-lstm, 1-day input</td>\n",
       "      <td>3.931</td>\n",
       "      <td>7.67</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEMO</th>\n",
       "      <td>None</td>\n",
       "      <td>16.03</td>\n",
       "      <td>16.922</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn2</th>\n",
       "      <td>1-to-1, price_day_ahead:False</td>\n",
       "      <td>7.139</td>\n",
       "      <td>21.382</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost3</th>\n",
       "      <td>{'max_depth': 16, 'price_day_ahead': False}</td>\n",
       "      <td>0.026</td>\n",
       "      <td>24.84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost2</th>\n",
       "      <td>{'max_depth': 2, 'price_day_ahead': False}</td>\n",
       "      <td>4.331</td>\n",
       "      <td>27.241</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso2</th>\n",
       "      <td>{'price_day_ahead': False}</td>\n",
       "      <td>11.811</td>\n",
       "      <td>32.664</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Parameters SMAPE_train SMAPE_val  \\\n",
       "nn1                                            1-to-1       3.332      3.88   \n",
       "nn3                                          24-to-24       4.096     4.301   \n",
       "Lasso1                            {'num_features': 5}       3.367     5.056   \n",
       "XGBoost1                             {'max_depth': 2}       2.465      5.85   \n",
       "Lasso                                         Vanilla       3.021     5.869   \n",
       "XGBoost                                       Vanilla       1.248     6.668   \n",
       "nn4                                 LSTM, 7-day input       3.439     7.123   \n",
       "nn5                                 LSTM, 7-day input       3.873     7.499   \n",
       "nn6                             dnn-lstm, 1-day input       3.931      7.67   \n",
       "NEMO                                             None       16.03    16.922   \n",
       "nn2                     1-to-1, price_day_ahead:False       7.139    21.382   \n",
       "XGBoost3  {'max_depth': 16, 'price_day_ahead': False}       0.026     24.84   \n",
       "XGBoost2   {'max_depth': 2, 'price_day_ahead': False}       4.331    27.241   \n",
       "Lasso2                     {'price_day_ahead': False}      11.811    32.664   \n",
       "\n",
       "         r2_train r2_val  \n",
       "nn1         0.985  0.979  \n",
       "nn3         0.976  0.974  \n",
       "Lasso1      0.971  0.969  \n",
       "XGBoost1    0.984   0.97  \n",
       "Lasso       0.977  0.973  \n",
       "XGBoost     0.996  0.968  \n",
       "nn4         0.964  0.917  \n",
       "nn5         0.954  0.914  \n",
       "nn6         0.961  0.975  \n",
       "NEMO        0.954  0.971  \n",
       "nn2         0.906  0.467  \n",
       "XGBoost3      1.0  0.403  \n",
       "XGBoost2    0.953  0.427  \n",
       "Lasso2      0.676  0.557  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_actual.T.sort_values(by='SMAPE_val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above shows the results of each model, sorted by SMAPE_val.  The best models so far have been the two simple neural networks, followed by a shallow XGBoost model.  The worst models do not include `price_day_ahead`, which perform half as well across the board.  It's very clear that we need `price_day_ahead` in order to predict the actual price with any accuracy, but is it possible to predict the difference between `price_day_ahead` and `price_actual`? \n",
    "\n",
    "### Modeling Price Components<a class=\"anchor\" id=\"Modeling-Price_Residual\"></a>\n",
    "`Price_actual` in reality, is made of 15 different price components, the most important being `price_day_ahead`. I'd like to know the data contains any other information about these price components. So to answer that question, there are two different approaches to try.\n",
    "\n",
    "**Method 1: Model the Residual**<br>\n",
    "In this approach, I'll subtract the `price_day_ahead` from `price_actual` to get the residual.  The residual price represents the portion of `price_actual` that is not reflected in `price_day_ahead`\n",
    "\n",
    "**Methods 2: Model Individual Price Components**<br>\n",
    "In this approach I'll set up separate models to predict each individual price component(except `price_day_ahead`). This should be able to tell us at a granular level which price components are predictable, if any.\n",
    "\n",
    "### Model the Residual\n",
    "First thing to do, create the residual column. Then remove all the other price columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get price cols to predict\n",
    "price_cols = df_lag.filter(regex='price').columns.to_list()\n",
    "\n",
    "# Create price_residual\n",
    "df_comp = df_lag.copy()\n",
    "df_comp['price_residual'] = df_comp['price_day_ahead'] - df_comp['price_actual']\n",
    "\n",
    "# Drop other price cols, and split data\n",
    "df_comp.drop(columns = price_cols, inplace=True)\n",
    "X_train, y_train, X_val, y_val = split_data(df_comp, 2020, 'price_residual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create another results dataframe to update with results from each model. Then I'll fit a Lasso, XGBoost, and Neural Network to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>sMAPE_train</th>\n",
       "      <th>sMAPE_val</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lasso_resid</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>21.03</td>\n",
       "      <td>34.483</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xg_resid</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>9.025</td>\n",
       "      <td>35.37</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Parameters sMAPE_train sMAPE_val r2_train r2_val\n",
       "lasso_resid    vanilla       21.03    34.483     0.52  0.117\n",
       "xg_resid       vanilla       9.025     35.37    0.927  0.174"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create results table\n",
    "results_resid = pd.DataFrame(index=['Parameters','sMAPE_train', 'sMAPE_val', 'r2_train', 'r2_val'])\n",
    "\n",
    "# Instantiate Lasso, XGBoost\n",
    "lasso_resid = Lasso(max_iter=10000)\n",
    "xg_resid = XGBRegressor(random_state=17)\n",
    "\n",
    "\n",
    "# Fit Lasso, XGboost\n",
    "lasso_resid.fit(X_train, y_train)\n",
    "xg_resid.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Compute sMAPE, r2 and add to the table\n",
    "results_resid['lasso_resid']= compute_metrics(lasso_resid, 'vanilla', (X_train, y_train), (X_val, y_val))\n",
    "results_resid['xg_resid'] = compute_metrics(xg_resid, 'vanilla', (X_train, y_train), (X_val, y_val))\n",
    "results_resid.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, neither Lasso nor XGBoost seemed to fit the residual very well. Below I'll try a simple neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1369/1369 [==============================] - 3s 2ms/step - loss: 7.3481 - SMAPE: 200.0000 - val_loss: 5.1544 - val_SMAPE: 200.0000\n",
      "Epoch 2/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 7.3482 - SMAPE: 200.0000 - val_loss: 5.1544 - val_SMAPE: 200.0000\n",
      "Epoch 3/200\n",
      "1369/1369 [==============================] - 3s 2ms/step - loss: 7.3482 - SMAPE: 200.0000 - val_loss: 5.1544 - val_SMAPE: 200.0000\n",
      "Epoch 4/200\n",
      "1369/1369 [==============================] - 3s 2ms/step - loss: 7.3482 - SMAPE: 200.0000 - val_loss: 5.1544 - val_SMAPE: 200.0000\n",
      "Epoch 5/200\n",
      "1369/1369 [==============================] - 3s 2ms/step - loss: 7.3482 - SMAPE: 200.0000 - val_loss: 5.1544 - val_SMAPE: 200.0000\n",
      "Epoch 6/200\n",
      "1369/1369 [==============================] - 3s 2ms/step - loss: 7.3482 - SMAPE: 200.0000 - val_loss: 5.1544 - val_SMAPE: 200.0000\n",
      "Epoch 7/200\n",
      "1369/1369 [==============================] - 3s 2ms/step - loss: 7.3482 - SMAPE: 200.0000 - val_loss: 5.1544 - val_SMAPE: 200.0000\n",
      "Epoch 8/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 7.3482 - SMAPE: 200.0000 - val_loss: 5.1544 - val_SMAPE: 200.0000\n",
      "Epoch 9/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 7.3482 - SMAPE: 200.0000 - val_loss: 5.1544 - val_SMAPE: 200.0000\n",
      "Epoch 10/200\n",
      "1369/1369 [==============================] - 2s 1ms/step - loss: 7.3481 - SMAPE: 200.0000 - val_loss: 5.1544 - val_SMAPE: 200.0000\n",
      "Epoch 11/200\n",
      "1369/1369 [==============================] - 2s 1ms/step - loss: 7.3482 - SMAPE: 200.0000 - val_loss: 5.1544 - val_SMAPE: 200.0000\n"
     ]
    }
   ],
   "source": [
    "# Define input_shape\n",
    "input_shape = (X_train.shape[1],)\n",
    "\n",
    "# Instantiate model and build layers\n",
    "nn = models.Sequential()\n",
    "nn.add(layers.Dense(59, activation='relu', input_shape=input_shape))\n",
    "nn.add(layers.Dense(239, activation='relu'))\n",
    "nn.add(layers.Dense(162, activation='relu'))\n",
    "nn.add(layers.Dense(1, activation='relu'))\n",
    "\n",
    "# Compile and Fit\n",
    "nn_resid = compile_fit(nn, (X_train,y_train), (X_val, y_val), patience=10,\n",
    "                  loss = tf.keras.metrics.mean_absolute_error)\n",
    "\n",
    "# Compute metrics, add to table\n",
    "results_resid['nn_resid'] = compute_metrics(nn2, 'vanilla', (X_train,y_train), (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>sMAPE_train</th>\n",
       "      <th>sMAPE_val</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lasso_resid</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>21.03</td>\n",
       "      <td>34.483</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xg_resid</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>9.025</td>\n",
       "      <td>35.37</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn_resid</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Parameters sMAPE_train sMAPE_val r2_train r2_val\n",
       "lasso_resid    vanilla       21.03    34.483     0.52  0.117\n",
       "xg_resid       vanilla       9.025     35.37    0.927  0.174\n",
       "nn_resid       vanilla       200.0     200.0    0.047  0.003"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_resid.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, neural network did not work either. It does not seem like there is much information contained in the residual.  Next let's try Method 2.\n",
    "\n",
    "### Model Individual Price Components\n",
    "In this method, I'll model individual price components by using sklearn's MultiOutputRegressor wrapper.  This wrapper takes in a model object, and then fits the model to training data and each given target separately.  For simplicity, I'll start with Lasso.<br>\n",
    "**Lasso**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\holde\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0, tolerance: 0.0\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\holde\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\holde\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2560: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n",
      "C:\\Users\\holde\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\holde\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2560: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n",
      "C:\\Users\\holde\\flatiron\\capstone\\scripts\\functions.py:327: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return 100/(len(y_true)) * (abs(y_pred - y_true)/((abs(y_true)+abs(y_pred))/2)).sum()\n",
      "C:\\Users\\holde\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>sMAPE_train</th>\n",
       "      <th>sMAPE_val</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>price_power_factor</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>11.594</td>\n",
       "      <td>16.076</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_capacity_payment</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>34.371</td>\n",
       "      <td>36.169</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_PBF_tech</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>47.029</td>\n",
       "      <td>38.659</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_sec_reserve</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>44.785</td>\n",
       "      <td>58.79</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_measured_imbalances</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>90.578</td>\n",
       "      <td>85.028</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_imbalances_net</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>126.29</td>\n",
       "      <td>117.527</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_balance_failure</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>132.611</td>\n",
       "      <td>127.992</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_intraday_market</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>153.808</td>\n",
       "      <td>140.104</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_P0146_balance</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>173.384</td>\n",
       "      <td>167.904</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_rt_tech</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>162.144</td>\n",
       "      <td>172.66</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_interupt_service</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>19.309</td>\n",
       "      <td>193.665</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_intraday_tech</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_upward_reserve</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>190.879</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.095</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_generic_failure</th>\n",
       "      <td>vanilla</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Parameters sMAPE_train sMAPE_val r2_train r2_val\n",
       "price_power_factor           vanilla      11.594    16.076     0.38  0.009\n",
       "price_capacity_payment       vanilla      34.371    36.169    0.628  0.645\n",
       "price_PBF_tech               vanilla      47.029    38.659    0.549  0.431\n",
       "price_sec_reserve            vanilla      44.785     58.79    0.463  0.413\n",
       "price_measured_imbalances    vanilla      90.578    85.028    0.026  0.067\n",
       "price_imbalances_net         vanilla      126.29   117.527     0.03  0.017\n",
       "price_balance_failure        vanilla     132.611   127.992    0.022  0.005\n",
       "price_intraday_market        vanilla     153.808   140.104    0.026  0.014\n",
       "price_P0146_balance          vanilla     173.384   167.904    0.008  0.005\n",
       "price_rt_tech                vanilla     162.144    172.66    0.039   0.01\n",
       "price_interupt_service       vanilla      19.309   193.665    0.554  0.051\n",
       "price_intraday_tech          vanilla       200.0     200.0      0.0    NaN\n",
       "price_upward_reserve         vanilla     190.879     200.0    0.095    NaN\n",
       "price_generic_failure        vanilla         NaN       NaN      NaN    NaN"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unnecessary cols\n",
    "df_comps = df_lag.drop(columns=['price_day_ahead', 'price_actual'])\n",
    "\n",
    "# Get target cols\n",
    "price_cols = df_comps.filter(regex='price').columns.to_list()\n",
    "\n",
    "# Split Data\n",
    "X_train, y_train, X_val, y_val = split_data(df_comps, 2020, price_cols)\n",
    "\n",
    "# Instantiate Lasso and Multioutput Regressor\n",
    "lasso = Lasso(max_iter=10000)\n",
    "l_multi = MultiOutputRegressor(lasso)\n",
    "\n",
    "# Fit the Regressor\n",
    "l_multi.fit(X_train, y_train)\n",
    "\n",
    "# Get the predictions\n",
    "preds_train = l_multi.predict(X_train)\n",
    "preds_val = l_multi.predict(X_val)\n",
    "\n",
    "# Create results table\n",
    "results_lasso = pd.DataFrame(index=['Parameters','sMAPE_train', 'sMAPE_val', 'r2_train', 'r2_val'])\n",
    "\n",
    "# Add metric results to results table\n",
    "for i, model in enumerate(l_multi.estimators_):    \n",
    "    results_lasso[y_val.columns[i]] = compute_metrics(model,'vanilla',(X_train,y_train.iloc[:,i]), (X_val, y_val.iloc[:,i]))\n",
    "results_lasso.T.sort_values(by='sMAPE_val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few things to note about the above code.  First, as a few of the models fit, I received a warning that the model did not converge... or in other words, the algorithm did not zero in on a solution for its respective target component.  In the table, this result is apparent.  The model could not find a solution to predict `price_generic_failure` and therefore was not able to calculate its metrics.  Additionally, most of the SMAPE_val and r2_val values are exceptionally high with the exception of the top four components in the table.  This result is consistent with the model's trying to predict the price residual.  So while for most components, our data does not contain any information on the majority of components, it does have some (limited) information on `price_capacity_payment`, `price_PBF_tech`, and `price_sec_reserve`.<br>\n",
    "**XGBoost**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\holde\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\holde\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2560: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>sMAPE_train</th>\n",
       "      <th>sMAPE_val</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>price_power_factor</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>2.435</td>\n",
       "      <td>16.294</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_capacity_payment</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>11.405</td>\n",
       "      <td>38.368</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_PBF_tech</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>22.813</td>\n",
       "      <td>40.882</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_sec_reserve</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>25.511</td>\n",
       "      <td>58.703</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_measured_imbalances</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>74.216</td>\n",
       "      <td>94.997</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_imbalances_net</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>107.658</td>\n",
       "      <td>128.05</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_balance_failure</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>127.368</td>\n",
       "      <td>139.903</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_intraday_market</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>115.23</td>\n",
       "      <td>142.531</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_P0146_balance</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>123.289</td>\n",
       "      <td>148.704</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_rt_tech</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>155.139</td>\n",
       "      <td>172.34</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_interupt_service</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>3.722</td>\n",
       "      <td>191.344</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_intraday_tech</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>199.994</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.954</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_upward_reserve</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>186.057</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_generic_failure</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Parameters sMAPE_train sMAPE_val r2_train r2_val\n",
       "price_power_factor           Vanilla       2.435    16.294    0.971   0.13\n",
       "price_capacity_payment       Vanilla      11.405    38.368    0.957  0.573\n",
       "price_PBF_tech               Vanilla      22.813    40.882    0.933  0.471\n",
       "price_sec_reserve            Vanilla      25.511    58.703    0.874  0.297\n",
       "price_measured_imbalances    Vanilla      74.216    94.997    0.844  0.002\n",
       "price_imbalances_net         Vanilla     107.658    128.05    0.655  0.001\n",
       "price_balance_failure        Vanilla     127.368   139.903    0.646  0.001\n",
       "price_intraday_market        Vanilla      115.23   142.531    0.675  0.006\n",
       "price_P0146_balance          Vanilla     123.289   148.704    0.514  0.002\n",
       "price_rt_tech                Vanilla     155.139    172.34    0.743  0.016\n",
       "price_interupt_service       Vanilla       3.722   191.344    0.981  0.037\n",
       "price_intraday_tech          Vanilla     199.994     200.0    0.954    NaN\n",
       "price_upward_reserve         Vanilla     186.057     200.0    0.875    NaN\n",
       "price_generic_failure        Vanilla       200.0     200.0      NaN    NaN"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate Lasso and Multioutput Regressor\n",
    "xg = XGBRegressor(random_state=17)\n",
    "xg_multi = MultiOutputRegressor(xg)\n",
    "\n",
    "# Fit the Regressor\n",
    "xg_multi.fit(X_train, y_train)\n",
    "\n",
    "# Get the predictions\n",
    "preds_train = xg_multi.predict(X_train)\n",
    "preds_val = xg_multi.predict(X_val)\n",
    "\n",
    "# Create results table\n",
    "results_xg = pd.DataFrame(index=['Parameters','sMAPE_train', 'sMAPE_val', 'r2_train', 'r2_val'])\n",
    "\n",
    "# Add metric results to results table\n",
    "for i, model in enumerate(xg_multi.estimators_):    \n",
    "    results_xg[y_val.columns[i]] = compute_metrics(model,'Vanilla',(X_train,y_train.iloc[:,i]), (X_val, y_val.iloc[:,i]))\n",
    "results_xg.T.sort_values(by='sMAPE_val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the lasso and the XGBoost models have the same top 4 \"modelable\" components.  Lets retain Lasso and XGBoost models using on these top four components as the targets. The rest we'll leave out.  From there we'll use the data to predict these components, sum them together with the `price_day_ahead` and then compute their metrics and add to the original table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Components to drop\n",
    "price_drop = results_xg.T.sort_values(by='sMAPE_val').iloc[4:].index.to_list()\n",
    "df_comps2 = df_comps.drop(columns=price_drop)\n",
    "\n",
    "# Components to model\n",
    "top_comps = ['price_capacity_payment', 'price_PBF_tech', 'price_sec_reserve', 'price_power_factor']\n",
    "\n",
    "# Split Data\n",
    "X_train, y_train, X_val, y_val = split_data(df_comps2, 2020, top_comps)\n",
    "\n",
    "# Instantiate Lasso and Multioutput Regressor\n",
    "lasso = Lasso(max_iter=10000)\n",
    "l_multi = MultiOutputRegressor(lasso)\n",
    "xg = XGBRegressor(random_state=17)\n",
    "xg_multi = MultiOutputRegressor(xg)\n",
    "\n",
    "# Fit the Regressor\n",
    "l_multi.fit(X_train, y_train)\n",
    "xg_multi.fit(X_train, y_train)\n",
    "\n",
    "# Get the predictions\n",
    "preds_train_l = l_multi.predict(X_train).sum(axis=1) + df_lag.loc[:'2019', 'price_day_ahead']\n",
    "preds_val_l = l_multi.predict(X_val).sum(axis=1) + df_lag.loc['2020', 'price_day_ahead']\n",
    "preds_train_xg = xg_multi.predict(X_train).sum(axis=1) + df_lag.loc[:'2019', 'price_day_ahead']\n",
    "preds_val_xg = xg_multi.predict(X_val).sum(axis=1) + df_lag.loc['2020', 'price_day_ahead']\n",
    "\n",
    "# Get the training and validation actual price\n",
    "y_true_train = df_lag.loc[:'2019','price_actual']\n",
    "y_true_val = df_lag.loc['2020','price_actual']\n",
    "\n",
    "# Add to results dataframe\n",
    "results_actual['Lasso_MOR'] = ['Vanilla',\n",
    "                            sMAPE(y_true_train, preds_train_l),\n",
    "                            sMAPE(y_true_val, preds_val_l),\n",
    "                            r2(y_true_train,preds_train_l),\n",
    "                            r2(y_true_val,preds_val_l)]\n",
    "results_actual['XGBoost_MOR'] = ['Vanilla',\n",
    "                            sMAPE(y_true_train, preds_train_xg),\n",
    "                            sMAPE(y_true_val, preds_val_xg),\n",
    "                            r2(y_true_train,preds_train_xg),\n",
    "                            r2(y_true_val,preds_val_xg)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>SMAPE_train</th>\n",
       "      <th>SMAPE_val</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NEMO</th>\n",
       "      <td>None</td>\n",
       "      <td>16.03</td>\n",
       "      <td>16.922</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>3.021</td>\n",
       "      <td>5.869</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso1</th>\n",
       "      <td>{'num_features': 5}</td>\n",
       "      <td>3.367</td>\n",
       "      <td>5.056</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso2</th>\n",
       "      <td>{'price_day_ahead': False}</td>\n",
       "      <td>11.811</td>\n",
       "      <td>32.664</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>1.248</td>\n",
       "      <td>6.668</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost1</th>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>2.465</td>\n",
       "      <td>5.85</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost2</th>\n",
       "      <td>{'max_depth': 2, 'price_day_ahead': False}</td>\n",
       "      <td>4.331</td>\n",
       "      <td>27.241</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost3</th>\n",
       "      <td>{'max_depth': 16, 'price_day_ahead': False}</td>\n",
       "      <td>0.026</td>\n",
       "      <td>24.84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn1</th>\n",
       "      <td>1-to-1</td>\n",
       "      <td>3.332</td>\n",
       "      <td>3.88</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn2</th>\n",
       "      <td>1-to-1, price_day_ahead:False</td>\n",
       "      <td>7.139</td>\n",
       "      <td>21.382</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn3</th>\n",
       "      <td>24-to-24</td>\n",
       "      <td>4.096</td>\n",
       "      <td>4.301</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn4</th>\n",
       "      <td>LSTM, 7-day input</td>\n",
       "      <td>3.439</td>\n",
       "      <td>7.123</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn5</th>\n",
       "      <td>LSTM, 7-day input</td>\n",
       "      <td>3.873</td>\n",
       "      <td>7.499</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn6</th>\n",
       "      <td>dnn-lstm, 1-day input</td>\n",
       "      <td>3.931</td>\n",
       "      <td>7.67</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso_MOR</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>4.249187</td>\n",
       "      <td>4.117137</td>\n",
       "      <td>0.975298</td>\n",
       "      <td>0.971797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost_MOR</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>3.77565</td>\n",
       "      <td>4.391497</td>\n",
       "      <td>0.992147</td>\n",
       "      <td>0.971994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Parameters SMAPE_train  \\\n",
       "NEMO                                                None       16.03   \n",
       "Lasso                                            Vanilla       3.021   \n",
       "Lasso1                               {'num_features': 5}       3.367   \n",
       "Lasso2                        {'price_day_ahead': False}      11.811   \n",
       "XGBoost                                          Vanilla       1.248   \n",
       "XGBoost1                                {'max_depth': 2}       2.465   \n",
       "XGBoost2      {'max_depth': 2, 'price_day_ahead': False}       4.331   \n",
       "XGBoost3     {'max_depth': 16, 'price_day_ahead': False}       0.026   \n",
       "nn1                                               1-to-1       3.332   \n",
       "nn2                        1-to-1, price_day_ahead:False       7.139   \n",
       "nn3                                             24-to-24       4.096   \n",
       "nn4                                    LSTM, 7-day input       3.439   \n",
       "nn5                                    LSTM, 7-day input       3.873   \n",
       "nn6                                dnn-lstm, 1-day input       3.931   \n",
       "Lasso_MOR                                        Vanilla    4.249187   \n",
       "XGBoost_MOR                                      Vanilla     3.77565   \n",
       "\n",
       "            SMAPE_val  r2_train    r2_val  \n",
       "NEMO           16.922     0.954     0.971  \n",
       "Lasso           5.869     0.977     0.973  \n",
       "Lasso1          5.056     0.971     0.969  \n",
       "Lasso2         32.664     0.676     0.557  \n",
       "XGBoost         6.668     0.996     0.968  \n",
       "XGBoost1         5.85     0.984      0.97  \n",
       "XGBoost2       27.241     0.953     0.427  \n",
       "XGBoost3        24.84       1.0     0.403  \n",
       "nn1              3.88     0.985     0.979  \n",
       "nn2            21.382     0.906     0.467  \n",
       "nn3             4.301     0.976     0.974  \n",
       "nn4             7.123     0.964     0.917  \n",
       "nn5             7.499     0.954     0.914  \n",
       "nn6              7.67     0.961     0.975  \n",
       "Lasso_MOR    4.117137  0.975298  0.971797  \n",
       "XGBoost_MOR  4.391497  0.992147  0.971994  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_actual.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there was an increase in performance of the best Lasso and XGBoost model, these models did not outperform the best neural network in either SMAPE nor r-squared.\n",
    "\n",
    "## Final Model Evaluation\n",
    "___\n",
    "Since all the models fit have performed extremely well, I'll selected the most interpretable model: Lasso.  In particular, the Lasso model with only five features is extremely simple, cut SMAPE by about a third, and increased r-squared.  Below, I'll evaluate lasso1 on the test set (2021)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/Lasso1.pickle', 'rb') as file:\n",
    "    lasso1 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     SMAPE     R2\n",
      "Final Model 2021:    3.155    0.997\n",
      "NEMO 2021:           10.743   0.998\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training (2015-19) and testing (2021)\n",
    "X_train, y_train, X_test, y_test = split_data(df_lr.loc[:'2019' and '2021'], 2021, 'price_actual')\n",
    "cols = ['humidities_bilbao_lag', 'oil_lag', 'renewable_lag', 'waste_lag', 'price_day_ahead']\n",
    "\n",
    "# Compute Metrics\n",
    "results = compute_metrics(lasso1, 'Vanilla', (X_train[cols], y_train), (X_test[cols], y_test))\n",
    "NEMO_2020_SMAPE = round(sMAPE(df_lag.loc['2021', 'price_actual'], df_lag.loc['2021', 'price_day_ahead']), 3)\n",
    "NEMO_2020_R2 = round(r2(df_lag.loc['2021', 'price_actual'], df_lag.loc['2021', 'price_day_ahead']), 3)\n",
    "print('                     SMAPE     R2')\n",
    "print('Final Model 2021:', '  ', results[2], '  ',results[4])\n",
    "print('NEMO 2021:', '         ', NEMO_2020_SMAPE, ' ',NEMO_2020_R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the metrics on the test set (2021), we found that the model reduced the SMAPE error by about a third down to 3.1 %.  The r-squared remained virtually the same.\n",
    "\n",
    "Below, I'll create a new dataframe to display the coefficients of the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create results dataframe for display\n",
    "df_results = pd.DataFrame({'Coefficients':lasso1.coef_}, index=X_train[cols].columns)\n",
    "df_results['key'] = df_results.Coefficients.apply(lambda x: 'Negative' if x < 0 else 'Positive')\n",
    "df_results.Coefficients = df_results.Coefficients.apply(lambda x: round(x,3))\n",
    "df_results['magnitude'] = df_results.Coefficients.apply(lambda x: abs(x))\n",
    "df_results.sort_values(by='magnitude', ascending=False, inplace=True)\n",
    "\n",
    "\n",
    "sns.set_context('notebook')\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "fig\n",
    "ax.set_xlim(-.2,1.1)\n",
    "sns.barplot(\n",
    "    y=df_results.index,\n",
    "    x=df_results.Coefficients,\n",
    "    data=df_results,\n",
    "    hue='key',\n",
    "    dodge=False,\n",
    ");\n",
    "plt.xticks();\n",
    "ax.bar_label(ax.containers[0])\n",
    "ax.bar_label(ax.containers[1]);\n",
    "plt.title('Final Model Coefficients');\n",
    "plt.ylabel('Features');\n",
    "plt.axvline(x = 0, color = 'black');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "In the above plot, it is no surprise that `price_day_ahead` dominates the model.  The other features nudge that final price up or down. The model says that as renewable generation (feature represents other renewable outside major solar and wind) and waste generation decrease, the final price increases.  As generation from oil increases, the price also increases.  Finally  as the humidity in Bilbao decreases the price tends to decrease.\n",
    "\n",
    "Next I'll plot the final model predictions, the `price_day_ahead` and the actual price over a week.  In addition , I'll plot the final model's residual and the `price_day_ahead` residual over time.  This should give us a better sense for how well our model did compared to the benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add model prediction, price_day_ahead, and actuals to dataframe\n",
    "preds_final = lasso1.predict(X_test[cols])\n",
    "predictions = pd.DataFrame({'lasso1':preds_final,\n",
    "                           'NEMO':X_test.price_day_ahead,\n",
    "                           'actual': y_test})\n",
    "\n",
    "# Plot each over time\n",
    "predictions.loc['2021-1-1': '2021-1-7', ['NEMO', 'lasso1', 'actual']].plot(figsize=(15,5), color=['gray', 'orange', 'g']);\n",
    "plt.xlabel('Date');\n",
    "plt.ylabel('Price (Euros)');\n",
    "plt.title('Test Set Results');\n",
    "\n",
    "# Get residuals\n",
    "predictions['NEMO_resid'] = predictions.NEMO - predictions.actual\n",
    "predictions['lasso1_resid'] = predictions.lasso1 - predictions.actual\n",
    "\n",
    "#Plot\n",
    "predictions.loc['2021-1-1':'2021-1-7', ['NEMO_resid', 'lasso1_resid']].plot(figsize=(15,5), color=['gray', 'orange']);\n",
    "plt.xlabel('Date');\n",
    "plt.ylabel('Price Difference from Actual');\n",
    "plt.title('Test Set Residuals');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "___\n",
    "This project set out to see if the price was predictable from generation, transmission, weather, and price day-ahead data. In the end, the price day-ahead was a strong predictor of tomorrow's price, dominating the model. However, there are other features that nudge the price either up or down. On days when renewable generation, waste generation, and the humidity in Bilbao are up the final price tends to be cheaper.  On days when energy generation from oil is up, the final price tends to be more expensive.\n",
    "\n",
    "The other components of final price were modeled but only three could be easily predicted with the data.  These components are `price_capacity_payment`, `price_PBF_tech`, and `price_sec_reserve`.\n",
    "\n",
    "On the whole, most of the generation weather, and transmission variables were not helpful in predicting the final energy price.\n",
    "\n",
    "### Next Steps\n",
    "___\n",
    "Since most of the data in this project is very noisy, it would be beneficial to sit down with an expert who understands the calculation of `price_day_ahead`. Using some of the features that the NEMOs use to come up with this price would be useful in machine learning models. \n",
    "\n",
    "In combination with the appropriate data a GRU neural network ensemble, and convolutional neural network (CNNs) ensemble.  GRU NNs are similar to LSTM network, but more computationally more efficient. CNN are typically used for image classification but could be adapted for multi-step price forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
