{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project Title\n",
    "___\n",
    "**Author**: Evan Holder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview <a class=\"anchor\" id=\"Overview\"></a>\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Problem <a class=\"anchor\" id=\"Business-Problem\"></a>\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection <a class=\"anchor\" id=\"Data-Collection\"></a>\n",
    "___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning <a class=\"anchor\" id=\"Data-Cleaning\"></a>\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and Functions  <a class=\"anchor\" id=\"Import-Libraries-and-Funtions\"></a>\n",
    "___\n",
    "Data manipulation, cleaning, massaging: pandas, numpy<br>\n",
    "Modeling: sklearn, keras<br>\n",
    "Plotting: matplotlib<br>\n",
    "Custom functions: function.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for data cleaning, massaging:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "# Modeling Libraries\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, models, regularizers\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Save Models\n",
    "import pickle\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Manipulate directories \n",
    "import os\n",
    "\n",
    "# Import custom functions\n",
    "os.chdir('../scripts')\n",
    "from functions import split_data, sMAPE, SMAPE, compute_metrics, r2,impute_immediate_mean\n",
    "from functions import resample, plot_metric_range, compile_fit, ensemble_nn\n",
    "os.chdir('../notebooks')\n",
    "\n",
    "#from tensorflow.keras.preprocessing import timeseries_dataset_from_array\n",
    "#from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "#from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data <a class=\"anchor\" id=\"Import-Data\"></a>\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "df_lag = pd.read_csv('../data/clean/df_clean_lag.csv', index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation <a class=\"anchor\" id=\"Data-Preparation\"></a>\n",
    "___\n",
    "In this project, we'll focus on three main algorithms types: Lasso Regression, XGBoost, and Neural Networks.  We'll need to prepare the data in slightly different ways for each of the these model types. Much of the preprocessing was already taken care of as part of the steps list above in [Data Cleaning](#Data-Cleaning). The remaining steps are model specific, and so are prepared below:<br><br>\n",
    "**Lasso Regression**:<br>\n",
    "* Encode the categorical features\n",
    "* Remove mulitcolinearities\n",
    "\n",
    "**Neural Networks**:<br>\n",
    "* Encode the categorical features\n",
    "\n",
    "**XGBoost**: All preprocessing steps were previously \n",
    "While not required, we'll scale the continuous features for neural networks. And finally for lasso regression, it would be wise to remove any multicolinearities in the data. In order to run each of these models, I'll copy the dataset and process\n",
    "\n",
    "### Encode Catergorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Categorical columns\n",
    "categorical = df_lag.select_dtypes(include='object')\n",
    "\n",
    "# Instationate wind_dir_coder LabelEncoder, fit\n",
    "wind_dir_coder = LabelEncoder()\n",
    "wind_dir_coder.fit(df_lag['wind_madrid_lag'])\n",
    "\n",
    "# Transform wind_direction cols\n",
    "for col in categorical.filter(regex='wind').columns:\n",
    "    df_lag[col] = wind_dir_coder.transform(df_lag[col])\n",
    "    \n",
    "\n",
    "# Stack condition columns into single col\n",
    "stacked_conditions = categorical.filter(regex='condition').stack()\n",
    "\n",
    "# Instantiate condition_coder LabelEncoder, fit on stacked conditions\n",
    "condition_coder = LabelEncoder()\n",
    "condition_coder.fit(stacked_conditions)\n",
    "\n",
    "# Transform condition cols\n",
    "for col in categorical.filter(regex='condition').columns:\n",
    "    df_lag[col] = condition_coder.transform(df_lag[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get price components not to be used in modeling\n",
    "price_cols = df_lag.filter(regex='price').columns.to_list()[1:]\n",
    "price_cols.remove('price_day_ahead')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Continuous Features\n",
    "For neural networks, continuous features do not necessarily need to be scaled. However according to this [article](https://www.sciencedirect.com/science/article/pii/S030626191830196X#s0235), which uses neural networks to predict electrical prices, scaling your continuous features generally increases accuracy of deep learning models on the validation set.  We'll give it a go here and scale the the continuos features between [-1,1] for the neural networks we'll train later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the dataframe for neural networks\n",
    "df_nn = df_lag.drop(columns=price_cols).copy()\n",
    "continuous = df_nn.select_dtypes(exclude='object').filter(regex='^(?!.*price).*').columns\n",
    "\n",
    "# Get rid of negatives\n",
    "time = dt.datetime(2021,3,24,22)\n",
    "df_nn.loc[time, 'dew_point_bilbao_lag'] = impute_immediate_mean(df_nn['dew_point_bilbao_lag'], time)\n",
    "\n",
    "# Rescale data [-1,1]\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "df_nn[continuous] = scaler.fit_transform(df_nn[continuous])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multicolinearity\n",
    "One of the assumptions for regression is that featu\n",
    "res do not contain multicolinearities.  In this section, we'll investigate the predictors and eliminate any multicolinearities in preparation for a lasso regression. We'll need to find out which features are correlated with each other, and remove some of them to rid our dataset of multicolinearities. The steps are outlined below:\n",
    "1. Copy the dataframe, we'll modify this dataset for use in lasso regression\n",
    "2. Get the correlations between predictors, sort them in descending order\n",
    "3. Get the correlations between each individual predictor and the response variable\n",
    "4. Get the features which have a correlation greater than 0.8, add the feature which correlates less with price_actual to the drop list\n",
    "5. Drop the features in the drop list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy dataset for lasso regression specific preparation\n",
    "df_lr = df_lag.drop(columns=price_cols).copy()\n",
    "\n",
    "# Create correlation matrix predictors to predictors\n",
    "corr = df_lr.drop(columns='price_actual').corr().abs().stack().reset_index().sort_values(0, ascending=False)\n",
    "corr.rename(columns={0:'cor'}, inplace=True)  # Rename correlation column\n",
    "corr = corr.loc[corr['cor']!=1]  # remove correlations between same variables\n",
    "corr.drop_duplicates(subset='cor', inplace=True) # remove duplicate correlations\n",
    "corr.reset_index(drop=True, inplace=True) # Reset the index\n",
    "corr.cor =corr.cor.apply(lambda x: round(x,3))  # Round\n",
    "\n",
    "# Create correlation matrix predictors to response variable\n",
    "corr_price = df_lr.corr()['price_actual'].reset_index().sort_values('price_actual', ascending=False)\n",
    "corr_price = corr_price.loc[corr_price['price_actual']!=1] # remove correlations between same variables\n",
    "corr_price.reset_index(drop=True, inplace=True)  # Reset the index\n",
    "\n",
    "\n",
    "drop = []\n",
    "\n",
    "# For each feature pair where corr > 0.8, add feature with lower corr to price_actual to drop list\n",
    "for row in range(len(corr.loc[corr.cor>.8])):\n",
    "    var1 = corr.loc[row,'level_0'] # Get var1 name\n",
    "    var2 = corr.loc[row,'level_1'] # Get var2 name\n",
    "    var1_corr = float(corr_price.loc[corr_price['index'] == var1, 'price_actual'])  # Get var1 corr\n",
    "    var2_corr = float(corr_price.loc[corr_price['index'] == var2, 'price_actual'])  # Get var2 corr\n",
    "    \n",
    "    # Add the lower correlation to the drop list\n",
    "    if var1_corr > var2_corr:\n",
    "        drop.append(var2)\n",
    "    else:\n",
    "        drop.append(var1)\n",
    "        \n",
    "# Drop the features in the drop listi\n",
    "df_lr.drop(columns=drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xg = df_lag.drop(columns=price_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling `price_actual` <a class=\"anchor\" id=\"Modeling-`price_actual`\"></a>\n",
    "___\n",
    "\n",
    "Create results_actual dataframe to hold results\n",
    "\n",
    "Add TSO (price_day_ahead) as benchmark prediction to beat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Parameters</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMAPE_train</th>\n",
       "      <td>16.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMAPE_val</th>\n",
       "      <td>16.922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_train</th>\n",
       "      <td>0.954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_val</th>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                TSO\n",
       "Parameters     None\n",
       "SMAPE_train   16.03\n",
       "SMAPE_val    16.922\n",
       "r2_train      0.954\n",
       "r2_val        0.971"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Benchmark results\n",
    "TSO_train = df_lag.loc[:'2019', 'price_day_ahead']\n",
    "TSO_val = df_lag.loc['2020', 'price_day_ahead']\n",
    "\n",
    "actual_train = df_lag.loc[:'2019', 'price_actual']\n",
    "actual_val = df_lag.loc['2020', 'price_actual']\n",
    "\n",
    "# Create dataframe\n",
    "results_actual = pd.DataFrame(index=['Parameters','SMAPE_train', 'SMAPE_val', 'r2_train', 'r2_val'])\n",
    "\n",
    "# Add the baseline TSO predictions\n",
    "results_actual['TSO'] = ['None',\n",
    "                                    round(sMAPE(actual_train, TSO_train), 3),\n",
    "                                    round(sMAPE(actual_val, TSO_val), 3),\n",
    "                                    round(r2(actual_train, TSO_train), 3), \n",
    "                                    round(r2(actual_val, TSO_val),3)]\n",
    "results_actual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression\n",
    "To begin we'll split the data into training (2015-2019) and validation (2020). Next, we'll fit a Vanilla lasso regression model with max_iter=10000 to make sure that the model converges.  And finally, we'll compute the output and add it to the results table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>SMAPE_train</th>\n",
       "      <th>SMAPE_val</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TSO</th>\n",
       "      <td>None</td>\n",
       "      <td>16.03</td>\n",
       "      <td>16.922</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>3.021</td>\n",
       "      <td>5.869</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Parameters SMAPE_train SMAPE_val r2_train r2_val\n",
       "TSO         None       16.03    16.922    0.954  0.971\n",
       "Lasso    Vanilla       3.021     5.869    0.977  0.973"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data\n",
    "X_train, y_train, X_val, y_val = split_data(df_lr, 2020, 'price_actual')\n",
    "\n",
    "# Instatiate and fit model on \n",
    "lasso = Lasso(max_iter=10000)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Add results of vanilla lasso to dataframe\n",
    "results_actual['Lasso'] = compute_metrics(lasso, 'Vanilla', (X_train, y_train), (X_val, y_val))\n",
    "\n",
    "# Save model\n",
    "with open('../models/Lasso.pickle', 'wb') as f:\n",
    "    pickle.dump(lasso, f)\n",
    "\n",
    "# Preview\n",
    "results_actual.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/lasso_vanilla.pickle', 'rb') as file:\n",
    "    lasso_test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The very first model performed extremely well.  That's great, but it also isn't suprising given that we used the `price_day_ahead` as a predictor which has an r-squared value of 0.971 on the validation set.  The model outperformed the TSO predictions in SMAPE and even increased r-squared by a small margin. Increase r-squared must mean that some of the other features were important in our prediction of `price_actual`.  Below is a plot of the coefficients with the greatest magnitude.\n",
    "\n",
    "---insert plot here---\n",
    "\n",
    "It appears that renewable generation and waste generation have a negative relationship with `price_actual` (renewable and waste increase, results in price decrease).  Other than these, it appears that the other features have very little influence on the final price.  \n",
    "\n",
    "**Recursive Feature Elimination**<br>\n",
    "As part of the [Lasso](https://github.com/EvanHolder/capstone/blob/main/notebooks/LassoRegression.ipynb) notebook, I ran a recursive feature elimination to see how the model performs with varying amounts of features in the model.  I started with a single feature (`price_day_ahead`), trained a model, and computed its metrics. Then I iteratively added in the next most important feature, trained the new model, and computed its metrics.  This process was repeated until all features were added back into the training set and the metrics were plotted as below.\n",
    "\n",
    "![RFE_LassoRegression](../images/RFE_LassoRegression.png)\n",
    "\n",
    "As shown above, when trained on top five features, the model minimizes r-squared.  Below, I'll train the model on these top five features (`price_day_ahead`, `renewable_lag`,`waste_lag`,`oil_lag`,`humidities_seville_lag`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>SMAPE_train</th>\n",
       "      <th>SMAPE_val</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TSO</th>\n",
       "      <td>None</td>\n",
       "      <td>16.03</td>\n",
       "      <td>16.922</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>3.021</td>\n",
       "      <td>5.869</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso1</th>\n",
       "      <td>{'num_features': 5}</td>\n",
       "      <td>4.134</td>\n",
       "      <td>8.354</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso2</th>\n",
       "      <td>{'price_day_ahead': False}</td>\n",
       "      <td>11.811</td>\n",
       "      <td>32.664</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>1.248</td>\n",
       "      <td>6.668</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost1</th>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>2.465</td>\n",
       "      <td>5.85</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost2</th>\n",
       "      <td>{'max_depth': 2, 'price_day_ahead': False}</td>\n",
       "      <td>4.331</td>\n",
       "      <td>27.241</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost3</th>\n",
       "      <td>{'max_depth': 16, 'price_day_ahead': False}</td>\n",
       "      <td>0.026</td>\n",
       "      <td>24.84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn_1-1</th>\n",
       "      <td>{'Dense1': 59, 'Dense2': 239, 'Dense3': 1}</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn-24-24</th>\n",
       "      <td>{'Dense1': 59, 'Dense2': 239, 'Dense3': 162, '...</td>\n",
       "      <td>3.871</td>\n",
       "      <td>3.738</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM</th>\n",
       "      <td>{'LSTM1': 60, 'LSTM2': 24, 'TimeDistributed': ...</td>\n",
       "      <td>8.805</td>\n",
       "      <td>10.646</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM1</th>\n",
       "      <td>{'LSTM1': 83, 'LSTM2': 24, 'TimeDistributed': ...</td>\n",
       "      <td>6.062</td>\n",
       "      <td>9.337</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Parameters SMAPE_train  \\\n",
       "TSO                                                    None       16.03   \n",
       "Lasso                                               Vanilla       3.021   \n",
       "Lasso1                                  {'num_features': 5}       4.134   \n",
       "Lasso2                           {'price_day_ahead': False}      11.811   \n",
       "XGBoost                                             Vanilla       1.248   \n",
       "XGBoost1                                   {'max_depth': 2}       2.465   \n",
       "XGBoost2         {'max_depth': 2, 'price_day_ahead': False}       4.331   \n",
       "XGBoost3        {'max_depth': 16, 'price_day_ahead': False}       0.026   \n",
       "nn_1-1           {'Dense1': 59, 'Dense2': 239, 'Dense3': 1}       200.0   \n",
       "nn-24-24  {'Dense1': 59, 'Dense2': 239, 'Dense3': 162, '...       3.871   \n",
       "LSTM      {'LSTM1': 60, 'LSTM2': 24, 'TimeDistributed': ...       8.805   \n",
       "LSTM1     {'LSTM1': 83, 'LSTM2': 24, 'TimeDistributed': ...       6.062   \n",
       "\n",
       "         SMAPE_val r2_train r2_val  \n",
       "TSO         16.922    0.954  0.971  \n",
       "Lasso        5.869    0.977  0.973  \n",
       "Lasso1       8.354    0.954  0.971  \n",
       "Lasso2      32.664    0.676  0.557  \n",
       "XGBoost      6.668    0.996  0.968  \n",
       "XGBoost1      5.85    0.984   0.97  \n",
       "XGBoost2    27.241    0.953  0.427  \n",
       "XGBoost3     24.84      1.0  0.403  \n",
       "nn_1-1       200.0      NaN    NaN  \n",
       "nn-24-24     3.738    0.981  0.978  \n",
       "LSTM        10.646    0.787  0.804  \n",
       "LSTM1        9.337     0.89  0.866  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Important Features\n",
    "train_cols = ['humidities_bilbao_lag', 'oil_lag', 'renewable_lag', 'waste_lag', 'price_day_ahead']\n",
    "\n",
    "# Instatiate and fit model on \n",
    "lasso1 = Lasso(max_iter=10000)\n",
    "lasso1.fit(X_train[train_cols], y_train)\n",
    "\n",
    "# Add results of vanilla lasso to dataframe\n",
    "results_actual['Lasso1'] = compute_metrics(lasso1, {'num_features':5}, (X_train[train_cols], y_train), (X_val[train_cols], y_val))\n",
    "\n",
    "# Save model\n",
    "with open('../models/Lasso1.pickle', 'wb') as f:\n",
    "    pickle.dump(lasso1, f)\n",
    "    \n",
    "# Preview\n",
    "results_actual.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>SMAPE_train</th>\n",
       "      <th>SMAPE_val</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TSO</th>\n",
       "      <td>None</td>\n",
       "      <td>16.03</td>\n",
       "      <td>16.922</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>3.021</td>\n",
       "      <td>5.869</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso1</th>\n",
       "      <td>{'num_features': 5}</td>\n",
       "      <td>3.367</td>\n",
       "      <td>5.056</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso2</th>\n",
       "      <td>{'price_day_ahead': False}</td>\n",
       "      <td>11.811</td>\n",
       "      <td>32.664</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Parameters SMAPE_train SMAPE_val r2_train r2_val\n",
       "TSO                           None       16.03    16.922    0.954  0.971\n",
       "Lasso                      Vanilla       3.021     5.869    0.977  0.973\n",
       "Lasso1         {'num_features': 5}       3.367     5.056    0.971  0.969\n",
       "Lasso2  {'price_day_ahead': False}      11.811    32.664    0.676  0.557"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop 'price_day_ahead'\n",
    "X_train1, X_val1 = X_train.drop(columns='price_day_ahead'), X_val.drop(columns='price_day_ahead')\n",
    "\n",
    "# Instatiate and fit model on \n",
    "lasso2 = Lasso(max_iter=10000)\n",
    "lasso2.fit(X_train1, y_train)\n",
    "\n",
    "# Add results of vanilla lasso to dataframe\n",
    "results_actual['Lasso2'] = compute_metrics(lasso2, {'price_day_ahead':False}, (X_train1, y_train), (X_val1, y_val))\n",
    "\n",
    "# Save Model\n",
    "with open('../models/Lasso2.pickle', 'wb') as f:\n",
    "    pickle.dump(lasso2, f)\n",
    "\n",
    "# Preview\n",
    "results_actual.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>SMAPE_train</th>\n",
       "      <th>SMAPE_val</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TSO</th>\n",
       "      <td>None</td>\n",
       "      <td>16.03</td>\n",
       "      <td>16.922</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>3.021</td>\n",
       "      <td>5.869</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso1</th>\n",
       "      <td>{'num_features': 5}</td>\n",
       "      <td>3.367</td>\n",
       "      <td>5.056</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso2</th>\n",
       "      <td>{'price_day_ahead': False}</td>\n",
       "      <td>11.811</td>\n",
       "      <td>32.664</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>1.248</td>\n",
       "      <td>6.668</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Parameters SMAPE_train SMAPE_val r2_train r2_val\n",
       "TSO                            None       16.03    16.922    0.954  0.971\n",
       "Lasso                       Vanilla       3.021     5.869    0.977  0.973\n",
       "Lasso1          {'num_features': 5}       3.367     5.056    0.971  0.969\n",
       "Lasso2   {'price_day_ahead': False}      11.811    32.664    0.676  0.557\n",
       "XGBoost                     Vanilla       1.248     6.668    0.996  0.968"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data\n",
    "X_train, y_train, X_val, y_val = split_data(df_xg, 2020, 'price_actual')\n",
    "\n",
    "# Instantiate and fit XGBRegressor\n",
    "xg = XGBRegressor(random_state=17)\n",
    "xg.fit(X_train, y_train)\n",
    "\n",
    "# Compute sMAPE, r2 and add to the table\n",
    "results_actual['XGBoost'] = compute_metrics(xg, 'Vanilla',(X_train, y_train), (X_val, y_val))\n",
    "\n",
    "# Save Model\n",
    "with open('../models/XGBoost.pickle', 'wb') as f:\n",
    "    pickle.dump(xg, f)\n",
    "\n",
    "# Preview\n",
    "results_actual.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- write something about trying out different parameter ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>SMAPE_train</th>\n",
       "      <th>SMAPE_val</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TSO</th>\n",
       "      <td>None</td>\n",
       "      <td>16.03</td>\n",
       "      <td>16.922</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>3.021</td>\n",
       "      <td>5.869</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso1</th>\n",
       "      <td>{'num_features': 5}</td>\n",
       "      <td>3.367</td>\n",
       "      <td>5.056</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso2</th>\n",
       "      <td>{'price_day_ahead': False}</td>\n",
       "      <td>11.811</td>\n",
       "      <td>32.664</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>1.248</td>\n",
       "      <td>6.668</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost1</th>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>2.465</td>\n",
       "      <td>5.85</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Parameters SMAPE_train SMAPE_val r2_train r2_val\n",
       "TSO                             None       16.03    16.922    0.954  0.971\n",
       "Lasso                        Vanilla       3.021     5.869    0.977  0.973\n",
       "Lasso1           {'num_features': 5}       3.367     5.056    0.971  0.969\n",
       "Lasso2    {'price_day_ahead': False}      11.811    32.664    0.676  0.557\n",
       "XGBoost                      Vanilla       1.248     6.668    0.996  0.968\n",
       "XGBoost1            {'max_depth': 2}       2.465      5.85    0.984   0.97"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data\n",
    "X_train, y_train, X_val, y_val = split_data(df_xg, 2020, 'price_actual')\n",
    "\n",
    "# Instantiate and fit XGBRegressor\n",
    "xg1 = XGBRegressor(random_state=17, max_depth=2)\n",
    "xg1.fit(X_train, y_train)\n",
    "\n",
    "# Compute sMAPE, r2 and add to the table\n",
    "results_actual['XGBoost1'] = compute_metrics(xg1, {'max_depth':2},(X_train, y_train), (X_val, y_val))\n",
    "\n",
    "# Save Model\n",
    "with open('../models/XGBoost1.pickle', 'wb') as f:\n",
    "    pickle.dump(xg1, f)\n",
    "\n",
    "# Preview\n",
    "results_actual.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>price_day_ahead</th>\n",
       "      <td>0.735356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>biomass_lag</th>\n",
       "      <td>0.046353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>renewable_lag</th>\n",
       "      <td>0.037915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>load_forecast</th>\n",
       "      <td>0.035208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coal_lag</th>\n",
       "      <td>0.034028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waste_lag</th>\n",
       "      <td>0.020222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transmission_fs_lag</th>\n",
       "      <td>0.008342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dew_point_seville_lag</th>\n",
       "      <td>0.007706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>solar_lag</th>\n",
       "      <td>0.006477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reservoir_lag</th>\n",
       "      <td>0.006204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       importance\n",
       "price_day_ahead          0.735356\n",
       "biomass_lag              0.046353\n",
       "renewable_lag            0.037915\n",
       "load_forecast            0.035208\n",
       "coal_lag                 0.034028\n",
       "waste_lag                0.020222\n",
       "transmission_fs_lag      0.008342\n",
       "dew_point_seville_lag    0.007706\n",
       "solar_lag                0.006477\n",
       "reservoir_lag            0.006204"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp = pd.DataFrame({'importance':xg1.feature_importances_},\n",
    "                   index=X_train.columns).sort_values(by='importance', ascending=False)\n",
    "imp.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model without `price_day_ahead`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>SMAPE_train</th>\n",
       "      <th>SMAPE_val</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TSO</th>\n",
       "      <td>None</td>\n",
       "      <td>16.03</td>\n",
       "      <td>16.922</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>3.021</td>\n",
       "      <td>5.869</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso1</th>\n",
       "      <td>{'num_features': 5}</td>\n",
       "      <td>3.367</td>\n",
       "      <td>5.056</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso2</th>\n",
       "      <td>{'price_day_ahead': False}</td>\n",
       "      <td>11.811</td>\n",
       "      <td>32.664</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>1.248</td>\n",
       "      <td>6.668</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost1</th>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>2.465</td>\n",
       "      <td>5.85</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost2</th>\n",
       "      <td>{'max_depth': 2, 'price_day_ahead': False}</td>\n",
       "      <td>4.331</td>\n",
       "      <td>27.241</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Parameters SMAPE_train SMAPE_val  \\\n",
       "TSO                                             None       16.03    16.922   \n",
       "Lasso                                        Vanilla       3.021     5.869   \n",
       "Lasso1                           {'num_features': 5}       3.367     5.056   \n",
       "Lasso2                    {'price_day_ahead': False}      11.811    32.664   \n",
       "XGBoost                                      Vanilla       1.248     6.668   \n",
       "XGBoost1                            {'max_depth': 2}       2.465      5.85   \n",
       "XGBoost2  {'max_depth': 2, 'price_day_ahead': False}       4.331    27.241   \n",
       "\n",
       "         r2_train r2_val  \n",
       "TSO         0.954  0.971  \n",
       "Lasso       0.977  0.973  \n",
       "Lasso1      0.971  0.969  \n",
       "Lasso2      0.676  0.557  \n",
       "XGBoost     0.996  0.968  \n",
       "XGBoost1    0.984   0.97  \n",
       "XGBoost2    0.953  0.427  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop price_day_ahead\n",
    "X_train1, X_val1 = X_train.drop(columns='price_day_ahead'), X_val.drop(columns='price_day_ahead')\n",
    "\n",
    "\n",
    "# Instantiate and fit XGBRegressor\n",
    "xg2 = XGBRegressor(random_state=17)\n",
    "xg2.fit(X_train1, y_train)\n",
    "\n",
    "# Compute sMAPE, r2 and add to the table\n",
    "results_actual['XGBoost2'] = compute_metrics(xg2, {'max_depth':2,\n",
    "                                                   'price_day_ahead':False},(X_train1, y_train), (X_val1, y_val))\n",
    "# Save Model\n",
    "with open('../models/XGBoost2.pickle', 'wb') as f:\n",
    "    pickle.dump(xg2, f)\n",
    "\n",
    "# Preview\n",
    "results_actual.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- something about tuning parameters without `price_day_ahead`---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>SMAPE_train</th>\n",
       "      <th>SMAPE_val</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TSO</th>\n",
       "      <td>None</td>\n",
       "      <td>16.03</td>\n",
       "      <td>16.922</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>3.021</td>\n",
       "      <td>5.869</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso1</th>\n",
       "      <td>{'num_features': 5}</td>\n",
       "      <td>3.367</td>\n",
       "      <td>5.056</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso2</th>\n",
       "      <td>{'price_day_ahead': False}</td>\n",
       "      <td>11.811</td>\n",
       "      <td>32.664</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>1.248</td>\n",
       "      <td>6.668</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost1</th>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>2.465</td>\n",
       "      <td>5.85</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost2</th>\n",
       "      <td>{'max_depth': 2, 'price_day_ahead': False}</td>\n",
       "      <td>4.331</td>\n",
       "      <td>27.241</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost3</th>\n",
       "      <td>{'max_depth': 16, 'price_day_ahead': False}</td>\n",
       "      <td>0.026</td>\n",
       "      <td>24.84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Parameters SMAPE_train SMAPE_val  \\\n",
       "TSO                                              None       16.03    16.922   \n",
       "Lasso                                         Vanilla       3.021     5.869   \n",
       "Lasso1                            {'num_features': 5}       3.367     5.056   \n",
       "Lasso2                     {'price_day_ahead': False}      11.811    32.664   \n",
       "XGBoost                                       Vanilla       1.248     6.668   \n",
       "XGBoost1                             {'max_depth': 2}       2.465      5.85   \n",
       "XGBoost2   {'max_depth': 2, 'price_day_ahead': False}       4.331    27.241   \n",
       "XGBoost3  {'max_depth': 16, 'price_day_ahead': False}       0.026     24.84   \n",
       "\n",
       "         r2_train r2_val  \n",
       "TSO         0.954  0.971  \n",
       "Lasso       0.977  0.973  \n",
       "Lasso1      0.971  0.969  \n",
       "Lasso2      0.676  0.557  \n",
       "XGBoost     0.996  0.968  \n",
       "XGBoost1    0.984   0.97  \n",
       "XGBoost2    0.953  0.427  \n",
       "XGBoost3      1.0  0.403  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit XGBRegressor\n",
    "xg3 = XGBRegressor(random_state=17, max_depth=16)\n",
    "xg3.fit(X_train1, y_train)\n",
    "\n",
    "# Compute sMAPE, r2 and add to the table\n",
    "results_actual['XGBoost3'] = compute_metrics(xg3,\n",
    "                                             {'max_depth':16, 'price_day_ahead':False},\n",
    "                                             (X_train1, y_train), \n",
    "                                             (X_val1, y_val))\n",
    "# Save Model\n",
    "with open('../models/XGBoost3.pickle', 'wb') as f:\n",
    "    pickle.dump(xg3, f)\n",
    "\n",
    "#Preview\n",
    "results_actual.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks (1-to-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data\n",
    "X_train, y_train, X_val, y_val = split_data(df_nn, 2020, 'price_actual')\n",
    "\n",
    "# Define input_shape\n",
    "input_shape = (X_train.shape[1],)\n",
    "\n",
    "# Instantiate model and build layers\n",
    "nn = models.Sequential()\n",
    "nn.add(layers.Dense(59, activation='relu', input_shape=input_shape))\n",
    "nn.add(layers.Dense(239, activation='relu'))\n",
    "nn.add(layers.Dense(162, activation='relu'))\n",
    "nn.add(layers.Dense(1, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1369/1369 [==============================] - 2s 1ms/step - loss: 56.7856 - SMAPE: 200.0000 - val_loss: 39.1089 - val_SMAPE: 200.0000\n",
      "Epoch 2/200\n",
      "1369/1369 [==============================] - ETA: 0s - loss: 56.7881 - SMAPE: 200.0000 - 2s 1ms/step - loss: 56.7856 - SMAPE: 200.0000 - val_loss: 39.1089 - val_SMAPE: 200.0000\n",
      "Epoch 3/200\n",
      "1369/1369 [==============================] - 2s 1ms/step - loss: 56.7857 - SMAPE: 200.0000 - val_loss: 39.1089 - val_SMAPE: 200.0000\n",
      "Epoch 4/200\n",
      "1369/1369 [==============================] - 2s 1ms/step - loss: 56.7856 - SMAPE: 200.0000 - val_loss: 39.1089 - val_SMAPE: 200.0000\n",
      "Epoch 5/200\n",
      "1369/1369 [==============================] - 2s 1ms/step - loss: 56.7856 - SMAPE: 200.0000 - val_loss: 39.1089 - val_SMAPE: 200.0000\n",
      "Epoch 6/200\n",
      "1369/1369 [==============================] - 2s 2ms/step - loss: 56.7857 - SMAPE: 200.0000 - val_loss: 39.1089 - val_SMAPE: 200.0000\n",
      "Epoch 7/200\n",
      "1369/1369 [==============================] - 2s 1ms/step - loss: 56.7857 - SMAPE: 200.0000 - val_loss: 39.1089 - val_SMAPE: 200.0000\n",
      "Epoch 8/200\n",
      "1369/1369 [==============================] - 2s 1ms/step - loss: 56.7857 - SMAPE: 200.0000 - val_loss: 39.1089 - val_SMAPE: 200.0000\n",
      "Epoch 9/200\n",
      "1369/1369 [==============================] - 2s 1ms/step - loss: 56.7856 - SMAPE: 200.0000 - val_loss: 39.1089 - val_SMAPE: 200.0000\n",
      "Epoch 10/200\n",
      "1369/1369 [==============================] - 2s 1ms/step - loss: 56.7856 - SMAPE: 200.0000 - val_loss: 39.1089 - val_SMAPE: 200.0000\n",
      "Epoch 11/200\n",
      "1369/1369 [==============================] - 2s 1ms/step - loss: 56.7856 - SMAPE: 200.0000 - val_loss: 39.1089 - val_SMAPE: 200.0000\n"
     ]
    }
   ],
   "source": [
    "nn1 = compile_fit(nn, (X_train,y_train), (X_val, y_val), patience=10,\n",
    "                  loss = tf.keras.metrics.mean_absolute_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\holde\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\holde\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2560: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>SMAPE_train</th>\n",
       "      <th>SMAPE_val</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TSO</th>\n",
       "      <td>None</td>\n",
       "      <td>16.03</td>\n",
       "      <td>16.922</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>3.021</td>\n",
       "      <td>5.869</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso1</th>\n",
       "      <td>{'num_features': 5}</td>\n",
       "      <td>3.367</td>\n",
       "      <td>5.056</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso2</th>\n",
       "      <td>{'price_day_ahead': False}</td>\n",
       "      <td>11.811</td>\n",
       "      <td>32.664</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>1.248</td>\n",
       "      <td>6.668</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost1</th>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>2.465</td>\n",
       "      <td>5.85</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost2</th>\n",
       "      <td>{'max_depth': 2, 'price_day_ahead': False}</td>\n",
       "      <td>4.331</td>\n",
       "      <td>27.241</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost3</th>\n",
       "      <td>{'max_depth': 16, 'price_day_ahead': False}</td>\n",
       "      <td>0.026</td>\n",
       "      <td>24.84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn_1-1</th>\n",
       "      <td>{'Dense1': 59, 'Dense2': 239, 'Dense3': 1}</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Parameters SMAPE_train SMAPE_val  \\\n",
       "TSO                                              None       16.03    16.922   \n",
       "Lasso                                         Vanilla       3.021     5.869   \n",
       "Lasso1                            {'num_features': 5}       3.367     5.056   \n",
       "Lasso2                     {'price_day_ahead': False}      11.811    32.664   \n",
       "XGBoost                                       Vanilla       1.248     6.668   \n",
       "XGBoost1                             {'max_depth': 2}       2.465      5.85   \n",
       "XGBoost2   {'max_depth': 2, 'price_day_ahead': False}       4.331    27.241   \n",
       "XGBoost3  {'max_depth': 16, 'price_day_ahead': False}       0.026     24.84   \n",
       "nn_1-1     {'Dense1': 59, 'Dense2': 239, 'Dense3': 1}       200.0     200.0   \n",
       "\n",
       "         r2_train r2_val  \n",
       "TSO         0.954  0.971  \n",
       "Lasso       0.977  0.973  \n",
       "Lasso1      0.971  0.969  \n",
       "Lasso2      0.676  0.557  \n",
       "XGBoost     0.996  0.968  \n",
       "XGBoost1    0.984   0.97  \n",
       "XGBoost2    0.953  0.427  \n",
       "XGBoost3      1.0  0.403  \n",
       "nn_1-1        NaN    NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'Dense1':59,\n",
    "          'Dense2':239,\n",
    "          'Dense3':162,\n",
    "          'Dense3':1}\n",
    "results_actual['nn_1-1'] = compute_metrics(nn1, params, (X_train,y_train), (X_val, y_val))\n",
    "\n",
    "# Save Model\n",
    "nn1.save('../models/nn1')\n",
    "\n",
    "# Preview\n",
    "results_actual.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks (24 to 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data\n",
    "X_train, y_train, X_val, y_val = split_data(df_nn, 2020, 'price_actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "58/58 [==============================] - 1s 7ms/step - loss: 10.4981 - SMAPE: 26.2713 - val_loss: 2.1611 - val_SMAPE: 6.2083\n",
      "Epoch 2/200\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 1.9406 - SMAPE: 3.8526 - val_loss: 3.8172 - val_SMAPE: 10.3004\n",
      "Epoch 3/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 2.0019 - SMAPE: 3.8225 - val_loss: 1.7064 - val_SMAPE: 4.9796\n",
      "Epoch 4/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.7521 - SMAPE: 3.5644 - val_loss: 3.1751 - val_SMAPE: 8.6492\n",
      "Epoch 5/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.7285 - SMAPE: 3.3064 - val_loss: 2.5200 - val_SMAPE: 7.0934\n",
      "Epoch 6/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.6208 - SMAPE: 3.1050 - val_loss: 1.5668 - val_SMAPE: 4.5625\n",
      "Epoch 7/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.8051 - SMAPE: 3.4228 - val_loss: 2.6854 - val_SMAPE: 7.4583\n",
      "Epoch 8/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.7150 - SMAPE: 3.2461 - val_loss: 1.5230 - val_SMAPE: 4.4033\n",
      "Epoch 9/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.6426 - SMAPE: 3.1354 - val_loss: 1.9047 - val_SMAPE: 5.3274\n",
      "Epoch 10/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.5986 - SMAPE: 3.0373 - val_loss: 1.6190 - val_SMAPE: 4.6570\n",
      "Epoch 11/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.5151 - SMAPE: 2.8946 - val_loss: 1.6564 - val_SMAPE: 4.8364\n",
      "Epoch 12/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.4640 - SMAPE: 2.8155 - val_loss: 1.5088 - val_SMAPE: 4.4274\n",
      "Epoch 13/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.4982 - SMAPE: 2.8360 - val_loss: 2.5914 - val_SMAPE: 7.2317\n",
      "Epoch 14/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.6003 - SMAPE: 3.0162 - val_loss: 1.7718 - val_SMAPE: 5.0442\n",
      "Epoch 15/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.4946 - SMAPE: 2.8330 - val_loss: 1.5647 - val_SMAPE: 4.5518\n",
      "Epoch 16/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.4519 - SMAPE: 2.7912 - val_loss: 1.5919 - val_SMAPE: 4.5569\n",
      "Epoch 17/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.4881 - SMAPE: 2.8197 - val_loss: 1.2876 - val_SMAPE: 3.7401\n",
      "Epoch 18/200\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 1.6117 - SMAPE: 3.0104 - val_loss: 1.9260 - val_SMAPE: 5.5756\n",
      "Epoch 19/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.4624 - SMAPE: 2.7602 - val_loss: 1.6228 - val_SMAPE: 4.7093\n",
      "Epoch 20/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.4504 - SMAPE: 2.7441 - val_loss: 1.7756 - val_SMAPE: 5.0344\n",
      "Epoch 21/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.3946 - SMAPE: 2.6485 - val_loss: 2.0559 - val_SMAPE: 5.8085\n",
      "Epoch 22/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.4338 - SMAPE: 2.6939 - val_loss: 1.8316 - val_SMAPE: 5.2968\n",
      "Epoch 23/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.3789 - SMAPE: 2.6797 - val_loss: 1.9481 - val_SMAPE: 5.4805\n",
      "Epoch 24/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.4566 - SMAPE: 2.7463 - val_loss: 1.5113 - val_SMAPE: 4.4426\n",
      "Epoch 25/200\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 1.4269 - SMAPE: 2.6711 - val_loss: 1.3849 - val_SMAPE: 4.0096\n",
      "Epoch 26/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.3932 - SMAPE: 2.6545 - val_loss: 2.2458 - val_SMAPE: 6.2469\n",
      "Epoch 27/200\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 1.3945 - SMAPE: 2.6320 - val_loss: 1.9490 - val_SMAPE: 5.6112\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>SMAPE_train</th>\n",
       "      <th>SMAPE_val</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TSO</th>\n",
       "      <td>None</td>\n",
       "      <td>16.03</td>\n",
       "      <td>16.922</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>3.021</td>\n",
       "      <td>5.869</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso1</th>\n",
       "      <td>{'num_features': 5}</td>\n",
       "      <td>3.367</td>\n",
       "      <td>5.056</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso2</th>\n",
       "      <td>{'price_day_ahead': False}</td>\n",
       "      <td>11.811</td>\n",
       "      <td>32.664</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>1.248</td>\n",
       "      <td>6.668</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost1</th>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>2.465</td>\n",
       "      <td>5.85</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost2</th>\n",
       "      <td>{'max_depth': 2, 'price_day_ahead': False}</td>\n",
       "      <td>4.331</td>\n",
       "      <td>27.241</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost3</th>\n",
       "      <td>{'max_depth': 16, 'price_day_ahead': False}</td>\n",
       "      <td>0.026</td>\n",
       "      <td>24.84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn_1-1</th>\n",
       "      <td>{'Dense1': 59, 'Dense2': 239, 'Dense3': 1}</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn-24-24</th>\n",
       "      <td>{'Dense1': 59, 'Dense2': 239, 'Dense3': 162, '...</td>\n",
       "      <td>3.871</td>\n",
       "      <td>3.738</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Parameters SMAPE_train  \\\n",
       "TSO                                                    None       16.03   \n",
       "Lasso                                               Vanilla       3.021   \n",
       "Lasso1                                  {'num_features': 5}       3.367   \n",
       "Lasso2                           {'price_day_ahead': False}      11.811   \n",
       "XGBoost                                             Vanilla       1.248   \n",
       "XGBoost1                                   {'max_depth': 2}       2.465   \n",
       "XGBoost2         {'max_depth': 2, 'price_day_ahead': False}       4.331   \n",
       "XGBoost3        {'max_depth': 16, 'price_day_ahead': False}       0.026   \n",
       "nn_1-1           {'Dense1': 59, 'Dense2': 239, 'Dense3': 1}       200.0   \n",
       "nn-24-24  {'Dense1': 59, 'Dense2': 239, 'Dense3': 162, '...       3.871   \n",
       "\n",
       "         SMAPE_val r2_train r2_val  \n",
       "TSO         16.922    0.954  0.971  \n",
       "Lasso        5.869    0.977  0.973  \n",
       "Lasso1       5.056    0.971  0.969  \n",
       "Lasso2      32.664    0.676  0.557  \n",
       "XGBoost      6.668    0.996  0.968  \n",
       "XGBoost1      5.85    0.984   0.97  \n",
       "XGBoost2    27.241    0.953  0.427  \n",
       "XGBoost3     24.84      1.0  0.403  \n",
       "nn_1-1       200.0      NaN    NaN  \n",
       "nn-24-24     3.738    0.981  0.978  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reorganize the training and testing data into batches\n",
    "X_train, y_train = resample((X_train, y_train), 24, 24, 24)\n",
    "X_val, y_val = resample((X_val,y_val), 24, 24, 24)\n",
    "\n",
    "# Define input_shape\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "# Instantiate model and build layers\n",
    "nn = models.Sequential()\n",
    "nn.add(layers.Dense(59, activation='relu', input_shape=input_shape))\n",
    "nn.add(layers.Dense(239, activation='relu'))\n",
    "nn.add(layers.Dense(162, activation='relu'))\n",
    "nn.add(TimeDistributed(layers.Dense(1)))\n",
    "\n",
    "nn2 = compile_fit(nn, (X_train, y_train), (X_val, y_val))\n",
    "\n",
    "params = {'Dense1':59,\n",
    "          'Dense2':239,\n",
    "          'Dense3':162,\n",
    "          'TimeDistributed':1}\n",
    "results_actual['nn-24-24'] = compute_metrics(nn2, params, (X_train,y_train), (X_val, y_val))\n",
    "\n",
    "# Save model\n",
    "nn2.save('../models/nn2')\n",
    "\n",
    "# Preview\n",
    "results_actual.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "58/58 [==============================] - 10s 102ms/step - loss: 53.4057 - SMAPE: 175.6884 - val_loss: 33.2597 - val_SMAPE: 144.3217\n",
      "Epoch 2/200\n",
      "58/58 [==============================] - 5s 90ms/step - loss: 49.8368 - SMAPE: 153.5010 - val_loss: 31.1744 - val_SMAPE: 128.3129\n",
      "Epoch 3/200\n",
      "58/58 [==============================] - 5s 83ms/step - loss: 48.0504 - SMAPE: 143.6363 - val_loss: 29.5401 - val_SMAPE: 116.8996\n",
      "Epoch 4/200\n",
      "58/58 [==============================] - 5s 82ms/step - loss: 46.4607 - SMAPE: 135.0932 - val_loss: 27.9949 - val_SMAPE: 106.8921\n",
      "Epoch 5/200\n",
      "58/58 [==============================] - 5s 80ms/step - loss: 44.9269 - SMAPE: 127.2520 - val_loss: 26.4899 - val_SMAPE: 97.7824\n",
      "Epoch 6/200\n",
      "58/58 [==============================] - 5s 82ms/step - loss: 43.4249 - SMAPE: 120.4168 - val_loss: 25.0227 - val_SMAPE: 89.4552\n",
      "Epoch 7/200\n",
      "58/58 [==============================] - 5s 83ms/step - loss: 41.9491 - SMAPE: 113.6031 - val_loss: 23.5879 - val_SMAPE: 81.7939\n",
      "Epoch 8/200\n",
      "58/58 [==============================] - 5s 83ms/step - loss: 40.4950 - SMAPE: 107.1393 - val_loss: 22.1852 - val_SMAPE: 74.7275\n",
      "Epoch 9/200\n",
      "58/58 [==============================] - 5s 81ms/step - loss: 39.0590 - SMAPE: 101.1148 - val_loss: 20.8153 - val_SMAPE: 68.1975\n",
      "Epoch 10/200\n",
      "58/58 [==============================] - 5s 82ms/step - loss: 37.6412 - SMAPE: 95.1150 - val_loss: 19.4848 - val_SMAPE: 62.1849\n",
      "Epoch 11/200\n",
      "58/58 [==============================] - 4s 77ms/step - loss: 36.2407 - SMAPE: 89.9152 - val_loss: 18.2003 - val_SMAPE: 56.6743\n",
      "Epoch 12/200\n",
      "58/58 [==============================] - 5s 80ms/step - loss: 34.8549 - SMAPE: 84.9152 - val_loss: 16.9591 - val_SMAPE: 51.6118\n",
      "Epoch 13/200\n",
      "58/58 [==============================] - 5s 89ms/step - loss: 33.4824 - SMAPE: 80.3885 - val_loss: 15.7671 - val_SMAPE: 46.9735\n",
      "Epoch 14/200\n",
      "58/58 [==============================] - 5s 80ms/step - loss: 32.0976 - SMAPE: 75.2896 - val_loss: 14.6555 - val_SMAPE: 42.8398\n",
      "Epoch 15/200\n",
      "58/58 [==============================] - 4s 76ms/step - loss: 30.7592 - SMAPE: 70.8317 - val_loss: 13.4321 - val_SMAPE: 38.5156\n",
      "Epoch 16/200\n",
      "58/58 [==============================] - 4s 69ms/step - loss: 29.4356 - SMAPE: 65.9145 - val_loss: 12.4344 - val_SMAPE: 35.1071\n",
      "Epoch 17/200\n",
      "58/58 [==============================] - 4s 67ms/step - loss: 28.0774 - SMAPE: 62.8711 - val_loss: 11.6837 - val_SMAPE: 32.6259\n",
      "Epoch 18/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 26.7995 - SMAPE: 58.4794 - val_loss: 10.7823 - val_SMAPE: 29.7147\n",
      "Epoch 19/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 25.4597 - SMAPE: 54.8518 - val_loss: 9.9121 - val_SMAPE: 26.9944\n",
      "Epoch 20/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 24.1931 - SMAPE: 51.2367 - val_loss: 9.0438 - val_SMAPE: 24.6661\n",
      "Epoch 21/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 22.9264 - SMAPE: 47.3815 - val_loss: 8.5904 - val_SMAPE: 23.1343\n",
      "Epoch 22/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 21.7035 - SMAPE: 44.3952 - val_loss: 7.8699 - val_SMAPE: 21.1062\n",
      "Epoch 23/200\n",
      "58/58 [==============================] - 4s 71ms/step - loss: 20.5203 - SMAPE: 41.4207 - val_loss: 7.4803 - val_SMAPE: 20.0925\n",
      "Epoch 24/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 19.3341 - SMAPE: 38.6584 - val_loss: 7.3128 - val_SMAPE: 19.5828\n",
      "Epoch 25/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 18.2191 - SMAPE: 35.9299 - val_loss: 6.7351 - val_SMAPE: 17.9761\n",
      "Epoch 26/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 17.1386 - SMAPE: 33.4427 - val_loss: 6.1964 - val_SMAPE: 16.7076\n",
      "Epoch 27/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 16.1320 - SMAPE: 30.7717 - val_loss: 6.4109 - val_SMAPE: 17.1602\n",
      "Epoch 28/200\n",
      "58/58 [==============================] - 4s 70ms/step - loss: 15.1994 - SMAPE: 28.9181 - val_loss: 6.3778 - val_SMAPE: 17.0113\n",
      "Epoch 29/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 14.3210 - SMAPE: 27.2876 - val_loss: 6.1813 - val_SMAPE: 16.4834\n",
      "Epoch 30/200\n",
      "58/58 [==============================] - 4s 68ms/step - loss: 13.5527 - SMAPE: 25.4644 - val_loss: 6.2621 - val_SMAPE: 16.5082\n",
      "Epoch 31/200\n",
      "58/58 [==============================] - 4s 70ms/step - loss: 12.8248 - SMAPE: 23.9058 - val_loss: 6.3976 - val_SMAPE: 16.9318\n",
      "Epoch 32/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 12.1417 - SMAPE: 22.4249 - val_loss: 6.0744 - val_SMAPE: 16.3837\n",
      "Epoch 33/200\n",
      "58/58 [==============================] - 4s 71ms/step - loss: 11.5237 - SMAPE: 21.0934 - val_loss: 5.8030 - val_SMAPE: 15.4404\n",
      "Epoch 34/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 10.9971 - SMAPE: 19.9401 - val_loss: 5.1427 - val_SMAPE: 14.1200\n",
      "Epoch 35/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 10.4914 - SMAPE: 19.0893 - val_loss: 5.3408 - val_SMAPE: 14.5460\n",
      "Epoch 36/200\n",
      "58/58 [==============================] - 4s 71ms/step - loss: 10.0654 - SMAPE: 18.1134 - val_loss: 6.3867 - val_SMAPE: 17.0774\n",
      "Epoch 37/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 9.6902 - SMAPE: 17.8596 - val_loss: 5.2518 - val_SMAPE: 14.2880\n",
      "Epoch 38/200\n",
      "58/58 [==============================] - 4s 71ms/step - loss: 9.2936 - SMAPE: 16.8912 - val_loss: 5.0398 - val_SMAPE: 13.6331\n",
      "Epoch 39/200\n",
      "58/58 [==============================] - 4s 76ms/step - loss: 8.9170 - SMAPE: 16.2522 - val_loss: 5.5810 - val_SMAPE: 15.3866\n",
      "Epoch 40/200\n",
      "58/58 [==============================] - 4s 74ms/step - loss: 8.6192 - SMAPE: 15.6114 - val_loss: 5.2688 - val_SMAPE: 14.5299\n",
      "Epoch 41/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 8.3084 - SMAPE: 14.9232 - val_loss: 5.0158 - val_SMAPE: 13.6924\n",
      "Epoch 42/200\n",
      "58/58 [==============================] - 4s 71ms/step - loss: 8.0733 - SMAPE: 14.6670 - val_loss: 5.2163 - val_SMAPE: 13.9766\n",
      "Epoch 43/200\n",
      "58/58 [==============================] - 4s 71ms/step - loss: 7.8306 - SMAPE: 14.2443 - val_loss: 4.7046 - val_SMAPE: 12.8845\n",
      "Epoch 44/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 7.5810 - SMAPE: 13.4747 - val_loss: 5.4604 - val_SMAPE: 14.4078\n",
      "Epoch 45/200\n",
      "58/58 [==============================] - 4s 71ms/step - loss: 7.5993 - SMAPE: 13.6165 - val_loss: 4.9266 - val_SMAPE: 13.5603\n",
      "Epoch 46/200\n",
      "58/58 [==============================] - 4s 69ms/step - loss: 7.2563 - SMAPE: 12.8909 - val_loss: 4.3300 - val_SMAPE: 11.8480\n",
      "Epoch 47/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 6.9418 - SMAPE: 12.4597 - val_loss: 4.3570 - val_SMAPE: 12.0015\n",
      "Epoch 48/200\n",
      "58/58 [==============================] - 4s 68ms/step - loss: 6.6907 - SMAPE: 12.1440 - val_loss: 4.7602 - val_SMAPE: 13.0505\n",
      "Epoch 49/200\n",
      "58/58 [==============================] - 4s 70ms/step - loss: 6.4294 - SMAPE: 11.4822 - val_loss: 4.3719 - val_SMAPE: 12.0075\n",
      "Epoch 50/200\n",
      "58/58 [==============================] - 4s 70ms/step - loss: 6.2709 - SMAPE: 11.6373 - val_loss: 4.3229 - val_SMAPE: 11.9670\n",
      "Epoch 51/200\n",
      "58/58 [==============================] - 4s 71ms/step - loss: 6.0008 - SMAPE: 10.7411 - val_loss: 4.3714 - val_SMAPE: 12.0521\n",
      "Epoch 52/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 5.9246 - SMAPE: 10.6326 - val_loss: 4.4337 - val_SMAPE: 12.2746\n",
      "Epoch 53/200\n",
      "58/58 [==============================] - 4s 71ms/step - loss: 5.7612 - SMAPE: 10.3866 - val_loss: 4.1848 - val_SMAPE: 11.5761\n",
      "Epoch 54/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 5.5807 - SMAPE: 10.0541 - val_loss: 4.0235 - val_SMAPE: 11.2812\n",
      "Epoch 55/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 5.4489 - SMAPE: 9.9187 - val_loss: 3.9768 - val_SMAPE: 11.0857\n",
      "Epoch 56/200\n",
      "58/58 [==============================] - 4s 76ms/step - loss: 5.2963 - SMAPE: 9.5633 - val_loss: 4.1062 - val_SMAPE: 11.4413\n",
      "Epoch 57/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 5.1344 - SMAPE: 9.2681 - val_loss: 4.0776 - val_SMAPE: 11.3395\n",
      "Epoch 58/200\n",
      "58/58 [==============================] - 4s 72ms/step - loss: 5.0232 - SMAPE: 9.0886 - val_loss: 4.0160 - val_SMAPE: 11.1078\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 4s 68ms/step - loss: 4.9382 - SMAPE: 8.9469 - val_loss: 3.8587 - val_SMAPE: 10.7696\n",
      "Epoch 60/200\n",
      "58/58 [==============================] - 4s 70ms/step - loss: 4.7818 - SMAPE: 8.8076 - val_loss: 4.1379 - val_SMAPE: 11.5559\n",
      "Epoch 61/200\n",
      "58/58 [==============================] - 4s 70ms/step - loss: 4.9300 - SMAPE: 8.9392 - val_loss: 4.4251 - val_SMAPE: 12.0608\n",
      "Epoch 62/200\n",
      "58/58 [==============================] - 4s 67ms/step - loss: 4.8954 - SMAPE: 8.9288 - val_loss: 4.0642 - val_SMAPE: 11.2926\n",
      "Epoch 63/200\n",
      "58/58 [==============================] - 4s 69ms/step - loss: 4.5529 - SMAPE: 8.3687 - val_loss: 3.9526 - val_SMAPE: 10.9456\n",
      "Epoch 64/200\n",
      "58/58 [==============================] - 4s 70ms/step - loss: 4.4620 - SMAPE: 8.2225 - val_loss: 3.9264 - val_SMAPE: 10.9503\n",
      "Epoch 65/200\n",
      "58/58 [==============================] - 4s 70ms/step - loss: 4.4057 - SMAPE: 8.0574 - val_loss: 3.9838 - val_SMAPE: 11.0598\n",
      "Epoch 66/200\n",
      "58/58 [==============================] - 4s 71ms/step - loss: 4.3629 - SMAPE: 8.0396 - val_loss: 3.9981 - val_SMAPE: 11.1139\n",
      "Epoch 67/200\n",
      "58/58 [==============================] - 4s 70ms/step - loss: 4.2785 - SMAPE: 7.8490 - val_loss: 4.0536 - val_SMAPE: 11.2978\n",
      "Epoch 68/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 4.1954 - SMAPE: 7.8514 - val_loss: 3.9943 - val_SMAPE: 11.1059\n",
      "Epoch 69/200\n",
      "58/58 [==============================] - 4s 73ms/step - loss: 4.1461 - SMAPE: 7.6096 - val_loss: 4.0571 - val_SMAPE: 11.2796\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>SMAPE_train</th>\n",
       "      <th>SMAPE_val</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TSO</th>\n",
       "      <td>None</td>\n",
       "      <td>16.03</td>\n",
       "      <td>16.922</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>3.021</td>\n",
       "      <td>5.869</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso1</th>\n",
       "      <td>{'num_features': 5}</td>\n",
       "      <td>3.367</td>\n",
       "      <td>5.056</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso2</th>\n",
       "      <td>{'price_day_ahead': False}</td>\n",
       "      <td>11.811</td>\n",
       "      <td>32.664</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>1.248</td>\n",
       "      <td>6.668</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost1</th>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>2.465</td>\n",
       "      <td>5.85</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost2</th>\n",
       "      <td>{'max_depth': 2, 'price_day_ahead': False}</td>\n",
       "      <td>4.331</td>\n",
       "      <td>27.241</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost3</th>\n",
       "      <td>{'max_depth': 16, 'price_day_ahead': False}</td>\n",
       "      <td>0.026</td>\n",
       "      <td>24.84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn_1-1</th>\n",
       "      <td>{'Dense1': 59, 'Dense2': 239, 'Dense3': 1}</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn-24-24</th>\n",
       "      <td>{'Dense1': 59, 'Dense2': 239, 'Dense3': 162, '...</td>\n",
       "      <td>3.871</td>\n",
       "      <td>3.738</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM</th>\n",
       "      <td>{'LSTM1': 60, 'LSTM2': 24, 'TimeDistributed': ...</td>\n",
       "      <td>8.805</td>\n",
       "      <td>10.646</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Parameters SMAPE_train  \\\n",
       "TSO                                                    None       16.03   \n",
       "Lasso                                               Vanilla       3.021   \n",
       "Lasso1                                  {'num_features': 5}       3.367   \n",
       "Lasso2                           {'price_day_ahead': False}      11.811   \n",
       "XGBoost                                             Vanilla       1.248   \n",
       "XGBoost1                                   {'max_depth': 2}       2.465   \n",
       "XGBoost2         {'max_depth': 2, 'price_day_ahead': False}       4.331   \n",
       "XGBoost3        {'max_depth': 16, 'price_day_ahead': False}       0.026   \n",
       "nn_1-1           {'Dense1': 59, 'Dense2': 239, 'Dense3': 1}       200.0   \n",
       "nn-24-24  {'Dense1': 59, 'Dense2': 239, 'Dense3': 162, '...       3.871   \n",
       "LSTM      {'LSTM1': 60, 'LSTM2': 24, 'TimeDistributed': ...       8.805   \n",
       "\n",
       "         SMAPE_val r2_train r2_val  \n",
       "TSO         16.922    0.954  0.971  \n",
       "Lasso        5.869    0.977  0.973  \n",
       "Lasso1       5.056    0.971  0.969  \n",
       "Lasso2      32.664    0.676  0.557  \n",
       "XGBoost      6.668    0.996  0.968  \n",
       "XGBoost1      5.85    0.984   0.97  \n",
       "XGBoost2    27.241    0.953  0.427  \n",
       "XGBoost3     24.84      1.0  0.403  \n",
       "nn_1-1       200.0      NaN    NaN  \n",
       "nn-24-24     3.738    0.981  0.978  \n",
       "LSTM        10.646    0.787  0.804  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into train and validation\n",
    "X_train, y_train, X_val, y_val = split_data(df_nn, 2020, 'price_actual')\n",
    "\n",
    "# Reorganize the training and testing data into batches\n",
    "X_train, y_train = resample((X_train, y_train), 24*7, 24, 24)\n",
    "X_val, y_val = resample((X_val,y_val), 24*7, 24, 24)\n",
    "\n",
    "# Input Shape\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "# Instantiate model and build layers\n",
    "nn = models.Sequential()\n",
    "nn.add(layers.LSTM(60, activation='tanh', input_shape=input_shape))\n",
    "nn.add(layers.RepeatVector(y_train.shape[1]))\n",
    "nn.add(layers.LSTM(24, activation='tanh', return_sequences=True))\n",
    "nn.add(TimeDistributed(layers.Dense(1)))\n",
    "\n",
    "# Compile Fit\n",
    "nn3 = compile_fit(nn, (X_train, y_train), (X_val, y_val))\n",
    "\n",
    "# Append results\n",
    "params = {'LSTM1':60,\n",
    "          'LSTM2':24,\n",
    "          'TimeDistributed':1,\n",
    "          'input_win':'7-days'}\n",
    "\n",
    "results_actual['LSTM'] = compute_metrics(nn3, params, (X_train,y_train), (X_val,y_val))\n",
    "\n",
    "# Save Model\n",
    "nn3.save('../models/nn3')\n",
    "\n",
    "# Preview\n",
    "results_actual.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "58/58 [==============================] - 8s 103ms/step - loss: 52.9091 - SMAPE: 172.8656 - val_loss: 32.6573 - val_SMAPE: 139.4956\n",
      "Epoch 2/200\n",
      "58/58 [==============================] - 6s 98ms/step - loss: 49.3830 - SMAPE: 149.9188 - val_loss: 30.7945 - val_SMAPE: 125.5707\n",
      "Epoch 3/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 47.6901 - SMAPE: 141.5163 - val_loss: 29.1960 - val_SMAPE: 114.6066\n",
      "Epoch 4/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 46.1242 - SMAPE: 133.4158 - val_loss: 27.6689 - val_SMAPE: 104.8651\n",
      "Epoch 5/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 44.6061 - SMAPE: 125.9322 - val_loss: 26.1796 - val_SMAPE: 95.9753\n",
      "Epoch 6/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 43.1165 - SMAPE: 118.0820 - val_loss: 24.7233 - val_SMAPE: 87.8168\n",
      "Epoch 7/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 41.6503 - SMAPE: 112.3395 - val_loss: 23.3010 - val_SMAPE: 80.3152\n",
      "Epoch 8/200\n",
      "58/58 [==============================] - 6s 95ms/step - loss: 40.2042 - SMAPE: 105.2437 - val_loss: 21.9094 - val_SMAPE: 73.3837\n",
      "Epoch 9/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 38.7759 - SMAPE: 99.9760 - val_loss: 20.5496 - val_SMAPE: 66.9706\n",
      "Epoch 10/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 37.3639 - SMAPE: 94.5229 - val_loss: 19.2316 - val_SMAPE: 61.0750\n",
      "Epoch 11/200\n",
      "58/58 [==============================] - 6s 98ms/step - loss: 35.9699 - SMAPE: 89.0931 - val_loss: 17.9551 - val_SMAPE: 55.6538\n",
      "Epoch 12/200\n",
      "58/58 [==============================] - 6s 97ms/step - loss: 34.5879 - SMAPE: 83.8528 - val_loss: 16.7278 - val_SMAPE: 50.6950\n",
      "Epoch 13/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 33.2205 - SMAPE: 79.0721 - val_loss: 15.5572 - val_SMAPE: 46.1795\n",
      "Epoch 14/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 31.8653 - SMAPE: 74.1672 - val_loss: 14.4550 - val_SMAPE: 42.1137\n",
      "Epoch 15/200\n",
      "58/58 [==============================] - 6s 97ms/step - loss: 30.5252 - SMAPE: 69.9598 - val_loss: 13.4165 - val_SMAPE: 38.4455\n",
      "Epoch 16/200\n",
      "58/58 [==============================] - 6s 97ms/step - loss: 29.1943 - SMAPE: 66.2703 - val_loss: 12.2256 - val_SMAPE: 34.5719\n",
      "Epoch 17/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 27.8847 - SMAPE: 61.6014 - val_loss: 11.6044 - val_SMAPE: 32.3896\n",
      "Epoch 18/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 26.6022 - SMAPE: 57.9456 - val_loss: 10.8309 - val_SMAPE: 29.9000\n",
      "Epoch 19/200\n",
      "58/58 [==============================] - 6s 97ms/step - loss: 25.3154 - SMAPE: 54.1084 - val_loss: 9.9914 - val_SMAPE: 27.3249\n",
      "Epoch 20/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 23.9769 - SMAPE: 50.6583 - val_loss: 8.8695 - val_SMAPE: 23.9155\n",
      "Epoch 21/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 22.7339 - SMAPE: 47.4038 - val_loss: 9.0569 - val_SMAPE: 24.4343\n",
      "Epoch 22/200\n",
      "58/58 [==============================] - 6s 106ms/step - loss: 21.5144 - SMAPE: 43.6249 - val_loss: 7.8851 - val_SMAPE: 21.0616\n",
      "Epoch 23/200\n",
      "58/58 [==============================] - 7s 113ms/step - loss: 20.2937 - SMAPE: 40.4399 - val_loss: 7.8480 - val_SMAPE: 21.0267\n",
      "Epoch 24/200\n",
      "58/58 [==============================] - 6s 109ms/step - loss: 19.1517 - SMAPE: 38.3327 - val_loss: 7.0382 - val_SMAPE: 18.9283\n",
      "Epoch 25/200\n",
      "58/58 [==============================] - 6s 98ms/step - loss: 18.0778 - SMAPE: 35.0352 - val_loss: 6.5883 - val_SMAPE: 17.4260\n",
      "Epoch 26/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 16.9694 - SMAPE: 32.4954 - val_loss: 6.8820 - val_SMAPE: 18.2144\n",
      "Epoch 27/200\n",
      "58/58 [==============================] - 6s 97ms/step - loss: 15.9589 - SMAPE: 30.4965 - val_loss: 6.0999 - val_SMAPE: 16.3163\n",
      "Epoch 28/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 15.0438 - SMAPE: 28.7818 - val_loss: 6.1071 - val_SMAPE: 16.7482\n",
      "Epoch 29/200\n",
      "58/58 [==============================] - 6s 97ms/step - loss: 14.2241 - SMAPE: 26.6543 - val_loss: 7.8971 - val_SMAPE: 20.7193\n",
      "Epoch 30/200\n",
      "58/58 [==============================] - 6s 97ms/step - loss: 13.4539 - SMAPE: 25.0019 - val_loss: 6.2340 - val_SMAPE: 16.5750\n",
      "Epoch 31/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 12.6934 - SMAPE: 23.5341 - val_loss: 5.5881 - val_SMAPE: 14.9219\n",
      "Epoch 32/200\n",
      "58/58 [==============================] - 6s 98ms/step - loss: 12.0227 - SMAPE: 21.8687 - val_loss: 5.4239 - val_SMAPE: 14.7301\n",
      "Epoch 33/200\n",
      "58/58 [==============================] - 6s 97ms/step - loss: 11.5342 - SMAPE: 21.1360 - val_loss: 7.8677 - val_SMAPE: 19.9720\n",
      "Epoch 34/200\n",
      "58/58 [==============================] - 6s 97ms/step - loss: 10.9984 - SMAPE: 19.9258 - val_loss: 5.4187 - val_SMAPE: 14.5471\n",
      "Epoch 35/200\n",
      "58/58 [==============================] - 6s 97ms/step - loss: 10.4514 - SMAPE: 18.8503 - val_loss: 5.4863 - val_SMAPE: 14.8633\n",
      "Epoch 36/200\n",
      "58/58 [==============================] - 6s 99ms/step - loss: 10.0067 - SMAPE: 18.2614 - val_loss: 5.3716 - val_SMAPE: 14.5506\n",
      "Epoch 37/200\n",
      "58/58 [==============================] - 6s 97ms/step - loss: 9.6565 - SMAPE: 17.5691 - val_loss: 5.8016 - val_SMAPE: 15.5337\n",
      "Epoch 38/200\n",
      "58/58 [==============================] - 6s 97ms/step - loss: 9.2054 - SMAPE: 16.4733 - val_loss: 5.0210 - val_SMAPE: 13.5812\n",
      "Epoch 39/200\n",
      "58/58 [==============================] - 5s 95ms/step - loss: 8.8307 - SMAPE: 15.8113 - val_loss: 5.2116 - val_SMAPE: 14.2625\n",
      "Epoch 40/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 8.4973 - SMAPE: 15.2859 - val_loss: 4.6907 - val_SMAPE: 12.8695\n",
      "Epoch 41/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 8.2178 - SMAPE: 14.7705 - val_loss: 5.6223 - val_SMAPE: 15.1418\n",
      "Epoch 42/200\n",
      "58/58 [==============================] - 6s 97ms/step - loss: 7.9083 - SMAPE: 14.1313 - val_loss: 4.9555 - val_SMAPE: 13.6534\n",
      "Epoch 43/200\n",
      "58/58 [==============================] - 6s 103ms/step - loss: 7.6357 - SMAPE: 13.6340 - val_loss: 4.9061 - val_SMAPE: 13.5345\n",
      "Epoch 44/200\n",
      "58/58 [==============================] - 6s 97ms/step - loss: 7.3451 - SMAPE: 13.1861 - val_loss: 4.5011 - val_SMAPE: 12.4606\n",
      "Epoch 45/200\n",
      "58/58 [==============================] - 6s 97ms/step - loss: 7.0688 - SMAPE: 12.6244 - val_loss: 4.4053 - val_SMAPE: 12.3038\n",
      "Epoch 46/200\n",
      "58/58 [==============================] - 6s 97ms/step - loss: 6.8750 - SMAPE: 12.2658 - val_loss: 4.4152 - val_SMAPE: 12.1250\n",
      "Epoch 47/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 6.6513 - SMAPE: 11.8967 - val_loss: 4.3857 - val_SMAPE: 12.2515\n",
      "Epoch 48/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 6.4333 - SMAPE: 11.5837 - val_loss: 4.3238 - val_SMAPE: 11.9155\n",
      "Epoch 49/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 6.2015 - SMAPE: 11.1111 - val_loss: 4.4855 - val_SMAPE: 12.3039\n",
      "Epoch 50/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 6.1976 - SMAPE: 11.0634 - val_loss: 4.1980 - val_SMAPE: 11.5634\n",
      "Epoch 51/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 5.8858 - SMAPE: 10.8120 - val_loss: 4.3894 - val_SMAPE: 12.0697\n",
      "Epoch 52/200\n",
      "58/58 [==============================] - 6s 97ms/step - loss: 5.7115 - SMAPE: 10.2657 - val_loss: 4.1046 - val_SMAPE: 11.3364\n",
      "Epoch 53/200\n",
      "58/58 [==============================] - 6s 98ms/step - loss: 5.5460 - SMAPE: 9.9409 - val_loss: 4.3250 - val_SMAPE: 11.9155\n",
      "Epoch 54/200\n",
      "58/58 [==============================] - 6s 97ms/step - loss: 5.4395 - SMAPE: 9.8774 - val_loss: 4.4072 - val_SMAPE: 12.1697\n",
      "Epoch 55/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 5.2975 - SMAPE: 9.4953 - val_loss: 4.2930 - val_SMAPE: 11.8749\n",
      "Epoch 56/200\n",
      "58/58 [==============================] - 6s 97ms/step - loss: 5.0525 - SMAPE: 9.1105 - val_loss: 4.5085 - val_SMAPE: 12.4534\n",
      "Epoch 57/200\n",
      "58/58 [==============================] - 6s 96ms/step - loss: 4.9116 - SMAPE: 8.8097 - val_loss: 4.4191 - val_SMAPE: 12.0524\n",
      "Epoch 58/200\n",
      "58/58 [==============================] - 6s 97ms/step - loss: 4.8947 - SMAPE: 8.8246 - val_loss: 4.3739 - val_SMAPE: 12.1735\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 5s 91ms/step - loss: 4.6707 - SMAPE: 8.3977 - val_loss: 4.1804 - val_SMAPE: 11.6542\n",
      "Epoch 60/200\n",
      "58/58 [==============================] - 5s 91ms/step - loss: 4.5772 - SMAPE: 8.5437 - val_loss: 3.9321 - val_SMAPE: 10.9229\n",
      "Epoch 61/200\n",
      "58/58 [==============================] - 5s 92ms/step - loss: 4.5810 - SMAPE: 8.5058 - val_loss: 4.0838 - val_SMAPE: 11.2956\n",
      "Epoch 62/200\n",
      "58/58 [==============================] - 5s 91ms/step - loss: 4.3850 - SMAPE: 7.9147 - val_loss: 4.4194 - val_SMAPE: 12.2945\n",
      "Epoch 63/200\n",
      "58/58 [==============================] - 5s 92ms/step - loss: 4.3502 - SMAPE: 7.8925 - val_loss: 4.2038 - val_SMAPE: 11.7330\n",
      "Epoch 64/200\n",
      "58/58 [==============================] - 5s 92ms/step - loss: 4.2466 - SMAPE: 7.7399 - val_loss: 3.9747 - val_SMAPE: 11.0827\n",
      "Epoch 65/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 4.1603 - SMAPE: 7.5915 - val_loss: 3.9382 - val_SMAPE: 10.9863\n",
      "Epoch 66/200\n",
      "58/58 [==============================] - 6s 95ms/step - loss: 4.0903 - SMAPE: 7.4718 - val_loss: 3.8507 - val_SMAPE: 10.7699\n",
      "Epoch 67/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 4.0269 - SMAPE: 7.3584 - val_loss: 3.7648 - val_SMAPE: 10.5335\n",
      "Epoch 68/200\n",
      "58/58 [==============================] - 5s 93ms/step - loss: 3.9748 - SMAPE: 7.2382 - val_loss: 4.0746 - val_SMAPE: 11.3964\n",
      "Epoch 69/200\n",
      "58/58 [==============================] - 5s 92ms/step - loss: 3.8641 - SMAPE: 7.0698 - val_loss: 3.6523 - val_SMAPE: 10.3498\n",
      "Epoch 70/200\n",
      "58/58 [==============================] - 5s 91ms/step - loss: 3.9133 - SMAPE: 7.1543 - val_loss: 3.7203 - val_SMAPE: 10.5085\n",
      "Epoch 71/200\n",
      "58/58 [==============================] - 5s 91ms/step - loss: 3.7582 - SMAPE: 7.0058 - val_loss: 3.7414 - val_SMAPE: 10.5265\n",
      "Epoch 72/200\n",
      "58/58 [==============================] - 5s 92ms/step - loss: 3.7020 - SMAPE: 6.8171 - val_loss: 3.6448 - val_SMAPE: 10.2741\n",
      "Epoch 73/200\n",
      "58/58 [==============================] - 5s 93ms/step - loss: 3.6675 - SMAPE: 6.7548 - val_loss: 3.9115 - val_SMAPE: 10.9165\n",
      "Epoch 74/200\n",
      "58/58 [==============================] - 5s 91ms/step - loss: 3.7090 - SMAPE: 6.8515 - val_loss: 3.6268 - val_SMAPE: 10.1946\n",
      "Epoch 75/200\n",
      "58/58 [==============================] - 5s 93ms/step - loss: 3.5995 - SMAPE: 6.6278 - val_loss: 3.6472 - val_SMAPE: 10.2496\n",
      "Epoch 76/200\n",
      "58/58 [==============================] - 5s 93ms/step - loss: 3.4730 - SMAPE: 6.4226 - val_loss: 3.6491 - val_SMAPE: 10.2528\n",
      "Epoch 77/200\n",
      "58/58 [==============================] - 5s 92ms/step - loss: 3.4948 - SMAPE: 6.4927 - val_loss: 3.4269 - val_SMAPE: 9.7334\n",
      "Epoch 78/200\n",
      "58/58 [==============================] - 5s 92ms/step - loss: 3.3896 - SMAPE: 6.4679 - val_loss: 3.4075 - val_SMAPE: 9.6850\n",
      "Epoch 79/200\n",
      "58/58 [==============================] - 5s 92ms/step - loss: 3.3132 - SMAPE: 6.1574 - val_loss: 3.4816 - val_SMAPE: 9.9159\n",
      "Epoch 80/200\n",
      "58/58 [==============================] - 5s 92ms/step - loss: 3.2818 - SMAPE: 6.0580 - val_loss: 3.5513 - val_SMAPE: 10.0440\n",
      "Epoch 81/200\n",
      "58/58 [==============================] - 5s 92ms/step - loss: 3.2386 - SMAPE: 5.9742 - val_loss: 3.3319 - val_SMAPE: 9.4707\n",
      "Epoch 82/200\n",
      "58/58 [==============================] - 5s 92ms/step - loss: 3.1733 - SMAPE: 5.8914 - val_loss: 3.3018 - val_SMAPE: 9.4271\n",
      "Epoch 83/200\n",
      "58/58 [==============================] - 5s 92ms/step - loss: 3.2342 - SMAPE: 6.0812 - val_loss: 3.3618 - val_SMAPE: 9.5980\n",
      "Epoch 84/200\n",
      "58/58 [==============================] - 5s 92ms/step - loss: 3.1753 - SMAPE: 5.8927 - val_loss: 3.4626 - val_SMAPE: 9.9885\n",
      "Epoch 85/200\n",
      "58/58 [==============================] - 5s 94ms/step - loss: 3.0773 - SMAPE: 5.7024 - val_loss: 3.3821 - val_SMAPE: 9.6997\n",
      "Epoch 86/200\n",
      "58/58 [==============================] - 5s 92ms/step - loss: 3.0351 - SMAPE: 5.6268 - val_loss: 3.2931 - val_SMAPE: 9.4481\n",
      "Epoch 87/200\n",
      "58/58 [==============================] - 5s 92ms/step - loss: 2.9966 - SMAPE: 5.7190 - val_loss: 3.3345 - val_SMAPE: 9.5980\n",
      "Epoch 88/200\n",
      "58/58 [==============================] - 5s 92ms/step - loss: 3.0523 - SMAPE: 5.7295 - val_loss: 3.6387 - val_SMAPE: 10.2961\n",
      "Epoch 89/200\n",
      "58/58 [==============================] - 5s 92ms/step - loss: 3.0127 - SMAPE: 5.6817 - val_loss: 3.3564 - val_SMAPE: 9.6630\n",
      "Epoch 90/200\n",
      "58/58 [==============================] - 5s 92ms/step - loss: 3.0057 - SMAPE: 5.6491 - val_loss: 3.4794 - val_SMAPE: 9.9107\n",
      "Epoch 91/200\n",
      "58/58 [==============================] - 6s 98ms/step - loss: 2.9717 - SMAPE: 5.5320 - val_loss: 3.4805 - val_SMAPE: 9.9190\n",
      "Epoch 92/200\n",
      "58/58 [==============================] - 5s 92ms/step - loss: 2.9435 - SMAPE: 5.4983 - val_loss: 3.4576 - val_SMAPE: 9.8288\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameters</th>\n",
       "      <th>SMAPE_train</th>\n",
       "      <th>SMAPE_val</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>r2_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TSO</th>\n",
       "      <td>None</td>\n",
       "      <td>16.03</td>\n",
       "      <td>16.922</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>3.021</td>\n",
       "      <td>5.869</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso1</th>\n",
       "      <td>{'num_features': 5}</td>\n",
       "      <td>3.367</td>\n",
       "      <td>5.056</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso2</th>\n",
       "      <td>{'price_day_ahead': False}</td>\n",
       "      <td>11.811</td>\n",
       "      <td>32.664</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>Vanilla</td>\n",
       "      <td>1.248</td>\n",
       "      <td>6.668</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost1</th>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>2.465</td>\n",
       "      <td>5.85</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost2</th>\n",
       "      <td>{'max_depth': 2, 'price_day_ahead': False}</td>\n",
       "      <td>4.331</td>\n",
       "      <td>27.241</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost3</th>\n",
       "      <td>{'max_depth': 16, 'price_day_ahead': False}</td>\n",
       "      <td>0.026</td>\n",
       "      <td>24.84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn_1-1</th>\n",
       "      <td>{'Dense1': 59, 'Dense2': 239, 'Dense3': 1}</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn-24-24</th>\n",
       "      <td>{'Dense1': 59, 'Dense2': 239, 'Dense3': 162, '...</td>\n",
       "      <td>3.871</td>\n",
       "      <td>3.738</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM</th>\n",
       "      <td>{'LSTM1': 60, 'LSTM2': 24, 'TimeDistributed': ...</td>\n",
       "      <td>8.805</td>\n",
       "      <td>10.646</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM1</th>\n",
       "      <td>{'LSTM1': 83, 'LSTM2': 24, 'TimeDistributed': ...</td>\n",
       "      <td>6.062</td>\n",
       "      <td>9.337</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Parameters SMAPE_train  \\\n",
       "TSO                                                    None       16.03   \n",
       "Lasso                                               Vanilla       3.021   \n",
       "Lasso1                                  {'num_features': 5}       3.367   \n",
       "Lasso2                           {'price_day_ahead': False}      11.811   \n",
       "XGBoost                                             Vanilla       1.248   \n",
       "XGBoost1                                   {'max_depth': 2}       2.465   \n",
       "XGBoost2         {'max_depth': 2, 'price_day_ahead': False}       4.331   \n",
       "XGBoost3        {'max_depth': 16, 'price_day_ahead': False}       0.026   \n",
       "nn_1-1           {'Dense1': 59, 'Dense2': 239, 'Dense3': 1}       200.0   \n",
       "nn-24-24  {'Dense1': 59, 'Dense2': 239, 'Dense3': 162, '...       3.871   \n",
       "LSTM      {'LSTM1': 60, 'LSTM2': 24, 'TimeDistributed': ...       8.805   \n",
       "LSTM1     {'LSTM1': 83, 'LSTM2': 24, 'TimeDistributed': ...       6.062   \n",
       "\n",
       "         SMAPE_val r2_train r2_val  \n",
       "TSO         16.922    0.954  0.971  \n",
       "Lasso        5.869    0.977  0.973  \n",
       "Lasso1       5.056    0.971  0.969  \n",
       "Lasso2      32.664    0.676  0.557  \n",
       "XGBoost      6.668    0.996  0.968  \n",
       "XGBoost1      5.85    0.984   0.97  \n",
       "XGBoost2    27.241    0.953  0.427  \n",
       "XGBoost3     24.84      1.0  0.403  \n",
       "nn_1-1       200.0      NaN    NaN  \n",
       "nn-24-24     3.738    0.981  0.978  \n",
       "LSTM        10.646    0.787  0.804  \n",
       "LSTM1        9.337     0.89  0.866  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input Shape\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "# Instantiate model and build layers\n",
    "nn = models.Sequential()\n",
    "nn.add(layers.LSTM(83, activation='tanh', input_shape=input_shape))\n",
    "nn.add(layers.RepeatVector(y_train.shape[1]))\n",
    "nn.add(layers.LSTM(24, activation='tanh', return_sequences=True))\n",
    "nn.add(TimeDistributed(layers.Dense(1)))\n",
    "\n",
    "# Compile Fit\n",
    "nn4 = compile_fit(nn, (X_train, y_train), (X_val, y_val))\n",
    "\n",
    "# Append results\n",
    "params = {'LSTM1':83,\n",
    "          'LSTM2':24,\n",
    "          'TimeDistributed':1,\n",
    "          'input_win':'7-days'}\n",
    "\n",
    "results_actual['LSTM1'] = compute_metrics(nn4, params, (X_train,y_train), (X_val,y_val))\n",
    "\n",
    "# Save Model\n",
    "nn4.save('../models/nn4')\n",
    "\n",
    "# Preview\n",
    "results_actual.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM-DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "58/58 [==============================] - 1s 6ms/step - loss: 12.3746 - SMAPE: 32.1995 - val_loss: 1.9944 - val_SMAPE: 6.8858\n",
      "Epoch 2/200\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 2.7985 - SMAPE: 6.5479 - val_loss: 2.1330 - val_SMAPE: 6.3469\n",
      "Epoch 3/200\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 2.6315 - SMAPE: 5.5008 - val_loss: 1.9710 - val_SMAPE: 5.9442\n",
      "Epoch 4/200\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 2.5122 - SMAPE: 4.9637 - val_loss: 2.3746 - val_SMAPE: 6.9121\n",
      "Epoch 5/200\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 2.4242 - SMAPE: 4.7868 - val_loss: 2.0387 - val_SMAPE: 6.1979\n",
      "Epoch 6/200\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 2.5448 - SMAPE: 4.9840 - val_loss: 1.8914 - val_SMAPE: 5.7971\n",
      "Epoch 7/200\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 2.4210 - SMAPE: 4.6925 - val_loss: 2.0036 - val_SMAPE: 6.1003\n",
      "Epoch 8/200\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 2.2121 - SMAPE: 4.3799 - val_loss: 2.7121 - val_SMAPE: 7.6715\n",
      "Epoch 9/200\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 2.2984 - SMAPE: 4.4421 - val_loss: 2.8765 - val_SMAPE: 7.9538\n",
      "Epoch 10/200\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 2.2407 - SMAPE: 4.3456 - val_loss: 2.5946 - val_SMAPE: 7.3144\n",
      "Epoch 11/200\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 2.2048 - SMAPE: 4.2852 - val_loss: 1.8636 - val_SMAPE: 5.6569\n",
      "Epoch 12/200\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 2.4028 - SMAPE: 4.6309 - val_loss: 3.5478 - val_SMAPE: 9.5228\n",
      "Epoch 13/200\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 2.2582 - SMAPE: 4.3720 - val_loss: 3.1010 - val_SMAPE: 8.4712\n",
      "Epoch 14/200\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 2.1662 - SMAPE: 4.1658 - val_loss: 1.8214 - val_SMAPE: 5.4442\n",
      "Epoch 15/200\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 2.3280 - SMAPE: 4.4289 - val_loss: 3.0686 - val_SMAPE: 8.4135\n",
      "Epoch 16/200\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 2.2259 - SMAPE: 4.2496 - val_loss: 2.0627 - val_SMAPE: 6.0373\n",
      "Epoch 17/200\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 2.0821 - SMAPE: 4.0215 - val_loss: 2.1223 - val_SMAPE: 6.2177\n",
      "Epoch 18/200\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 2.2110 - SMAPE: 4.1954 - val_loss: 2.5537 - val_SMAPE: 7.1167\n",
      "Epoch 19/200\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 2.0562 - SMAPE: 3.9733 - val_loss: 4.2712 - val_SMAPE: 11.3531\n",
      "Epoch 20/200\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 2.2118 - SMAPE: 4.1565 - val_loss: 3.0038 - val_SMAPE: 8.2069\n",
      "Epoch 21/200\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 2.0649 - SMAPE: 4.0237 - val_loss: 2.2857 - val_SMAPE: 6.5116\n",
      "Epoch 22/200\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 2.0918 - SMAPE: 3.9680 - val_loss: 3.7815 - val_SMAPE: 10.2656\n",
      "Epoch 23/200\n",
      "58/58 [==============================] - 0s 3ms/step - loss: 2.0953 - SMAPE: 3.9599 - val_loss: 4.8929 - val_SMAPE: 12.6864\n",
      "Epoch 24/200\n",
      "58/58 [==============================] - 0s 4ms/step - loss: 2.3814 - SMAPE: 4.4168 - val_loss: 4.0952 - val_SMAPE: 10.8741\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train and validation\n",
    "X_train, y_train, X_val, y_val = split_data(df_nn, 2020, 'price_actual')\n",
    "\n",
    "# Get the x cols for lstm network, lagged cols\n",
    "X_train_lstm = X_train.filter(regex='lag')\n",
    "X_train_dnn = X_train.drop(columns=X_train_lstm.columns)\n",
    "\n",
    "# Get the x cols for dnn network, forecast cols\n",
    "X_val_lstm = X_val.filter(regex='lag')\n",
    "X_val_dnn = X_val.drop(columns=X_val_lstm.columns)\n",
    "\n",
    "# Reorganize the training and testing data into batches\n",
    "X_train_dnn, y_train_dnn = resample((X_train_dnn, y_train), 24, 24, 24)\n",
    "X_val_dnn, y_val_dnn = resample((X_val_dnn, y_val), 24, 24, 24)\n",
    "\n",
    "# LSTM\n",
    "X_train_lstm, y_train_lstm = resample((X_train_lstm, y_train), 24, 24, 24)\n",
    "X_val_lstm, y_val_lstm = resample((X_val_lstm, y_val), 24, 24, 24)\n",
    "\n",
    "# Input Shape\n",
    "input_shape = (X_train_dnn.shape[1], X_train_dnn.shape[2])\n",
    "\n",
    "# Instantiate model and build layers\n",
    "nn = models.Sequential()\n",
    "nn.add(layers.Dense(59, activation='relu', input_shape=input_shape))\n",
    "nn.add(layers.Dense(239, activation='relu'))\n",
    "nn.add(layers.Dense(162, activation='relu'))\n",
    "nn.add(TimeDistributed(layers.Dense(1)))\n",
    "\n",
    "dnn = compile_fit(nn, (X_train_dnn, y_train_dnn), (X_val_dnn, y_val_dnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['None', 5.79, 5.482, 0.96, 0.963]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(dnn, 'None',(X_train_dnn, y_train_dnn), (X_val_dnn, y_val_dnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "58/58 [==============================] - 3s 25ms/step - loss: 52.6457 - SMAPE: 170.9025 - val_loss: 32.5681 - val_SMAPE: 138.8117\n",
      "Epoch 2/200\n",
      "58/58 [==============================] - 1s 18ms/step - loss: 49.3168 - SMAPE: 150.6581 - val_loss: 30.6863 - val_SMAPE: 124.8068\n",
      "Epoch 3/200\n",
      "58/58 [==============================] - 1s 18ms/step - loss: 47.5523 - SMAPE: 141.1469 - val_loss: 29.0365 - val_SMAPE: 113.5617\n",
      "Epoch 4/200\n",
      "58/58 [==============================] - 1s 18ms/step - loss: 45.9508 - SMAPE: 132.8189 - val_loss: 27.4837 - val_SMAPE: 103.7307\n",
      "Epoch 5/200\n",
      "58/58 [==============================] - 1s 18ms/step - loss: 44.4116 - SMAPE: 124.6981 - val_loss: 25.9782 - val_SMAPE: 94.8193\n",
      "Epoch 6/200\n",
      "58/58 [==============================] - 1s 18ms/step - loss: 42.9081 - SMAPE: 118.0794 - val_loss: 24.5145 - val_SMAPE: 86.6892\n",
      "Epoch 7/200\n",
      "58/58 [==============================] - 1s 19ms/step - loss: 41.4330 - SMAPE: 110.9771 - val_loss: 23.0847 - val_SMAPE: 79.2133\n",
      "Epoch 8/200\n",
      "58/58 [==============================] - 1s 19ms/step - loss: 39.9799 - SMAPE: 105.1034 - val_loss: 21.6896 - val_SMAPE: 72.3247\n",
      "Epoch 9/200\n",
      "58/58 [==============================] - 1s 20ms/step - loss: 38.5460 - SMAPE: 98.9284 - val_loss: 20.3303 - val_SMAPE: 65.9690\n",
      "Epoch 10/200\n",
      "58/58 [==============================] - 1s 20ms/step - loss: 37.1308 - SMAPE: 93.1463 - val_loss: 19.0122 - val_SMAPE: 60.1237\n",
      "Epoch 11/200\n",
      "58/58 [==============================] - 1s 19ms/step - loss: 35.7314 - SMAPE: 88.1254 - val_loss: 17.7409 - val_SMAPE: 54.7717\n",
      "Epoch 12/200\n",
      "58/58 [==============================] - 1s 19ms/step - loss: 34.3484 - SMAPE: 83.1615 - val_loss: 16.5148 - val_SMAPE: 49.8589\n",
      "Epoch 13/200\n",
      "58/58 [==============================] - 1s 19ms/step - loss: 32.9784 - SMAPE: 78.4644 - val_loss: 15.3537 - val_SMAPE: 45.4157\n",
      "Epoch 14/200\n",
      "58/58 [==============================] - 1s 19ms/step - loss: 31.6223 - SMAPE: 73.5024 - val_loss: 14.2617 - val_SMAPE: 41.4200\n",
      "Epoch 15/200\n",
      "58/58 [==============================] - 1s 20ms/step - loss: 30.2809 - SMAPE: 68.9322 - val_loss: 13.2389 - val_SMAPE: 37.8320\n",
      "Epoch 16/200\n",
      "58/58 [==============================] - 1s 24ms/step - loss: 28.9595 - SMAPE: 65.3741 - val_loss: 12.2979 - val_SMAPE: 34.6541\n",
      "Epoch 17/200\n",
      "58/58 [==============================] - 1s 25ms/step - loss: 27.6571 - SMAPE: 61.2699 - val_loss: 11.4678 - val_SMAPE: 31.9475\n",
      "Epoch 18/200\n",
      "58/58 [==============================] - 1s 24ms/step - loss: 26.3788 - SMAPE: 57.4905 - val_loss: 10.7585 - val_SMAPE: 29.7042\n",
      "Epoch 19/200\n",
      "58/58 [==============================] - 2s 26ms/step - loss: 25.1250 - SMAPE: 53.3629 - val_loss: 10.1785 - val_SMAPE: 27.9143\n",
      "Epoch 20/200\n",
      "58/58 [==============================] - 1s 26ms/step - loss: 23.8967 - SMAPE: 49.6713 - val_loss: 9.7359 - val_SMAPE: 26.5667\n",
      "Epoch 21/200\n",
      "58/58 [==============================] - 1s 22ms/step - loss: 22.7201 - SMAPE: 47.0606 - val_loss: 9.4168 - val_SMAPE: 25.5940\n",
      "Epoch 22/200\n",
      "58/58 [==============================] - 1s 22ms/step - loss: 21.5592 - SMAPE: 44.1417 - val_loss: 9.2065 - val_SMAPE: 24.9303\n",
      "Epoch 23/200\n",
      "58/58 [==============================] - 1s 23ms/step - loss: 20.4323 - SMAPE: 41.3549 - val_loss: 9.0999 - val_SMAPE: 24.5477\n",
      "Epoch 24/200\n",
      "58/58 [==============================] - 1s 23ms/step - loss: 19.3481 - SMAPE: 38.4354 - val_loss: 9.0938 - val_SMAPE: 24.4337\n",
      "Epoch 25/200\n",
      "58/58 [==============================] - 1s 24ms/step - loss: 18.3196 - SMAPE: 36.2931 - val_loss: 9.1906 - val_SMAPE: 24.5727\n",
      "Epoch 26/200\n",
      "58/58 [==============================] - 1s 23ms/step - loss: 17.3560 - SMAPE: 34.1179 - val_loss: 9.3885 - val_SMAPE: 24.9382\n",
      "Epoch 27/200\n",
      "58/58 [==============================] - 1s 23ms/step - loss: 16.4611 - SMAPE: 31.5086 - val_loss: 9.6778 - val_SMAPE: 25.4948\n",
      "Epoch 28/200\n",
      "58/58 [==============================] - 1s 24ms/step - loss: 15.6394 - SMAPE: 29.9916 - val_loss: 10.0424 - val_SMAPE: 26.1974\n",
      "Epoch 29/200\n",
      "58/58 [==============================] - 1s 24ms/step - loss: 14.9229 - SMAPE: 28.2874 - val_loss: 10.4520 - val_SMAPE: 26.9802\n",
      "Epoch 30/200\n",
      "58/58 [==============================] - 2s 26ms/step - loss: 14.2655 - SMAPE: 27.0977 - val_loss: 10.9233 - val_SMAPE: 27.8736\n",
      "Epoch 31/200\n",
      "58/58 [==============================] - 1s 22ms/step - loss: 13.6697 - SMAPE: 25.6604 - val_loss: 11.4208 - val_SMAPE: 28.8026\n",
      "Epoch 32/200\n",
      "58/58 [==============================] - 1s 23ms/step - loss: 13.1483 - SMAPE: 24.5747 - val_loss: 11.9378 - val_SMAPE: 29.7584\n",
      "Epoch 33/200\n",
      "58/58 [==============================] - 1s 22ms/step - loss: 12.7193 - SMAPE: 23.5832 - val_loss: 12.4549 - val_SMAPE: 30.7011\n",
      "Epoch 34/200\n",
      "58/58 [==============================] - 1s 24ms/step - loss: 12.3429 - SMAPE: 23.2752 - val_loss: 12.9791 - val_SMAPE: 31.6460\n"
     ]
    }
   ],
   "source": [
    "# Input Shape\n",
    "input_shape = (X_train_lstm.shape[1], X_train_lstm.shape[2])\n",
    "\n",
    "# Instantiate model and build layers\n",
    "nn = models.Sequential()\n",
    "nn.add(layers.LSTM(83, activation='tanh', input_shape=input_shape))\n",
    "nn.add(layers.RepeatVector(y_train_lstm.shape[1]))\n",
    "nn.add(layers.LSTM(24, activation='tanh', return_sequences=True))\n",
    "nn.add(TimeDistributed(layers.Dense(1)))\n",
    "\n",
    "lstm = compile_fit(nn, (X_train_lstm, y_train_lstm), (X_val_lstm, y_val_lstm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "58/58 [==============================] - 3s 22ms/step - loss: 2.0247 - SMAPE: 3.9934 - val_loss: 3.3477 - val_SMAPE: 9.3828\n",
      "Epoch 2/200\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 2.0468 - SMAPE: 3.9272 - val_loss: 2.9500 - val_SMAPE: 8.4063\n",
      "Epoch 3/200\n",
      "58/58 [==============================] - 1s 12ms/step - loss: 2.0287 - SMAPE: 3.8945 - val_loss: 3.2214 - val_SMAPE: 9.0830\n",
      "Epoch 4/200\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 2.0226 - SMAPE: 3.9312 - val_loss: 2.9404 - val_SMAPE: 8.3859\n",
      "Epoch 5/200\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 2.0256 - SMAPE: 4.0693 - val_loss: 3.0385 - val_SMAPE: 8.6289\n",
      "Epoch 6/200\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 2.0177 - SMAPE: 3.9020 - val_loss: 3.1071 - val_SMAPE: 8.7770\n",
      "Epoch 7/200\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 2.0150 - SMAPE: 3.8586 - val_loss: 3.4189 - val_SMAPE: 9.5543\n",
      "Epoch 8/200\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 2.0524 - SMAPE: 4.0052 - val_loss: 3.1026 - val_SMAPE: 8.7838\n",
      "Epoch 9/200\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 2.0279 - SMAPE: 3.9271 - val_loss: 2.8503 - val_SMAPE: 8.1651\n",
      "Epoch 10/200\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 2.0226 - SMAPE: 3.9111 - val_loss: 2.7179 - val_SMAPE: 7.8282\n",
      "Epoch 11/200\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 2.0403 - SMAPE: 3.9178 - val_loss: 2.6244 - val_SMAPE: 7.5818\n",
      "Epoch 12/200\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 2.0226 - SMAPE: 3.8893 - val_loss: 2.9399 - val_SMAPE: 8.3773\n",
      "Epoch 13/200\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 2.0331 - SMAPE: 3.9277 - val_loss: 3.0226 - val_SMAPE: 8.5930\n",
      "Epoch 14/200\n",
      "58/58 [==============================] - 1s 12ms/step - loss: 2.0141 - SMAPE: 3.8908 - val_loss: 3.2809 - val_SMAPE: 9.2305\n",
      "Epoch 15/200\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 2.0295 - SMAPE: 3.8915 - val_loss: 3.0407 - val_SMAPE: 8.6300\n",
      "Epoch 16/200\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 2.0451 - SMAPE: 4.1770 - val_loss: 3.3453 - val_SMAPE: 9.3786\n",
      "Epoch 17/200\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 2.0190 - SMAPE: 3.9065 - val_loss: 2.9591 - val_SMAPE: 8.4475\n",
      "Epoch 18/200\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 2.0229 - SMAPE: 3.9409 - val_loss: 2.9077 - val_SMAPE: 8.3018\n",
      "Epoch 19/200\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 2.0374 - SMAPE: 3.9078 - val_loss: 3.7623 - val_SMAPE: 10.3998\n",
      "Epoch 20/200\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 2.0358 - SMAPE: 3.9866 - val_loss: 2.9917 - val_SMAPE: 8.5100\n",
      "Epoch 21/200\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 2.0353 - SMAPE: 3.9668 - val_loss: 3.2755 - val_SMAPE: 9.2163\n"
     ]
    }
   ],
   "source": [
    "#LSTM_DNN = ensemble_nn([dnn, lstm])\n",
    "\n",
    "nn5 = compile_fit(LSTM_DNN, ([X_train_dnn, X_train_lstm], y_train_dnn), ([X_val_dnn, X_val_lstm], y_val_dnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/nn5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/nn5\\assets\n"
     ]
    }
   ],
   "source": [
    "nn5.save('../models/nn5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
